<!DOCTYPE html><html lang="zh-CN" data-theme="dark"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no"><title>Flink的DataStreamAPI | 曦</title><meta name="keywords" content="geekswg,大数据,Flink"><meta name="author" content="曦"><meta name="copyright" content="曦"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#18171d"><meta name="mobile-web-app-capable" content="yes"><meta name="apple-touch-fullscreen" content="yes"><meta name="apple-mobile-web-app-title" content="Flink的DataStreamAPI"><meta name="application-name" content="Flink的DataStreamAPI"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="#18171d"><meta property="og:type" content="article"><meta property="og:title" content="Flink的DataStreamAPI"><meta property="og:url" content="https://bigdata-yx.github.io/posts/pd14.html"><meta property="og:site_name" content="曦"><meta property="og:description" content="DataStream API是Flink的核心层API。一个Flink程序，其实就是对DataStream的各种转换。具体来说，代码基本上都由以下几部分构成： 在Flink1.12以前，旧的添加source的方式，是调用执行环境的addSource()方法：1DataStream&amp;lt;String"><meta property="og:locale" content="zh-CN"><meta property="og:image" content="https://pic1.imgdb.cn/item/6784bd24d0e0a243d4f3d4a3.png?_r_=c31f22a8-5d93-17a1-e2f3-b175d5805f0e"><meta property="article:author" content="曦"><meta property="article:tag" content="[&quot;云曦&quot;,&quot;集群&quot;,&quot;曦&quot;,&quot;hexo&quot;,&quot;大数据&quot;]"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://pic1.imgdb.cn/item/6784bd24d0e0a243d4f3d4a3.png?_r_=c31f22a8-5d93-17a1-e2f3-b175d5805f0e"><meta name="description" content="DataStream API是Flink的核心层API。一个Flink程序，其实就是对DataStream的各种转换。具体来说，代码基本上都由以下几部分构成： 在Flink1.12以前，旧的添加source的方式，是调用执行环境的addSource()方法：1DataStream&amp;lt;String"><link rel="shortcut icon" href="/favicon.ico"><link rel="canonical" href="https://bigdata-yx.github.io/posts/pd14.html"><link rel="preconnect" href="//unpkg.com"/><link rel="preconnect" href="//www.google-analytics.com" crossorigin=""/><link rel="preconnect" href="//hm.baidu.com"/><link rel="preconnect" href="//www.clarity.ms"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><meta name="google-site-verification" content="zdB7aP6RvrvD3vHDMiBCw88fHYFi6pWHVgy4OruU6ZI"/><meta name="baidu-site-verification" content="codeva-h6TRQ4og6W"/><meta name="msvalidate.01" content="A1131C8FE475E0378A8D237741CD7850"/><link rel="manifest" href="/manifest.json"/><meta name="msapplication-TileColor" content="var(--anzhiyu-main)"/><link rel="mask-icon" href="/img/siteicon/apple-icon-180.png" color="#5bbad5"/><link rel="apple-touch-icon" sizes="180x180" href="/img/siteicon/apple-icon-180.png"/><link rel="apple-touch-icon-precomposed" sizes="180x180" href="/img/siteicon/apple-icon-180.png"/><link rel="icon" type="image/png" sizes="32x32" href="/img/siteicon/32.png"/><link rel="icon" type="image/png" sizes="16x16" href="/img/siteicon/16.png"/><link rel="bookmark" href="/img/siteicon/apple-icon-180.png"/><link rel="apple-touch-startup-image" href="/img/siteicon/apple-splash-2048-2732.jpg" media="(device-width: 1024px) and (device-height: 1366px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)"/><link rel="apple-touch-startup-image" href="/img/siteicon/apple-splash-2732-2048.jpg" media="(device-width: 1024px) and (device-height: 1366px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)"/><link rel="apple-touch-startup-image" href="/img/siteicon/apple-splash-1668-2388.jpg" media="(device-width: 834px) and (device-height: 1194px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)"/><link rel="apple-touch-startup-image" href="/img/siteicon/apple-splash-2388-1668.jpg" media="(device-width: 834px) and (device-height: 1194px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)"/><link rel="apple-touch-startup-image" href="/img/siteicon/apple-splash-1536-2048.jpg" media="(device-width: 768px) and (device-height: 1024px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)"/><link rel="apple-touch-startup-image" href="/img/siteicon/apple-splash-2048-1536.jpg" media="(device-width: 768px) and (device-height: 1024px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)"/><link rel="apple-touch-startup-image" href="/img/siteicon/apple-splash-1668-2224.jpg" media="(device-width: 834px) and (device-height: 1112px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)"/><link rel="apple-touch-startup-image" href="/img/siteicon/apple-splash-2224-1668.jpg" media="(device-width: 834px) and (device-height: 1112px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)"/><link rel="apple-touch-startup-image" href="/img/siteicon/apple-splash-1620-2160.jpg" media="(device-width: 810px) and (device-height: 1080px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)"/><link rel="apple-touch-startup-image" href="/img/siteicon/apple-splash-2160-1620.jpg" media="(device-width: 810px) and (device-height: 1080px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)"/><link rel="apple-touch-startup-image" href="/img/siteicon/apple-splash-1290-2796.jpg" media="(device-width: 430px) and (device-height: 932px) and (-webkit-device-pixel-ratio: 3) and (orientation: portrait)"/><link rel="apple-touch-startup-image" href="/img/siteicon/apple-splash-2796-1290.jpg" media="(device-width: 430px) and (device-height: 932px) and (-webkit-device-pixel-ratio: 3) and (orientation: landscape)"/><link rel="apple-touch-startup-image" href="/img/siteicon/apple-splash-1179-2556.jpg" media="(device-width: 393px) and (device-height: 852px) and (-webkit-device-pixel-ratio: 3) and (orientation: portrait)"/><link rel="apple-touch-startup-image" href="/img/siteicon/apple-splash-2556-1179.jpg" media="(device-width: 393px) and (device-height: 852px) and (-webkit-device-pixel-ratio: 3) and (orientation: landscape)"/><link rel="apple-touch-startup-image" href="/img/siteicon/apple-splash-1284-2778.jpg" media="(device-width: 428px) and (device-height: 926px) and (-webkit-device-pixel-ratio: 3) and (orientation: portrait)"/><link rel="apple-touch-startup-image" href="/img/siteicon/apple-splash-2778-1284.jpg" media="(device-width: 428px) and (device-height: 926px) and (-webkit-device-pixel-ratio: 3) and (orientation: landscape)"/><link rel="apple-touch-startup-image" href="/img/siteicon/apple-splash-1170-2532.jpg" media="(device-width: 390px) and (device-height: 844px) and (-webkit-device-pixel-ratio: 3) and (orientation: portrait)"/><link rel="apple-touch-startup-image" href="/img/siteicon/apple-splash-2532-1170.jpg" media="(device-width: 390px) and (device-height: 844px) and (-webkit-device-pixel-ratio: 3) and (orientation: landscape)"/><link rel="apple-touch-startup-image" href="/img/siteicon/apple-splash-1125-2436.jpg" media="(device-width: 375px) and (device-height: 812px) and (-webkit-device-pixel-ratio: 3) and (orientation: portrait)"/><link rel="apple-touch-startup-image" href="/img/siteicon/apple-splash-2436-1125.jpg" media="(device-width: 375px) and (device-height: 812px) and (-webkit-device-pixel-ratio: 3) and (orientation: landscape)"/><link rel="apple-touch-startup-image" href="/img/siteicon/apple-splash-1242-2688.jpg" media="(device-width: 414px) and (device-height: 896px) and (-webkit-device-pixel-ratio: 3) and (orientation: portrait)"/><link rel="apple-touch-startup-image" href="/img/siteicon/apple-splash-2688-1242.jpg" media="(device-width: 414px) and (device-height: 896px) and (-webkit-device-pixel-ratio: 3) and (orientation: landscape)"/><link rel="apple-touch-startup-image" href="/img/siteicon/apple-splash-828-1792.jpg" media="(device-width: 414px) and (device-height: 896px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)"/><link rel="apple-touch-startup-image" href="/img/siteicon/apple-splash-1792-828.jpg" media="(device-width: 414px) and (device-height: 896px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)"/><link rel="apple-touch-startup-image" href="/img/siteicon/apple-splash-1242-2208.jpg" media="(device-width: 414px) and (device-height: 736px) and (-webkit-device-pixel-ratio: 3) and (orientation: portrait)"/><link rel="apple-touch-startup-image" href="/img/siteicon/apple-splash-2208-1242.jpg" media="(device-width: 414px) and (device-height: 736px) and (-webkit-device-pixel-ratio: 3) and (orientation: landscape)"/><link rel="apple-touch-startup-image" href="/img/siteicon/apple-splash-750-1334.jpg" media="(device-width: 375px) and (device-height: 667px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)"/><link rel="apple-touch-startup-image" href="/img/siteicon/apple-splash-1334-750.jpg" media="(device-width: 375px) and (device-height: 667px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)"/><link rel="apple-touch-startup-image" href="/img/siteicon/apple-splash-640-1136.jpg" media="(device-width: 320px) and (device-height: 568px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)"/><link rel="apple-touch-startup-image" href="/img/siteicon/apple-splash-1136-640.jpg" media="(device-width: 320px) and (device-height: 568px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)"/><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-tag-plugins-plus@1.0.17/lib/assets/font-awesome-animation.min.css"><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://unpkg.com/@fortawesome/fontawesome-free@6.4.0/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://unpkg.com/node-snackbar@0.1.16/dist/snackbar.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://unpkg.com/@fancyapps/ui@5.0.28/dist/fancybox/fancybox.css" media="print" onload="this.media='all'"><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?c78e148e63a5f161b51f3c05d3be3acb";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script><script async="async" src="https://www.googletagmanager.com/gtag/js?id=G-MXDTZ2L2TY"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-MXDTZ2L2TY');
</script><script>(function(c,l,a,r,i,t,y){
    c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
    t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
    y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
})(window, document, "clarity", "script", "hhn2or4dz5");</script><script>const GLOBAL_CONFIG = {
  linkPageTop: {"enable":true,"title":"我来此游息，夏景方赫曦","addFriendPlaceholder":"昵称（请勿包含博客等字样）：\n网站地址（要求博客地址，请勿提交个人主页）：\n头像图片url（请提供尽可能清晰的图片，我会上传到我自己的图床）：\n描述：\n站点截图（可选）：\n"},
  peoplecanvas: undefined,
  postHeadAiDescription: {"enable":true,"gptName":"Geek","mode":"local","switchBtn":false,"btnLink":"https://afdian.net/item/886a79d4db6711eda42a52540025c377","randomNum":3,"basicWordCount":1000,"key":"xxxx","Referer":"https://xx.xx/"},
  diytitle: {"enable":true,"leaveTitle":"w(ﾟДﾟ)w 不要走！再看看嘛！","backTitle":"♪(^∇^*)欢迎肥来！"},
  LA51: {"enable":true,"ck":"K2mM1vs6nmCWtp4K","LingQueMonitorID":"K2p99vzdYjQNd6HL"},
  greetingBox: {"enable":true,"default":"Hello World","list":[{"greeting":"🌉晚安,好梦😴","startTime":0,"endTime":5},{"greeting":"🌅早上好鸭, 祝你一天好心情！","startTime":6,"endTime":9},{"greeting":"🧑‍💻上午好, 状态很好，鼓励一下～","startTime":10,"endTime":10},{"greeting":"🕚11点多啦, 在坚持一下就吃饭啦～","startTime":11,"endTime":11},{"greeting":"☀️午安, 宝贝该午休了🥱","startTime":12,"endTime":14},{"greeting":"💻充实的一天辛苦啦！","startTime":14,"endTime":18},{"greeting":"🛸下班啦, 奖励一顿丰盛的大餐吧🍔。","startTime":19,"endTime":19},{"greeting":"🌃晚上好, 在属于自己的时间好好放松😌~","startTime":20,"endTime":24}]},
  twikooEnvId: 'https://hkjcpdd.xiaozhou.cloud/',
  commentBarrageConfig:{"enable":true,"maxBarrage":1,"barrageTime":5000,"accessToken":"a237426c5e1099af41370c4b0afe0a3e","mailMd5":"387d70b783681ad6f6c7a0bc0ccc329c"},
  music_page_default: "nav_music",
  root: '/',
  preloader: {"source":3},
  friends_vue_info: {"apiurl":"https://blogyx.top//YXlhx/blog"},
  navMusic: true,
  mainTone: {"mode":"api","api":"https://api.qjqq.cn/api/Imgcolor?img=","cover_change":true},
  authorStatus: {"skills":["🤖️ 数码科技爱好者","🔍 分享与热心帮助","🏠 智能家居小能手","🔨 设计开发一条龙","🤝 专修交互与设计","🏃 脚踏实地行动派","🧱 团队小组发动机","💢 壮汉人狠话不多"]},
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":true,"languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: {"limitDay":180,"position":"top","messagePrev":"It has been","messageNext":"days since the last update, the content of the article may be outdated."},
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":512},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    simplehomepage: true,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: {"copy":true,"copyrightEbable":true,"limitCount":128,"languages":{"author":"作者: 曦","link":"链接: ","source":"来源: 曦","info":"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。","copySuccess":"复制成功，复制和转载请标注本文地址"}},
  lightbox: 'mediumZoom',
  Snackbar: {"chs_to_cht":"你已切换为繁体","cht_to_chs":"你已切换为简体","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#3b70fc","bgDark":"#1f1f1f","position":"top-center"},
  source: {
    justifiedGallery: {
      js: 'https://unpkg.com/flickr-justified-gallery@2.1.2/dist/fjGallery.min.js',
      css: 'https://unpkg.com/flickr-justified-gallery@2.1.2/dist/fjGallery.css'
    }
  },
  isPhotoFigcaption: true,
  islazyload: true,
  isAnchor: true,
  shortcutKey: {"enable":true,"delay":100,"shiftDelay":200},
  autoDarkmode: true
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  configTitle: '曦',
  title: 'Flink的DataStreamAPI',
  postAI: 'Flink',
  pageFillDescription: 'DataStream API是Flink的核心层API。一个Flink程序其实就是对DataStream的各种转换。具体来说代码基本上都由以下几部分构成：, 在Flink1.12以前旧的添加source的方式是调用执行环境的addSource()方法：, 方法传入的参数是一个源函数（source function）需要实现SourceFunction接口。, 从Flink1.12开始主要使用流批统一的新Source架构：, Flink直接提供了很多预实现的接口此外还有很多外部连接工具也帮我们实现了对应的Source通常情况下足以应对我们的实际需求。, 准备工作, 为了方便练习这里使用WaterSensor作为数据模型。, 具体代码如下：, 这里需要注意我们定义的WaterSensor有这样几个特点：, Flink会把这样的类作为一种特殊的POJO（Plain Ordinary Java Object简单的Java对象实际就是普通JavaBeans）数据类型来对待方便数据的解析和序列化。另外我们在类中还重写了toString方法主要是为了测试输出显示更清晰。, 我们这里自定义的POJO类会在后面的代码中频繁使用所以在后面的代码中碰到把这里的POJO类导入就好了。, 1.从集合、文件、元素中读取数据, 最简单的读取数据的方式就是在代码中直接创建一个Java集合然后调用执行环境的fromCollection方法进行读取。这相当于将数据临时存储到内存中形成特殊的数据结构后作为数据源使用一般用于测试。, 1.2从Socket读取数据, 不论从集合还是文件我们读取的其实都是有界数据。在流处理的场景中数据往往是无界的。, 我们之前用到的读取socket文本流就是流处理场景。但是这种方式由于吞吐量小、稳定性较差一般也是用于测试。, 1.3从Kafka中读取数据, Flink官方提供了连接工具flink-connector-kafka直接帮我们实现了一个消费者FlinkKafkaConsumer它就是用来读取Kafka数据的SourceFunction。, 所以想要以Kafka作为数据源获取数据我们只需要引入Kafka连接器的依赖。Flink官方提供的是一个通用的Kafka连接器它会自动跟踪最新版本的Kafka客户端。目前最新版本只支持0.10.0版本以上的Kafka。这里我们需要导入的依赖如下。, 代码如下：, 1.4 从数据生成器读取数据, Flink从1.11开始提供了一个内置的DataGen 连接器主要是用于生成一些随机数用于在没有数据源的时候进行流任务的测试以及性能测试等。1.17提供了新的Source写法需要导入依赖：, 代码如下：, 1.5Flink支持的数据类型, Flink的类型系统, Flink支持的数据类型, （1）基本类型, （2）数组类型, （3）复合数据类型, Scala 样例类及Scala元组：不支持空字段。, 行类型（ROW）：可以认为是具有任意个字段的元组并支持空字段。, POJO：Flink自定义的类似于Java bean模式的类。, （4）辅助类型, Option、Either、List、Map等。, （5）泛型类型（GENERIC）, Flink支持所有的Java类和Scala类。不过如果没有按照上面POJO类型的要求来定义就会被Flink当作泛型类来处理。Flink会把泛型类型当作黑盒无法获取它们内部的属性；它们也不是由Flink本身序列化的而是由Kryo序列化的。, 在这些类型中元组类型和POJO类型最为灵活因为它们支持创建复杂类型。而相比之下POJO还支持在键（key）的定义中直接使用字段名这会让我们的代码可读性大大增加。所以在项目实践中往往会将流处理程序中的元素类型定为Flink的POJO类型。, Flink对POJO类型的要求如下：, 类是公有（public）的, 有一个无参的构造方法, 所有属性都是公有（public）的, 所有属性的类型都是可以序列化的, 3）类型提示（Type Hints）, Flink还具有一个类型提取系统可以分析函数的输入和返回类型自动获取类型信息从而获得对应的序列化器和反序列化器。但是由于Java中泛型擦除的存在在某些特殊情况下（比如Lambda表达式中）自动提取的信息是不够精细的——只告诉Flink当前的元素由船头、船身、船尾构成根本无法重建出大船的模样；这时就需要显式地提供类型信息才能使应用程序正常工作或提高其性能。, 为了解决这类问题Java API提供了专门的类型提示（type hints）。, 回忆一下之前的word count流处理程序我们在将String类型的每个词转换成（word count）二元组后就明确地用returns指定了返回的类型。因为对于map里传入的Lambda表达式系统只能推断出返回的是Tuple2类型而无法得到Tuple2ltString Longgt。只有显式地告诉系统当前的返回类型才能正确地解析出完整数据。, Flink还专门提供了TypeHint类它可以捕获泛型的类型信息并且一直记录下来为运行时提供足够的信息。我们同样可以通过.returns()方法明确地指定转换之后的DataStream里元素的类型。, 转换算子（Transformation）, 数据源读入数据之后我们就可以使用各种转换算子将一个或多个DataStream转换为新的DataStream。, 1.基本转换算子（mapx2F filterx2F flatMap）, 1.1.1映射（map）, map是大家非常熟悉的大数据操作算子主要用于将数据流中的数据进行转换形成新的数据流。简单来说就是一个一一映射消费一个元素就产出一个元素。, 我们只需要基于DataStream调用map()方法就可以进行转换处理。方法需要传入的参数是接口MapFunction的实现；返回值类型还是DataStream不过泛型（流中的元素类型）可能改变。, 下面的代码用不同的方式实现了提取WaterSensor中的id字段的功能。, 上面代码中MapFunction实现类的泛型类型与输入数据类型和输出数据的类型有关。在实现MapFunction接口的时候需要指定两个泛型分别是输入事件和输出事件的类型还需要重写一个map()方法定义从一个输入事件转换为另一个输出事件的具体逻辑。, 1.1.2过滤（filter）, filter转换操作顾名思义是对数据流执行一个过滤通过一个布尔条件表达式设置过滤条件对于每一个流内元素进行判断若为true则元素正常输出若为false则元素被过滤掉。, 进行filter转换之后的新数据流的数据类型与原数据流是相同的。filter转换需要传入的参数需要实现FilterFunction接口而FilterFunction内要实现filter()方法就相当于一个返回布尔类型的条件表达式。, 案例需求：下面的代码会将数据流中传感器id为sensor_1的数据过滤出来。, 1.1.3 扁平映射（flatMap）, flatMap操作又称为扁平映射主要是将数据流中的整体（一般是集合类型）拆分成一个一个的个体使用。消费一个元素可以产生0到多个元素。flatMap可以认为是扁平化（flatten）和映射（map）两步操作的结合也就是先按照某种规则对数据进行打散拆分再对拆分后的元素做转换处理。, 同map一样flatMap也可以使用Lambda表达式或者FlatMapFunction接口实现类的方式来进行传参返回值类型取决于所传参数的具体逻辑可以与原数据流相同也可以不同。, 案例需求：如果输入的数据是sensor_1只打印vc；如果输入的数据是sensor_2既打印ts又打印vc。, 实现代码如下：, 1.2聚合算子（Aggregation）, 计算的结果不仅依赖当前数据还跟之前的数据有关相当于要把所有数据聚在一起进行汇总合并——这就是所谓的聚合（Aggregation）类似于MapReduce中的reduce操作。, 1.2.1 按键分区（keyBy）, 对于Flink而言DataStream是没有直接进行聚合的API的。因为我们对海量数据做聚合肯定要进行分区并行处理这样才能提高效率。所以在Flink中要做聚合需要先进行分区；这个操作就是通过keyBy来完成的。, keyBy是聚合前必须要用到的一个算子。keyBy通过指定键（key）可以将一条流从逻辑上划分成不同的分区（partitions）。这里所说的分区其实就是并行处理的子任务。, 基于不同的key流中的数据将被分配到不同的分区中去；这样一来所有具有相同的key的数据都将被发往同一个分区。, 在内部是通过计算key的哈希值（hash code）对分区数进行取模运算来实现的。所以这里key如果是POJO的话必须要重写hashCode()方法。, keyBy()方法需要传入一个参数这个参数指定了一个或一组key。有很多不同的方法来指定key：比如对于Tuple数据类型可以指定字段的位置或者多个位置的组合；对于POJO类型可以指定字段的名称（String）；另外还可以传入Lambda表达式或者实现一个键选择器（KeySelector）用于说明从数据中提取key的逻辑。, 我们可以以id作为key做一个分区操作代码实现如下：, 需要注意的是keyBy得到的结果将不再是DataStream而是会将DataStream转换为KeyedStream。KeyedStream可以认为是分区流或者键控流它是对DataStream按照key的一个逻辑分区所以泛型有两个类型：除去当前流中的元素类型外还需要指定key的类型。, KeyedStream也继承自DataStream所以基于它的操作也都归属于DataStream API。但它跟之前的转换操作得到的SingleOutputStreamOperator不同只是一个流的分区操作并不是一个转换算子。KeyedStream是一个非常重要的数据结构只有基于它才可以做后续的聚合操作（比如sumreduce）。, 1.2.2 简单聚合（sumx2Fminx2Fmaxx2FminByx2FmaxBy）, 有了按键分区的数据流KeyedStream我们就可以基于它进行聚合操作了。Flink为我们内置实现了一些最基本、最简单的聚合API主要有以下几种：, sum()：在输入流上对指定的字段做叠加求和的操作。, min()：在输入流上对指定的字段求最小值。, max()：在输入流上对指定的字段求最大值。, minBy()：与min()类似在输入流上针对指定字段求最小值。不同的是min()只计算指定字段的最小值其他字段会保留最初第一个数据的值；而minBy()则会返回包含字段最小值的整条数据。, maxBy()：与max()类似在输入流上针对指定字段求最大值。两者区别与min()x2FminBy()完全一致。, 简单聚合算子使用非常方便语义也非常明确。这些聚合方法调用时也需要传入参数；但并不像基本转换算子那样需要实现自定义函数只要说明聚合指定的字段就可以了。指定字段的方式有两种：指定位置和指定名称。, 对于元组类型的数据可以使用这两种方式来指定字段。需要注意的是元组中字段的名称是以f0、f1、f2、…来命名的。, 如果数据流的类型是POJO类那么就只能通过字段名称来指定不能通过位置来指定了。, 简单聚合算子返回的同样是一个SingleOutputStreamOperator也就是从KeyedStream又转换成了常规的DataStream。所以可以这样理解：keyBy和聚合是成对出现的先分区、后聚合得到的依然是一个DataStream。而且经过简单聚合之后的数据流元素的数据类型保持不变。, 一个聚合算子会为每一个key保存一个聚合的值在Flink中我们把它叫作状态（state）。所以每当有一个新的数据输入算子就会更新保存的聚合结果并发送一个带有更新后聚合值的事件到下游算子。对于无界流来说这些状态是永远不会被清除的所以我们使用聚合算子应该只用在含有有限个key的数据流上。, 1.2.3 归约聚合（reduce）, reduce可以对已有的数据进行归约处理把每一个新输入的数据和当前已经归约出来的值再做一个聚合计算。, reduce操作也会将KeyedStream转换为DataStream。它不会改变流的元素数据类型所以输出类型和输入类型是一样的。, 调用KeyedStream的reduce方法时需要传入一个参数实现ReduceFunction接口。接口在源码中的定义如下：, ReduceFunction接口里需要实现reduce()方法这个方法接收两个输入事件经过转换处理之后输出一个相同类型的事件。在流处理的底层实现过程中实际上是将中间合并的结果作为任务的一个状态保存起来的；之后每来一个新的数据就和之前的聚合状态进一步做归约。, 我们可以单独定义一个函数类实现ReduceFunction接口也可以直接传入一个匿名类。当然同样也可以通过传入Lambda表达式实现类似的功能。, 为了方便后续使用定义一个WaterSensorMapFunction：, 案例：使用reduce实现max和maxBy的功能。, reduce同简单聚合算子一样也要针对每一个key保存状态。因为状态不会清空所以我们需要将reduce算子作用在一个有限key的流上。, 1.3.3 用户自定义函数（UDF）, 用户自定义函数（user-defined functionUDF）即用户可以根据自身需求重新实现算子的逻辑。, 用户自定义函数分为：函数类、匿名函数、富函数类。, 需求：用来从用户的点击数据中筛选包含sensor_1的内容：, 方式一：实现FilterFunction接口, 方式二：通过匿名类来实现FilterFunction接口：, 方式二的优化：为了类可以更加通用我们还可以将用于过滤的关键字home抽象出来作为类的属性调用构造方法时传进去。, 方式三：采用匿名函数（Lambda）, 1.3.2 富函数类（Rich Function Classes）, 富函数类也是DataStream API提供的一个函数类的接口所有的Flink函数类都有其Rich版本。富函数类一般是以抽象类的形式出现的。例如：RichMapFunction、RichFilterFunction、RichReduceFunction等。, 与常规函数类的不同主要在于富函数类可以获取运行环境的上下文并拥有一些生命周期方法所以可以实现更复杂的功能。, Rich Function有生命周期的概念。典型的生命周期方法有：, open()方法是Rich Function的初始化方法也就是会开启一个算子的生命周期。当一个算子的实际工作方法例如map()或者filter()方法被调用之前open()会首先被调用。, close()方法是生命周期中的最后一个调用的方法类似于结束方法。一般用来做一些清理工作。, 需要注意的是这里的生命周期方法对于一个并行子任务来说只会调用一次；而对应的实际工作方法例如RichMapFunction中的map()在每条数据到来后都会触发一次调用。, 来看一个例子说明：, 5.3.4 物理分区算子（Physical Partitioning）, 常见的物理分区策略有：随机分配（Random）、轮询分配（Round-Robin）、重缩放（Rescale）和广播（Broadcast）。, 1.4.1 随机分区（shuffle）, 最简单的重分区方式就是直接洗牌。通过调用DataStream的.shuffle()方法将数据随机地分配到下游算子的并行任务中去。, 随机分区服从均匀分布（uniform distribution）所以可以把流中的数据随机打乱均匀地传递到下游任务分区。因为是完全随机的所以对于同样的输入数据 每次执行得到的结果也不会相同。, 经过随机分区之后得到的依然是一个DataStream。, 我们可以做个简单测试：将数据读入之后直接打印到控制台将输出的并行度设置为2中间经历一次shuffle。执行多次观察结果是否相同。, 1.4.2 轮询分区（Round-Robin）, 轮询简单来说就是发牌按照先后顺序将数据做依次分发。通过调用DataStream的.rebalance()方法就可以实现轮询重分区。rebalance使用的是Round-Robin负载均衡算法可以将输入流数据平均分配到下游的并行任务中去。, 1.4.3 重缩放分区（rescale）, 重缩放分区和轮询分区非常相似。当调用rescale()方法时其实底层也是使用Round-Robin算法进行轮询但是只会将数据轮询发送到下游并行任务的一部分中。rescale的做法是分成小团体发牌人只给自己团体内的所有人轮流发牌。, 1.4.4 广播（broadcast）, 这种方式其实不应该叫做重分区因为经过广播之后数据会在不同的分区都保留一份可能进行重复处理。可以通过调用DataStream的broadcast()方法将输入数据复制并发送到下游算子的所有并行任务中去。, 1.4.5 全局分区（global）, 全局分区也是一种特殊的分区方式。这种做法非常极端通过调用.global()方法会将所有的输入流数据都发送到下游算子的第一个并行子任务中去。这就相当于强行让下游任务并行度变成了1所以使用这个操作需要非常谨慎可能对程序造成很大的压力。, 1.4.6 自定义分区（Custom）, 当Flink提供的所有分区策略都不能满足用户的需求时我们可以通过使用partitionCustom()方法来自定义分区策略。, 1)自定义分区器, 2）使用自定义分区器, 1.3.5分流, 所谓分流就是将一条数据流拆分成完全独立的两条、甚至多条流。也就是基于一个DataStream定义一些筛选条件将符合条件的数据拣选出来放到对应的流里。, 1.3.5.1 简单实现, 这种实现非常简单但代码显得有些冗余——我们的处理逻辑对拆分出的三条流其实是一样的却重复写了三次。而且这段代码背后的含义是将原始数据流stream复制三份然后对每一份分别做筛选；这明显是不够高效的。我们自然想到能不能不用复制流直接用一个算子就把它们都拆分开呢？, 1.3.5.2 使用侧输出流, 1.3.6 基本合流操作, 在实际应用中我们经常会遇到来源不同的多条流需要将它们的数据进行联合处理。所以Flink中合流的操作会更加普遍对应的API也更加丰富。, 1.3.6.1, 最简单的合流操作就是直接将多条流合在一起叫作流的联合（union）。联合操作要求必须流中的数据类型必须相同合并之后的新流会包括所有流中的元素数据类型不变。, 在代码中我们只要基于DataStream直接调用.union()方法传入其他DataStream作为参数就可以实现流的联合了；得到的依然是一个DataStream：, 注意：union()的参数可以是多个DataStream所以联合操作可以实现多条流的合并。, 1.3.6.2 连接（Connect）, 流的联合虽然简单不过受限于数据类型不能改变灵活性大打折扣所以实际应用较少出现。除了联合（union）Flink还提供了另外一种方便的合流操作——连接（connect）。, 1）连接流（ConnectedStreams）, 1.4输出算子, Flink作为数据处理框架最终还是要把计算处理的结果写入外部存储为外部应用提供支持。, 1.4.1 连接到外部系统, Flink的DataStream API专门提供了向外部写入数据的方法：addSink。与addSource类似addSink方法对应着一个Sink算子主要就是用来实现与外部系统连接、并将数据提交写入的；Flink程序中所有对外的输出操作一般都是利用Sink算子完成的。, Flink1.12以前Sink算子的创建是通过调用DataStream的.addSink()方法实现的。, stream.addSink(new SinkFunction(…)), addSink方法同样需要传入一个参数实现的是SinkFunction接口。在这个接口中只需要重写一个方法invoke()用来将指定的值写入到外部系统中。这个方法在每条数据记录到来时都会调用。, Flink1.12开始同样重构了Sink架构, 当然Sink多数情况下同样并不需要我们自己实现。之前我们一直在使用的print方法其实就是一种Sink它表示将数据流写入标准控制台打印输出。Flink官方为我们提供了一部分的框架的Sink连接器。如下图所示列出了Flink官方目前支持的第三方系统连接器：, 我们可以看到像Kafka之类流式系统Flink提供了完美对接sourcex2Fsink两端都能连接可读可写；而对于Elasticsearch、JDBC等数据存储系统则只提供了输出写入的sink连接器。, 除Flink官方之外Apache Bahir框架也实现了一些其他第三方系统与Flink的连接器。, 除此以外就需要用户自定义实现sink连接器了。, 5.4.2 输出到文件, Flink专门提供了一个流式文件系统的连接器：FileSink为批处理和流处理提供了一个统一的Sink它可以将分区文件写入Flink支持的文件系统。, FileSink支持行编码（Row-encoded）和批量编码（Bulk-encoded）格式。这两种不同的方式都有各自的构建器（builder）可以直接调用FileSink的静态方法：, 实例：, 1.4.3 输出到Kafka, （1）添加Kafka 连接器依赖, 由于我们已经测试过从Kafka数据源读取数据连接器相关依赖已经引入这里就不重复介绍了。, （2）启动Kafka集群, （3）编写输出到Kafka的示例代码, 输出无key的record, 然后开一个消费者查看是否到数据, 1.4.4 输出到MySQL（JDBC）, 写入数据的MySQL的测试步骤如下。, （1）添加依赖, 添加MySQL驱动：, 官方还未提供flink-connector-jdbc的1.17.0的正式依赖暂时从apache snapshot仓库下载pom文件中指定仓库路径：, 添加依赖：, 如果不生效还需要修改本地maven的配置文件mirrorOf中添加如下标红内容：, （2）启动MySQL在test库下建表ws, （3）编写输出到MySQL的示例代码, （4）运行代码用客户端连接MySQL查看是否成功写入数据。, 1.4.5 自定义Sink输出, 如果我们想将数据存储到我们自己的存储设备中而Flink并没有提供可以直接使用的连接器就只能自定义Sink进行输出了。与Source类似Flink为我们提供了通用的SinkFunction接口和对应的RichSinkDunction抽象类只要实现它通过简单地调用DataStream的.addSink()方法就可以自定义写入任何外部存储。, 在实现SinkFunction的时候需要重写的一个关键方法invoke()在这个方法中我们就可以实现将流里的数据发送出去的逻辑。, 这种方式比较通用对于任何外部存储系统都有效；不过自定义Sink想要实现状态一致性并不容易所以一般只在没有其它选择时使用。实际项目中用到的外部连接器Flink官方基本都已实现而且在不断地扩充因此自定义的场景并不常见。是的核心层一个程序其实就是对的各种转换具体来说代码基本上都由以下几部分构成在以前旧的添加的方式是调用执行环境的方法方法传入的参数是一个源函数需要实现接口从开始主要使用流批统一的新架构直接提供了很多预实现的接口此外还有很多外部连接工具也帮我们实现了对应的通常情况下足以应对我们的实际需求准备工作为了方便练习这里使用作为数据模型水位传感器类型传感器记录时间戳水位记录具体代码如下这里需要注意我们定义的有这样几个特点类是公有的有一个无参的构造方法所有属性都是公有的所有属性的类型都是可以序列化的会把这样的类作为一种特殊的简单的对象实际就是普通数据类型来对待方便数据的解析和序列化另外我们在类中还重写了方法主要是为了测试输出显示更清晰我们这里自定义的类会在后面的代码中频繁使用所以在后面的代码中碰到把这里的类导入就好了从集合文件元素中读取数据最简单的读取数据的方式就是在代码中直接创建一个集合然后调用执行环境的方法进行读取这相当于将数据临时存储到内存中形成特殊的数据结构后作为数据源使用一般用于测试从元素中读取数据从集合中读取数据从文件中读取数据学习打印输出从元素中从集合中从文件中从读取数据不论从集合还是文件我们读取的其实都是有界数据在流处理的场景中数据往往是无界的我们之前用到的读取文本流就是流处理场景但是这种方式由于吞吐量小稳定性较差一般也是用于测试从中读取数据官方提供了连接工具直接帮我们实现了一个消费者它就是用来读取数据的所以想要以作为数据源获取数据我们只需要引入连接器的依赖官方提供的是一个通用的连接器它会自动跟踪最新版本的客户端目前最新版本只支持版本以上的这里我们需要导入的依赖如下代码如下用保存连接的配置从数据生成器读取数据从开始提供了一个内置的连接器主要是用于生成一些随机数用于在没有数据源的时候进行流任务的测试以及性能测试等提供了新的写法需要导入依赖代码如下支持的数据类型的类型系统使用类型信息来统一表示数据类型类是中所有类型描述符的基类它涵盖了类型的一些基本属性并为每个数据类型生成特定的序列化器反序列化器和比较器支持的数据类型对于常见的和数据类型都是支持的在内部对支持不同的类型进行了划分这些类型可以在工具类中找到基本类型所有基本类型及其包装类再加上和数组类型包括基本类型数组和对象数组复合数据类型元组类型这是内置的元组类型是的一部分最多个字段也就是从不支持空字段样例类及元组不支持空字段行类型可以认为是具有任意个字段的元组并支持空字段自定义的类似于模式的类辅助类型等泛型类型支持所有的类和类不过如果没有按照上面类型的要求来定义就会被当作泛型类来处理会把泛型类型当作黑盒无法获取它们内部的属性它们也不是由本身序列化的而是由序列化的在这些类型中元组类型和类型最为灵活因为它们支持创建复杂类型而相比之下还支持在键的定义中直接使用字段名这会让我们的代码可读性大大增加所以在项目实践中往往会将流处理程序中的元素类型定为的类型对类型的要求如下类是公有的有一个无参的构造方法所有属性都是公有的所有属性的类型都是可以序列化的类型提示还具有一个类型提取系统可以分析函数的输入和返回类型自动获取类型信息从而获得对应的序列化器和反序列化器但是由于中泛型擦除的存在在某些特殊情况下比如表达式中自动提取的信息是不够精细的只告诉当前的元素由船头船身船尾构成根本无法重建出大船的模样这时就需要显式地提供类型信息才能使应用程序正常工作或提高其性能为了解决这类问题提供了专门的类型提示回忆一下之前的流处理程序我们在将类型的每个词转换成二元组后就明确地用指定了返回的类型因为对于里传入的表达式系统只能推断出返回的是类型而无法得到只有显式地告诉系统当前的返回类型才能正确地解析出完整数据还专门提供了类它可以捕获泛型的类型信息并且一直记录下来为运行时提供足够的信息我们同样可以通过方法明确地指定转换之后的里元素的类型转换算子数据源读入数据之后我们就可以使用各种转换算子将一个或多个转换为新的基本转换算子映射是大家非常熟悉的大数据操作算子主要用于将数据流中的数据进行转换形成新的数据流简单来说就是一个一一映射消费一个元素就产出一个元素我们只需要基于调用方法就可以进行转换处理方法需要传入的参数是接口的实现返回值类型还是不过泛型流中的元素类型可能改变下面的代码用不同的方式实现了提取中的字段的功能提取每次点击事件的用户名使用匿名函数实现接口上面代码中实现类的泛型类型与输入数据类型和输出数据的类型有关在实现接口的时候需要指定两个泛型分别是输入事件和输出事件的类型还需要重写一个方法定义从一个输入事件转换为另一个输出事件的具体逻辑过滤转换操作顾名思义是对数据流执行一个过滤通过一个布尔条件表达式设置过滤条件对于每一个流内元素进行判断若为则元素正常输出若为则元素被过滤掉进行转换之后的新数据流的数据类型与原数据流是相同的转换需要传入的参数需要实现接口而内要实现方法就相当于一个返回布尔类型的条件表达式案例需求下面的代码会将数据流中传感器为的数据过滤出来过滤出用户为的所有点击事件使用匿名函数实现扁平映射操作又称为扁平映射主要是将数据流中的整体一般是集合类型拆分成一个一个的个体使用消费一个元素可以产生到多个元素可以认为是扁平化和映射两步操作的结合也就是先按照某种规则对数据进行打散拆分再对拆分后的元素做转换处理同一样也可以使用表达式或者接口实现类的方式来进行传参返回值类型取决于所传参数的具体逻辑可以与原数据流相同也可以不同案例需求如果输入的数据是只打印如果输入的数据是既打印又打印实现代码如下测试灵活输出形式表达式学习自定义实现如果当前数据是的点击事件那就直接输出如果当前数据是的点击事件那么就输出和聚合算子计算的结果不仅依赖当前数据还跟之前的数据有关相当于要把所有数据聚在一起进行汇总合并这就是所谓的聚合类似于中的操作按键分区对于而言是没有直接进行聚合的的因为我们对海量数据做聚合肯定要进行分区并行处理这样才能提高效率所以在中要做聚合需要先进行分区这个操作就是通过来完成的是聚合前必须要用到的一个算子通过指定键可以将一条流从逻辑上划分成不同的分区这里所说的分区其实就是并行处理的子任务基于不同的流中的数据将被分配到不同的分区中去这样一来所有具有相同的的数据都将被发往同一个分区在内部是通过计算的哈希值对分区数进行取模运算来实现的所以这里如果是的话必须要重写方法方法需要传入一个参数这个参数指定了一个或一组有很多不同的方法来指定比如对于数据类型可以指定字段的位置或者多个位置的组合对于类型可以指定字段的名称另外还可以传入表达式或者实现一个键选择器用于说明从数据中提取的逻辑我们可以以作为做一个分区操作代码实现如下需要注意的是得到的结果将不再是而是会将转换为可以认为是分区流或者键控流它是对按照的一个逻辑分区所以泛型有两个类型除去当前流中的元素类型外还需要指定的类型也继承自所以基于它的操作也都归属于但它跟之前的转换操作得到的不同只是一个流的分区操作并不是一个转换算子是一个非常重要的数据结构只有基于它才可以做后续的聚合操作比如简单聚合有了按键分区的数据流我们就可以基于它进行聚合操作了为我们内置实现了一些最基本最简单的聚合主要有以下几种在输入流上对指定的字段做叠加求和的操作在输入流上对指定的字段求最小值在输入流上对指定的字段求最大值与类似在输入流上针对指定字段求最小值不同的是只计算指定字段的最小值其他字段会保留最初第一个数据的值而则会返回包含字段最小值的整条数据与类似在输入流上针对指定字段求最大值两者区别与完全一致简单聚合算子使用非常方便语义也非常明确这些聚合方法调用时也需要传入参数但并不像基本转换算子那样需要实现自定义函数只要说明聚合指定的字段就可以了指定字段的方式有两种指定位置和指定名称对于元组类型的数据可以使用这两种方式来指定字段需要注意的是元组中字段的名称是以来命名的如果数据流的类型是类那么就只能通过字段名称来指定不能通过位置来指定了指定字段名称简单聚合算子返回的同样是一个也就是从又转换成了常规的所以可以这样理解和聚合是成对出现的先分区后聚合得到的依然是一个而且经过简单聚合之后的数据流元素的数据类型保持不变一个聚合算子会为每一个保存一个聚合的值在中我们把它叫作状态所以每当有一个新的数据输入算子就会更新保存的聚合结果并发送一个带有更新后聚合值的事件到下游算子对于无界流来说这些状态是永远不会被清除的所以我们使用聚合算子应该只用在含有有限个的数据流上归约聚合可以对已有的数据进行归约处理把每一个新输入的数据和当前已经归约出来的值再做一个聚合计算操作也会将转换为它不会改变流的元素数据类型所以输出类型和输入类型是一样的调用的方法时需要传入一个参数实现接口接口在源码中的定义如下接口里需要实现方法这个方法接收两个输入事件经过转换处理之后输出一个相同类型的事件在流处理的底层实现过程中实际上是将中间合并的结果作为任务的一个状态保存起来的之后每来一个新的数据就和之前的聚合状态进一步做归约我们可以单独定义一个函数类实现接口也可以直接传入一个匿名类当然同样也可以通过传入表达式实现类似的功能为了方便后续使用定义一个案例使用实现和的功能归约聚合提取当前最活跃用户的作用的作用是中的一个算子用于将数据流按照指定的键进行分组分组后相同键的数据会被分配到同一个分区中的含义这里的是一个匿名函数它对每条数据返回固定的值由于所有数据的键都是因此所有数据都会被分配到同一个分区中为什么需要在统计最活跃用户时需要将所有用户的活跃度数据集中到一个分区中才能进行比较和筛选如果不使用数据会分散在多个分区中无法直接进行比较统计每个用户的活跃度将所有数据按照同样的分到同一个组中选取当前最活跃的用户同简单聚合算子一样也要针对每一个保存状态因为状态不会清空所以我们需要将算子作用在一个有限的流上用户自定义函数用户自定义函数即用户可以根据自身需求重新实现算子的逻辑用户自定义函数分为函数类匿名函数富函数类需求用来从用户的点击数据中筛选包含的内容方式一实现接口方式二通过匿名类来实现接口方式二的优化为了类可以更加通用我们还可以将用于过滤的关键字抽象出来作为类的属性调用构造方法时传进去方式三采用匿名函数测试的用法筛选中包含某个关键字的事件实现一个自定义的函数类使用匿名类使用表达式实现自定义个是指是否包含某些字段富函数类富函数类也是提供的一个函数类的接口所有的函数类都有其版本富函数类一般是以抽象类的形式出现的例如等与常规函数类的不同主要在于富函数类可以获取运行环境的上下文并拥有一些生命周期方法所以可以实现更复杂的功能有生命周期的概念典型的生命周期方法有方法是的初始化方法也就是会开启一个算子的生命周期当一个算子的实际工作方法例如或者方法被调用之前会首先被调用方法是生命周期中的最后一个调用的方法类似于结束方法一般用来做一些清理工作需要注意的是这里的生命周期方法对于一个并行子任务来说只会调用一次而对应的实际工作方法例如中的在每条数据到来后都会触发一次调用来看一个例子说明自定义一个测试复函数类的功能索引号为的任务开始索引号为的任务结束物理分区算子常见的物理分区策略有随机分配轮询分配重缩放和广播随机分区最简单的重分区方式就是直接洗牌通过调用的方法将数据随机地分配到下游算子的并行任务中去随机分区服从均匀分布所以可以把流中的数据随机打乱均匀地传递到下游任务分区因为是完全随机的所以对于同样的输入数据每次执行得到的结果也不会相同经过随机分区之后得到的依然是一个我们可以做个简单测试将数据读入之后直接打印到控制台将输出的并行度设置为中间经历一次执行多次观察结果是否相同轮询分区轮询简单来说就是发牌按照先后顺序将数据做依次分发通过调用的方法就可以实现轮询重分区使用的是负载均衡算法可以将输入流数据平均分配到下游的并行任务中去重缩放分区重缩放分区和轮询分区非常相似当调用方法时其实底层也是使用算法进行轮询但是只会将数据轮询发送到下游并行任务的一部分中的做法是分成小团体发牌人只给自己团体内的所有人轮流发牌广播这种方式其实不应该叫做重分区因为经过广播之后数据会在不同的分区都保留一份可能进行重复处理可以通过调用的方法将输入数据复制并发送到下游算子的所有并行任务中去全局分区全局分区也是一种特殊的分区方式这种做法非常极端通过调用方法会将所有的输入流数据都发送到下游算子的第一个并行子任务中去这就相当于强行让下游任务并行度变成了所以使用这个操作需要非常谨慎可能对程序造成很大的压力自定义分区当提供的所有分区策略都不能满足用户的需求时我们可以通过使用方法来自定义分区策略自定义分区器是并行度的就是并行多的标志位随机数生成器定义数据随机选择的范围关键流程用标志位作为循环的判断条件不停的发出数据为要发送的数据分配时间戳向下游直接发送水位线调用的方法向下游发送数据每隔一秒发送过一条数据使用自定义分区器读取自定义的数据流轮询重分区之后打印输出分流所谓分流就是将一条数据流拆分成完全独立的两条甚至多条流也就是基于一个定义一些筛选条件将符合条件的数据拣选出来放到对应的流里简单实现其实根据条件筛选数据的需求本身非常容易实现只要针对同一条流多次独立调用方法进行筛选就可以得到拆分之后的流了案例需求读取一个整数数字流将数据流划分为奇数流和偶数流代码实现将分为两个流一个是奇数流一个是偶数流使用过滤两次偶数奇数这种实现非常简单但代码显得有些冗余我们的处理逻辑对拆分出的三条流其实是一样的却重复写了三次而且这段代码背后的含义是将原始数据流复制三份然后对每一份分别做筛选这明显是不够高效的我们自然想到能不能不用复制流直接用一个算子就把它们都拆分开呢使用侧输出流关于处理函数中侧输出流的用法我们已经在节做了详细介绍简单来说只需要调用上下文的方法就可以输出任意类型的数据了而侧输出流的标记和提取都离不开一个输出标签指定了侧输出流的和类型代码实现将按照类型进行分流返回的都是主流主流主流非的传感器基本合流操作在实际应用中我们经常会遇到来源不同的多条流需要将它们的数据进行联合处理所以中合流的操作会更加普遍对应的也更加丰富最简单的合流操作就是直接将多条流合在一起叫作流的联合联合操作要求必须流中的数据类型必须相同合并之后的新流会包括所有流中的元素数据类型不变在代码中我们只要基于直接调用方法传入其他作为参数就可以实现流的联合了得到的依然是一个注意的参数可以是多个所以联合操作可以实现多条流的合并代码实现我们可以用下面的代码做一个简单测试连接流的联合虽然简单不过受限于数据类型不能改变灵活性大打折扣所以实际应用较少出现除了联合还提供了另外一种方便的合流操作连接连接流代码实现需要分为两步首先基于一条调用方法传入另外一条作为参数将两条流连接起来得到一个然后再调用同处理方法得到这里可以的调用的同处理方法有以及方法使用合流一次只能连接条流流的数据类型可以不一样连接后可以调用来处理但是各处理各的来源于数字流来源于字母流上面的代码中有两个类型参数分别表示内部包含的两条流各自的数据类型由于需要一国两制因此调用方法时传入的不再是一个简单的而是一个表示分别对两条流中的数据执行操作这个接口有三个类型参数依次表示第一条流第二条流以及合并后的流中的数据类型需要实现的方法也非常直白就是对第一条流中数据的操作则是针对第二条流与类似如果是调用就需要传入一个需要实现两个方法而调用时传入的则是一个它也是处理函数家族中的一员用法非常相似它需要实现的就是两个方法在每个数据到来时会根据来源的流调用其中的一个方法进行处理值得一提的是也可以直接调用进行按键分区的操作得到的还是一个这里传入两个参数和是两条流中各自的键选择器当然也可以直接传入键的位置值或者键的字段名这与普通的用法完全一致进行操作其实就是把两条流中相同的数据放到了一起然后针对来源的流再做各自处理这在一些场景下非常有用案例需求连接两条流输出能根据匹配上的数据类似效果多并行度下需要根据关联条件进行才能保证相同的数据到一起去才能匹配上定义缓存来过的数据数据来过的数据都存起来第一条数据初始化的放入不是第一条直接添加到中根据查找的数据只输出匹配上的数据来过的数据都存起来第一条数据初始化的放入不是第一条直接添加到中根据查找的数据只输出匹配上的数据输出算子作为数据处理框架最终还是要把计算处理的结果写入外部存储为外部应用提供支持连接到外部系统的专门提供了向外部写入数据的方法与类似方法对应着一个算子主要就是用来实现与外部系统连接并将数据提交写入的程序中所有对外的输出操作一般都是利用算子完成的以前算子的创建是通过调用的方法实现的方法同样需要传入一个参数实现的是接口在这个接口中只需要重写一个方法用来将指定的值写入到外部系统中这个方法在每条数据记录到来时都会调用开始同样重构了架构当然多数情况下同样并不需要我们自己实现之前我们一直在使用的方法其实就是一种它表示将数据流写入标准控制台打印输出官方为我们提供了一部分的框架的连接器如下图所示列出了官方目前支持的第三方系统连接器我们可以看到像之类流式系统提供了完美对接两端都能连接可读可写而对于等数据存储系统则只提供了输出写入的连接器除官方之外框架也实现了一些其他第三方系统与的连接器除此以外就需要用户自定义实现连接器了输出到文件专门提供了一个流式文件系统的连接器为批处理和流处理提供了一个统一的它可以将分区文件写入支持的文件系统支持行编码和批量编码格式这两种不同的方式都有各自的构建器可以直接调用的静态方法行编码批量编码实例直接以文本形式分布式的写入到文件中作用是将转成方便写入输出到添加连接器依赖由于我们已经测试过从数据源读取数据连接器相关依赖已经引入这里就不重复介绍了启动集群编写输出到的示例代码输出无的读取文件数据就是去空格讲数据写入到然后开一个消费者查看是否到数据输出到写入数据的的测试步骤如下添加依赖添加驱动官方还未提供的的正式依赖暂时从仓库下载文件中指定仓库路径添加依赖如果不生效还需要修改本地的配置文件中添加如下标红内容阿里云公共仓库启动在库下建表编写输出到的示例代码定义写入的语句运行代码用客户端连接查看是否成功写入数据自定义输出如果我们想将数据存储到我们自己的存储设备中而并没有提供可以直接使用的连接器就只能自定义进行输出了与类似为我们提供了通用的接口和对应的抽象类只要实现它通过简单地调用的方法就可以自定义写入任何外部存储在实现的时候需要重写的一个关键方法在这个方法中我们就可以实现将流里的数据发送出去的逻辑这种方式比较通用对于任何外部存储系统都有效不过自定义想要实现状态一致性并不容易所以一般只在没有其它选择时使用实际项目中用到的外部连接器官方基本都已实现而且在不断地扩充因此自定义的场景并不常见',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2025-01-14 15:38:45',
  postMainColor: '',
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
      win.saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
    
      win.getScript = (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        script.onerror = reject
        script.onload = script.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          script.onload = script.onreadystatechange = null
          resolve()
        }

        Object.keys(attr).forEach(key => {
          script.setAttribute(key, attr[key])
        })

        document.head.appendChild(script)
      })
    
      win.getCSS = (url, id = false) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onerror = reject
        link.onload = link.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          link.onload = link.onreadystatechange = null
          resolve()
        }
        document.head.appendChild(link)
      })
    
      win.activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#18171d')
        }
      }
      win.activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#f7f9fe')
        }
      }
      const t = saveToLocal.get('theme')
    
          const isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
          const isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
          const isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
          const hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

          if (t === undefined) {
            if (isLightMode) activateLightMode()
            else if (isDarkMode) activateDarkMode()
            else if (isNotSpecified || hasNoSupport) {
              const now = new Date()
              const hour = now.getHours()
              const isNight = hour <= 6 || hour >= 24
              isNight ? activateDarkMode() : activateLightMode()
            }
            window.matchMedia('(prefers-color-scheme: dark)').addListener(e => {
              if (saveToLocal.get('theme') === undefined) {
                e.matches ? activateDarkMode() : activateLightMode()
              }
            })
          } else if (t === 'light') activateLightMode()
          else activateDarkMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })(window)</script><script src="/custom/console/console.js"></script><link rel="stylesheet" href="/custom/css/tag-plugins.css" media="defer" onload="this.media='all'"><link rel="stylesheet" href="/custom/custom.css" media="defer" onload="this.media='all'"><script src="https://npm.elemecdn.com/echarts@4.9.0/dist/echarts.min.js"></script><link rel="stylesheet" href="/custom/welcome/welcome.css" media="defer" onload="this.media='all'"><script src="/custom/comm/jquery_3.6.0.min.js"></script><link rel="stylesheet" href="/css/home.css"><link rel="stylesheet" href="/css/imgloaded.css?1"><!-- hexo injector head_end start --><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/swiper/swiper-bundle.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-card-history/baiduhistory/css/main.css"><link rel="stylesheet" href="/custom/clock/clock.min.css" /><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.3.0"><link rel="alternate" href="/atom.xml" title="曦" type="application/atom+xml">
<link rel="alternate" href="/rss2.xml" title="曦" type="application/rss+xml">
</head><body data-type="anzhiyu"><div id="web_bg"></div><div id="an_music_bg"></div><div id="loading-box" onclick="document.getElementById(&quot;loading-box&quot;).classList.add(&quot;loaded&quot;)"><div class="loading-bg"><img class="loading-img nolazyload" alt="加载头像" src="/imgs/loading/loading-8.gif"/><div class="loading-image-dot"></div></div></div><script>const preloader = {
  endLoading: () => {
    document.getElementById('loading-box').classList.add("loaded");
  },
  initLoading: () => {
    document.getElementById('loading-box').classList.remove("loaded")
  }
}
window.addEventListener('load',()=> { preloader.endLoading() })
setTimeout(function(){preloader.endLoading();},10000)

if (true) {
  document.addEventListener('pjax:send', () => { preloader.initLoading() })
  document.addEventListener('pjax:complete', () => { preloader.endLoading() })
}</script><link rel="stylesheet" href="https://unpkg.com/anzhiyu-theme-static@1.1.10/progress_bar/progress_bar.css"/><script async="async" src="https://unpkg.com/pace-js@1.2.4/pace.min.js" data-pace-options="{ &quot;restartOnRequestAfter&quot;:false,&quot;eventLag&quot;:false}"></script><div class="post" id="body-wrap"><header class="post-bg" id="page-header"><nav id="nav"><div id="nav-group"><span id="blog_name"><div class="back-home-button"><i class="anzhiyufont anzhiyu-icon-grip-vertical"></i><div class="back-menu-list-groups"><div class="back-menu-list-group"><div class="back-menu-list-title">站点</div><div class="back-menu-list"><a class="back-menu-item" target="_blank" rel="noopener" href="https://blogyx.top/" title="个人主页"><img class="back-menu-item-icon" src="/imgs/avatar.webp" alt="个人主页"/><span class="back-menu-item-text">个人主页</span></a><a class="back-menu-item" target="_blank" rel="noopener" href="https://blogyx.top/" title="个人导航"><img class="back-menu-item-icon" src="/imgs/avatar.webp" alt="个人导航"/><span class="back-menu-item-text">个人导航</span></a><a class="back-menu-item" target="_blank" rel="noopener" href="https://blogyx.top/" title="博客-Hugo"><img class="back-menu-item-icon" src="/imgs/avatar.webp" alt="博客-Hugo"/><span class="back-menu-item-text">博客-Hugo</span></a><a class="back-menu-item" target="_blank" rel="noopener" href="https://blogyx.top/" title="博客-Hexo"><img class="back-menu-item-icon" src="/imgs/avatar.webp" alt="博客-Hexo"/><span class="back-menu-item-text">博客-Hexo</span></a></div></div><div class="back-menu-list-group"><div class="back-menu-list-title">常用网址</div><div class="back-menu-list"><a class="back-menu-item" target="_blank" rel="noopener" href="https://tool.lu/" title="在线工具"><img class="back-menu-item-icon" src="/imgs/avatar.webp" alt="在线工具"/><span class="back-menu-item-text">在线工具</span></a><a class="back-menu-item" target="_blank" rel="noopener" href="https://gavinblog.github.io/picx/#/upload" title="免费图床-Picx"><img class="back-menu-item-icon" src="/imgs/avatar.webp" alt="免费图床-Picx"/><span class="back-menu-item-text">免费图床-Picx</span></a></div></div><div class="back-menu-list-group"><div class="back-menu-list-title">AI大模型</div><div class="back-menu-list"><a class="back-menu-item" target="_blank" rel="noopener" href="https://chat.openai.com/" title="ChatGPT"><img class="back-menu-item-icon" src="/imgs/avatar.webp" alt="ChatGPT"/><span class="back-menu-item-text">ChatGPT</span></a><a class="back-menu-item" target="_blank" rel="noopener" href="https://blogyx.top//7flash/AutoChatGPT" title="AutoChatGPT"><img class="back-menu-item-icon" src="/imgs/avatar.webp" alt="AutoChatGPT"/><span class="back-menu-item-text">AutoChatGPT</span></a><a class="back-menu-item" target="_blank" rel="noopener" href="https://bing.com/create" title="Bing-图像创建者"><img class="back-menu-item-icon" src="/imgs/avatar.webp" alt="Bing-图像创建者"/><span class="back-menu-item-text">Bing-图像创建者</span></a><a class="back-menu-item" target="_blank" rel="noopener" href="https://stablediffusionweb.com/" title="Stable Diffusion Online"><img class="back-menu-item-icon" src="/imgs/avatar.webp" alt="Stable Diffusion Online"/><span class="back-menu-item-text">Stable Diffusion Online</span></a><a class="back-menu-item" target="_blank" rel="noopener" href="https://yiyan.baidu.com/" title="文心一言"><img class="back-menu-item-icon" src="/imgs/avatar.webp" alt="文心一言"/><span class="back-menu-item-text">文心一言</span></a><a class="back-menu-item" target="_blank" rel="noopener" href="https://yige.baidu.com/" title="文心一格"><img class="back-menu-item-icon" src="/imgs/avatar.webp" alt="文心一格"/><span class="back-menu-item-text">文心一格</span></a><a class="back-menu-item" target="_blank" rel="noopener" href="https://xinghuo.xfyun.cn/" title="讯飞星火"><img class="back-menu-item-icon" src="/imgs/avatar.webp" alt="讯飞星火"/><span class="back-menu-item-text">讯飞星火</span></a></div></div></div></div><a id="site-name" href="/" accesskey="h"><div class="title">曦</div><i class="anzhiyufont anzhiyu-icon-house-chimney"></i></a></span><div class="mask-name-container"><div id="name-container"><a id="page-name" href="javascript:anzhiyu.scrollToDest(0, 500)">PAGE_NAME</a></div></div><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page faa-parent animated-hover" target="_blank" rel="noopener" href="https://blogyx.top/"><span> 🏠</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><span> 博客</span></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/archives/"><i class="anzhiyufont anzhiyu-icon-box-archive faa-tada" style="font-size: 0.9em;"></i><span> 文章</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/categories/"><i class="anzhiyufont anzhiyu-icon-shapes faa-tada" style="font-size: 0.9em;"></i><span> 分类</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/tags/"><i class="anzhiyufont anzhiyu-icon-tags faa-tada" style="font-size: 0.9em;"></i><span> 标签</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/charts/"><i class="fa-solid fa-chart-pie fa-spin faa-tada"></i><span> 统计</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/anzhiyu-docs/"><i class="anzhiyufont anzhiyu-icon-book faa-tada" style="font-size: 0.9em;"></i><span> 文档</span></a></li><li><a class="site-page child faa-parent animated-hover" target="_blank" rel="noopener" href="https://blogyx.top/"><i class="anzhiyufont anzhiyu-icon-link faa-tada" style="font-size: 0.9em;"></i><span> 博客-Hugo</span></a></li><li><a class="site-page child faa-parent animated-hover" target="_blank" rel="noopener" href="https://blogyx.top/"><i class="anzhiyufont anzhiyu-icon-link faa-tada" style="font-size: 0.9em;"></i><span> 博客-Hexo</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><span> 我的</span></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/link/"><i class="anzhiyufont anzhiyu-icon-link faa-tada" style="font-size: 0.9em;"></i><span> 友人帐</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/fcircle/"><i class="anzhiyufont anzhiyu-icon-artstation faa-tada" style="font-size: 0.9em;"></i><span> 朋友圈</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/guestbook/"><i class="anzhiyufont anzhiyu-icon-envelope faa-tada" style="font-size: 0.9em;"></i><span> 留言板</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/essay/"><i class="anzhiyufont anzhiyu-icon-lightbulb faa-tada" style="font-size: 0.9em;"></i><span> 说说</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/album/"><i class="anzhiyufont anzhiyu-icon-images faa-tada" style="font-size: 0.9em;"></i><span> 相册集</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/air-condition/"><i class="anzhiyufont anzhiyu-icon-fan faa-tada" style="font-size: 0.9em;"></i><span> 小空调</span></a></li></ul></div><div class="menus_item"><a class="site-page faa-parent animated-hover" href="/music/?id=8138088068&amp;server=tencent"><span> 音乐</span></a></div><div class="menus_item"><a class="site-page faa-parent animated-hover" href="/sites/all-sites"><span> 🌐</span></a></div><div class="menus_item"><a class="site-page faa-parent animated-hover" href="/about/"><span> 🧑‍💻</span></a></div></div></div><div id="nav-right"><div class="nav-button only-home" id="travellings_button" title="随机前往一个开往项目网站"><a class="site-page" onclick="anzhiyu.totraveling()" title="随机前往一个开往项目网站" href="javascript:void(0);" rel="external nofollow" data-pjax-state="external"><i class="anzhiyufont anzhiyu-icon-train"></i></a></div><div class="nav-button" id="randomPost_button"><a class="site-page" onclick="toRandomPost()" title="随机前往一个文章" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-dice"></i></a></div><div class="nav-button" id="search-button"><a class="site-page social-icon search" href="javascript:void(0);" title="搜索🔍" accesskey="s"><i class="anzhiyufont anzhiyu-icon-magnifying-glass"></i><span> 搜索</span></a></div><input id="center-console" type="checkbox"/><label class="widget" for="center-console" title="中控台" onclick="anzhiyu.switchConsole();"><i class="left"></i><i class="widget center"></i><i class="widget right"></i></label><div id="console"><div class="console-card-group-reward"><ul class="reward-all console-card"><li class="reward-item"><a href="https://blogyx.top/" target="_blank"><img class="post-qr-code-img" alt="alipay" src="/imgs/reward/alipay.webp"/></a><div class="post-qr-code-desc">alipay</div></li><li class="reward-item"><a href="https://blogyx.top/" target="_blank"><img class="post-qr-code-img" alt="wechat" src="/imgs/reward/wechat.webp"/></a><div class="post-qr-code-desc">wechat</div></li></ul></div><div class="console-card-group"><div class="console-card-group-left"><div class="console-card" id="card-newest-comments"><div class="card-content"><div class="author-content-item-tips">互动</div><span class="author-content-item-title"> 最新评论</span></div><div class="aside-list"><span>正在加载中...</span></div></div></div><div class="console-card-group-right"><div class="console-card tags"><div class="card-content"><div class="author-content-item-tips">音乐</div><span class="author-content-item-title">灵魂的碰撞💥</span></div></div><div class="console-card history"><div class="item-headline"><i class="anzhiyufont anzhiyu-icon-box-archiv"></i><span>文章</span></div></div></div></div><div class="button-group"><div class="console-btn-item"><a class="darkmode_switchbutton" title="显示模式切换" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-moon"></i></a></div><div class="console-btn-item" id="consoleHideAside" onclick="anzhiyu.hideAsideBtn()" title="边栏显示控制"><a class="asideSwitch"><i class="anzhiyufont anzhiyu-icon-arrows-left-right"></i></a></div><div class="console-btn-item on" id="consoleCommentBarrage" onclick="anzhiyu.switchCommentBarrage()" title="热评开关"><a class="commentBarrage"><i class="anzhiyufont anzhiyu-icon-message"></i></a></div><div class="console-btn-item" id="consoleMusic" onclick="anzhiyu.musicToggle()" title="音乐开关"><a class="music-switch"><i class="anzhiyufont anzhiyu-icon-music"></i></a></div><div class="console-btn-item" id="consoleKeyboard" onclick="anzhiyu.keyboardToggle()" title="快捷键开关"><a class="keyboard-switch"><i class="anzhiyufont anzhiyu-icon-keyboard"></i></a></div></div><div class="console-mask" onclick="anzhiyu.hideConsole()" href="javascript:void(0);"></div></div><div class="nav-button" id="nav-totop"><a class="totopbtn" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-arrow-up"></i><span id="percent" onclick="anzhiyu.scrollToDest(0,500)">0</span></a></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);" title="切换"><i class="anzhiyufont anzhiyu-icon-bars"></i></a></div></div></div></nav><div id="post-info"><div id="post-firstinfo"><div class="meta-firstline"><a class="post-meta-original">原创</a><span class="post-meta-categories"><span class="post-meta-separator"></span><i class="anzhiyufont anzhiyu-icon-inbox post-meta-icon"></i><a class="post-meta-categories" href="/categories/Flink/" itemprop="url">Flink</a></span><span class="article-meta tags"><a class="article-meta__tags" href="/tags/%E7%A4%BA%E4%BE%8B/" tabindex="-1" itemprop="url"> <span> <i class="anzhiyufont anzhiyu-icon-hashtag"></i>示例</span></a><a class="article-meta__tags" href="/tags/Flink/" tabindex="-1" itemprop="url"> <span> <i class="anzhiyufont anzhiyu-icon-hashtag"></i>Flink</span></a></span></div></div><h1 class="post-title" itemprop="name headline">Flink的DataStreamAPI</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="anzhiyufont anzhiyu-icon-calendar-days post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" itemprop="dateCreated datePublished" datetime="2025-01-14T07:38:45.000Z" title="发表于 2025-01-14 15:38:45">2025-01-14</time><span class="post-meta-separator"></span><i class="anzhiyufont anzhiyu-icon-history post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" itemprop="dateCreated datePublished" datetime="2025-01-14T07:38:45.000Z" title="更新于 2025-01-14 15:38:45">2025-01-14</time></span></div><div class="meta-secondline"><span class="post-meta-separator"></span><span class="post-meta-wordcount"><i class="anzhiyufont anzhiyu-icon-file-word post-meta-icon" title="文章字数"></i><span class="post-meta-label" title="文章字数">字数总计:</span><span class="word-count" title="文章字数">11.9k</span><span class="post-meta-separator"></span><i class="anzhiyufont anzhiyu-icon-clock post-meta-icon" title="阅读时长"></i><span class="post-meta-label" title="阅读时长">阅读时长:</span><span>48分钟</span></span><span class="post-meta-separator"></span><span id="" data-flag-title="Flink的DataStreamAPI"><i class="anzhiyufont anzhiyu-icon-fw-eye post-meta-icon"></i><span class="post-meta-label" title="阅读量">阅读量:</span><span id="twikoo_visitors" title="访问量"><i class="anzhiyufont anzhiyu-icon-spinner anzhiyu-spin"></i></span></span><span class="post-meta-separator">       </span><span class="post-meta-position" title="作者IP属地为神州大地"><i class="anzhiyufont anzhiyu-icon-location-dot"></i>神州大地</span><span class="post-meta-separator"></span><span class="post-meta-commentcount"><i class="anzhiyufont anzhiyu-icon-comments post-meta-icon"></i><span class="post-meta-label">评论数:</span><a href="/posts/pd14.html#post-comment" tabindex="-1"><span id="twikoo-count"><i class="anzhiyufont anzhiyu-icon-spinner anzhiyu-spin"></i></span></a></span></div></div></div><section class="main-hero-waves-area waves-area"><svg class="waves-svg" xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink" viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto"><defs><path id="gentle-wave" d="M -160 44 c 30 0 58 -18 88 -18 s 58 18 88 18 s 58 -18 88 -18 s 58 18 88 18 v 44 h -352 Z"></path></defs><g class="parallax"><use href="#gentle-wave" x="48" y="0"></use><use href="#gentle-wave" x="48" y="3"></use><use href="#gentle-wave" x="48" y="5"></use><use href="#gentle-wave" x="48" y="7"></use></g></svg></section><div id="post-top-cover"><img class="nolazyload" id="post-top-bg" src="https://pic1.imgdb.cn/item/6784bd24d0e0a243d4f3d4a3.png?_r_=c31f22a8-5d93-17a1-e2f3-b175d5805f0e"></div></header><main id="blog-container"><div class="layout" id="content-inner"><div id="post"><div class="post-ai-description"><div class="ai-title"><i class="anzhiyufont anzhiyu-icon-bilibili"></i><div class="ai-title-text">AI-摘要</div><i class="anzhiyufont anzhiyu-icon-arrow-rotate-right"></i><i class="anzhiyufont anzhiyu-icon-circle-dot" title="朗读摘要"></i><div id="ai-tag">Geek GPT</div></div><div class="ai-explanation">AI初始化中...</div><div class="ai-btn-box"><div class="ai-btn-item">介绍自己 🙈</div><div class="ai-btn-item">生成本文简介 👋</div><div class="ai-btn-item">推荐相关文章 📖</div><div class="ai-btn-item">前往主页 🏠</div><div class="ai-btn-item" id="go-tianli-blog">前往爱发电购买</div></div><script data-pjax src="/js/anzhiyu/ai_abstract.js"></script></div><article class="post-content" id="article-container" itemscope itemtype="https://bigdata-yx.github.io/posts/pd14.html"><header><a class="post-meta-categories" href="/categories/Flink/" itemprop="url">Flink</a><a href="/tags/%E7%A4%BA%E4%BE%8B/" tabindex="-1" itemprop="url">示例</a><a href="/tags/Flink/" tabindex="-1" itemprop="url">Flink</a><h1 id="CrawlerTitle" itemprop="name headline">Flink的DataStreamAPI</h1><span itemprop="author" itemscope itemtype="http://schema.org/Person">曦</span><time itemprop="dateCreated datePublished" datetime="2025-01-14T07:38:45.000Z" title="发表于 2025-01-14 15:38:45">2025-01-14</time><time itemprop="dateCreated datePublished" datetime="2025-01-14T07:38:45.000Z" title="更新于 2025-01-14 15:38:45">2025-01-14</time></header><h5 id="DataStream-API是Flink的核心层API。一个Flink程序，其实就是对DataStream的各种转换。具体来说，代码基本上都由以下几部分构成："><a href="#DataStream-API是Flink的核心层API。一个Flink程序，其实就是对DataStream的各种转换。具体来说，代码基本上都由以下几部分构成：" class="headerlink" title="DataStream API是Flink的核心层API。一个Flink程序，其实就是对DataStream的各种转换。具体来说，代码基本上都由以下几部分构成："></a>DataStream API是Flink的核心层API。一个Flink程序，其实就是对DataStream的各种转换。具体来说，代码基本上都由以下几部分构成：</h5><p><img src= "/imgs/loading/loading.gif" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://pic1.imgdb.cn/item/67861fbed0e0a243d4f42964.png"></p>
<h5 id="在Flink1-12以前，旧的添加source的方式，是调用执行环境的addSource-方法："><a href="#在Flink1-12以前，旧的添加source的方式，是调用执行环境的addSource-方法：" class="headerlink" title="在Flink1.12以前，旧的添加source的方式，是调用执行环境的addSource()方法："></a>在Flink1.12以前，旧的添加source的方式，是调用执行环境的addSource()方法：</h5><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">DataStream</span>&lt;<span class="type">String</span>&gt; stream = env.addSource(...);</span><br></pre></td></tr></table></figure>

<h5 id="方法传入的参数是一个“源函数”（source-function），需要实现SourceFunction接口。"><a href="#方法传入的参数是一个“源函数”（source-function），需要实现SourceFunction接口。" class="headerlink" title="方法传入的参数是一个“源函数”（source function），需要实现SourceFunction接口。"></a>方法传入的参数是一个“源函数”（source function），需要实现SourceFunction接口。</h5><h5 id="从Flink1-12开始，主要使用流批统一的新Source架构："><a href="#从Flink1-12开始，主要使用流批统一的新Source架构：" class="headerlink" title="从Flink1.12开始，主要使用流批统一的新Source架构："></a>从Flink1.12开始，主要使用流批统一的新Source架构：</h5><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">DataStreamSource</span>&lt;<span class="type">String</span>&gt; stream = env.fromSource(…)</span><br></pre></td></tr></table></figure>

<h5 id="Flink直接提供了很多预实现的接口，此外还有很多外部连接工具也帮我们实现了对应的Source，通常情况下足以应对我们的实际需求。"><a href="#Flink直接提供了很多预实现的接口，此外还有很多外部连接工具也帮我们实现了对应的Source，通常情况下足以应对我们的实际需求。" class="headerlink" title="Flink直接提供了很多预实现的接口，此外还有很多外部连接工具也帮我们实现了对应的Source，通常情况下足以应对我们的实际需求。"></a>Flink直接提供了很多预实现的接口，此外还有很多外部连接工具也帮我们实现了对应的Source，通常情况下足以应对我们的实际需求。</h5><h2 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作:"></a>准备工作:</h2><h5 id="为了方便练习，这里使用WaterSensor作为数据模型。"><a href="#为了方便练习，这里使用WaterSensor作为数据模型。" class="headerlink" title="为了方便练习，这里使用WaterSensor作为数据模型。"></a>为了方便练习，这里使用WaterSensor作为数据模型。</h5><table>
<thead>
<tr>
<th><strong>id</strong></th>
<th><strong>String</strong></th>
<th><strong>水位传感器类型</strong></th>
</tr>
</thead>
<tbody><tr>
<td><strong>ts</strong></td>
<td><strong>Long</strong></td>
<td><strong>传感器记录时间戳</strong></td>
</tr>
<tr>
<td><strong>vc</strong></td>
<td><strong>Integer</strong></td>
<td><strong>水位记录</strong></td>
</tr>
</tbody></table>
<h4 id="具体代码如下："><a href="#具体代码如下：" class="headerlink" title="具体代码如下："></a>具体代码如下：</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">WaterSensor</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> String id;</span><br><span class="line">    <span class="keyword">public</span> Long ts;</span><br><span class="line">    <span class="keyword">public</span> Integer vc;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">WaterSensor</span><span class="params">()</span> &#123;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">WaterSensor</span><span class="params">(String id, Long ts, Integer vc)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.id = id;</span><br><span class="line">        <span class="built_in">this</span>.ts = ts;</span><br><span class="line">        <span class="built_in">this</span>.vc = vc;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">getId</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> id;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setId</span><span class="params">(String id)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.id = id;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> Long <span class="title function_">getTs</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> ts;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setTs</span><span class="params">(Long ts)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.ts = ts;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> Integer <span class="title function_">getVc</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> vc;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setVc</span><span class="params">(Integer vc)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.vc = vc;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">toString</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;WaterSensor&#123;&quot;</span> +</span><br><span class="line">                <span class="string">&quot;id=&#x27;&quot;</span> + id + <span class="string">&#x27;\&#x27;&#x27;</span> +</span><br><span class="line">                <span class="string">&quot;, ts=&quot;</span> + ts +</span><br><span class="line">                <span class="string">&quot;, vc=&quot;</span> + vc +</span><br><span class="line">                <span class="string">&#x27;&#125;&#x27;</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">boolean</span> <span class="title function_">equals</span><span class="params">(Object o)</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (<span class="built_in">this</span> == o) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (o == <span class="literal">null</span> || getClass() != o.getClass()) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="type">WaterSensor</span> <span class="variable">that</span> <span class="operator">=</span> (WaterSensor) o;</span><br><span class="line">        <span class="keyword">return</span> Objects.equals(id, that.id) &amp;&amp;</span><br><span class="line">                Objects.equals(ts, that.ts) &amp;&amp;</span><br><span class="line">                Objects.equals(vc, that.vc);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">hashCode</span><span class="params">()</span> &#123;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> Objects.hash(id, ts, vc);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="这里需要注意，我们定义的WaterSensor，有这样几个特点："><a href="#这里需要注意，我们定义的WaterSensor，有这样几个特点：" class="headerlink" title="这里需要注意，我们定义的WaterSensor，有这样几个特点："></a>这里需要注意，我们定义的WaterSensor，有这样几个特点：</h4><ul>
<li>类是公有（public）的</li>
<li>有一个无参的构造方法</li>
<li>所有属性都是公有（public）的</li>
<li>所有属性的类型都是可以序列化的</li>
</ul>
<h6 id="Flink会把这样的类作为一种特殊的POJO（Plain-Ordinary-Java-Object简单的Java对象，实际就是普通JavaBeans）数据类型来对待，方便数据的解析和序列化。另外我们在类中还重写了toString方法，主要是为了测试输出显示更清晰。"><a href="#Flink会把这样的类作为一种特殊的POJO（Plain-Ordinary-Java-Object简单的Java对象，实际就是普通JavaBeans）数据类型来对待，方便数据的解析和序列化。另外我们在类中还重写了toString方法，主要是为了测试输出显示更清晰。" class="headerlink" title="Flink会把这样的类作为一种特殊的POJO（Plain Ordinary Java Object简单的Java对象，实际就是普通JavaBeans）数据类型来对待，方便数据的解析和序列化。另外我们在类中还重写了toString方法，主要是为了测试输出显示更清晰。"></a>Flink会把这样的类作为一种特殊的POJO（Plain Ordinary Java Object简单的Java对象，实际就是普通JavaBeans）数据类型来对待，方便数据的解析和序列化。另外我们在类中还重写了toString方法，主要是为了测试输出显示更清晰。</h6><h6 id="我们这里自定义的POJO类会在后面的代码中频繁使用，所以在后面的代码中碰到，把这里的POJO类导入就好了。"><a href="#我们这里自定义的POJO类会在后面的代码中频繁使用，所以在后面的代码中碰到，把这里的POJO类导入就好了。" class="headerlink" title="我们这里自定义的POJO类会在后面的代码中频繁使用，所以在后面的代码中碰到，把这里的POJO类导入就好了。"></a>我们这里自定义的POJO类会在后面的代码中频繁使用，所以在后面的代码中碰到，把这里的POJO类导入就好了。</h6><h3 id="1-从集合、文件、元素中读取数据"><a href="#1-从集合、文件、元素中读取数据" class="headerlink" title="1.从集合、文件、元素中读取数据"></a>1.从集合、文件、元素中读取数据</h3><h5 id="最简单的读取数据的方式，就是在代码中直接创建一个Java集合，然后调用执行环境的fromCollection方法进行读取。这相当于将数据临时存储到内存中，形成特殊的数据结构后，作为数据源使用，一般用于测试。"><a href="#最简单的读取数据的方式，就是在代码中直接创建一个Java集合，然后调用执行环境的fromCollection方法进行读取。这相当于将数据临时存储到内存中，形成特殊的数据结构后，作为数据源使用，一般用于测试。" class="headerlink" title="最简单的读取数据的方式，就是在代码中直接创建一个Java集合，然后调用执行环境的fromCollection方法进行读取。这相当于将数据临时存储到内存中，形成特殊的数据结构后，作为数据源使用，一般用于测试。"></a>最简单的读取数据的方式，就是在代码中直接创建一个Java集合，然后调用执行环境的fromCollection方法进行读取。这相当于将数据临时存储到内存中，形成特殊的数据结构后，作为数据源使用，一般用于测试。</h5><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.day02</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.scala._</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">SourceBoundedTest</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">Event</span>(<span class="params">user: <span class="type">String</span>, url: <span class="type">String</span>, timestamp: <span class="type">Long</span></span>)</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> env = <span class="type">StreamExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 从元素中读取数据</span></span><br><span class="line"><span class="comment">//    val stream: DataStream[Int] = env.fromElements(1, 2, 3, 4, 5, 6)</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> stream: <span class="type">DataStream</span>[<span class="type">Event</span>] = env.fromElements(</span><br><span class="line">      <span class="type">Event</span>(<span class="string">&quot;hkj&quot;</span>, <span class="string">&quot;www.baidu.com&quot;</span>, <span class="number">1000</span>L),</span><br><span class="line">      <span class="type">Event</span>(<span class="string">&quot;Bob&quot;</span>, <span class="string">&quot;www.bing.com&quot;</span>, <span class="number">2000</span>L)</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 从集合中读取数据</span></span><br><span class="line">    <span class="keyword">val</span> clicks = <span class="type">List</span>(</span><br><span class="line">      <span class="type">Event</span>(<span class="string">&quot;hkj&quot;</span>, <span class="string">&quot;www.baidu.com&quot;</span>, <span class="number">1000</span>L),</span><br><span class="line">      <span class="type">Event</span>(<span class="string">&quot;Bob&quot;</span>, <span class="string">&quot;www.bing.com&quot;</span>, <span class="number">2000</span>L)</span><br><span class="line">    )</span><br><span class="line">    <span class="keyword">val</span> stream2: <span class="type">DataStream</span>[<span class="type">Event</span>] = env.fromCollection(clicks)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 从文件中读取数据</span></span><br><span class="line">    <span class="keyword">val</span> stream3: <span class="type">DataStream</span>[<span class="type">String</span>] = env.readTextFile(<span class="string">&quot;G:\\Flink学习\\FlinkStu\\data\\click.txt&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 打印输出</span></span><br><span class="line">    stream.print(<span class="string">&quot;从元素中&quot;</span>).setParallelism(<span class="number">1</span>)</span><br><span class="line">    stream2.print(<span class="string">&quot;从集合中&quot;</span>).setParallelism(<span class="number">1</span>)</span><br><span class="line">    stream3.print(<span class="string">&quot;从文件中&quot;</span>).setParallelism(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    env.execute()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h3 id="1-2从Socket读取数据"><a href="#1-2从Socket读取数据" class="headerlink" title="1.2从Socket读取数据"></a>1.2从Socket读取数据</h3><ul>
<li><h6 id="不论从集合还是文件，我们读取的其实都是有界数据。在流处理的场景中，数据往往是无界的。"><a href="#不论从集合还是文件，我们读取的其实都是有界数据。在流处理的场景中，数据往往是无界的。" class="headerlink" title="不论从集合还是文件，我们读取的其实都是有界数据。在流处理的场景中，数据往往是无界的。"></a>不论从集合还是文件，我们读取的其实都是有界数据。在流处理的场景中，数据往往是无界的。</h6></li>
<li><h6 id="我们之前用到的读取socket文本流，就是流处理场景。但是这种方式由于吞吐量小、稳定性较差，一般也是用于测试。"><a href="#我们之前用到的读取socket文本流，就是流处理场景。但是这种方式由于吞吐量小、稳定性较差，一般也是用于测试。" class="headerlink" title="我们之前用到的读取socket文本流，就是流处理场景。但是这种方式由于吞吐量小、稳定性较差，一般也是用于测试。"></a>我们之前用到的读取socket文本流，就是流处理场景。但是这种方式由于吞吐量小、稳定性较差，一般也是用于测试。</h6></li>
</ul>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">DataStream</span>&lt;<span class="type">String</span>&gt; stream = env.socketTextStream(<span class="string">&quot;localhost&quot;</span>, <span class="number">7777</span>);</span><br></pre></td></tr></table></figure>



<h3 id="1-3从Kafka中读取数据"><a href="#1-3从Kafka中读取数据" class="headerlink" title="1.3从Kafka中读取数据"></a>1.3从Kafka中读取数据</h3><ul>
<li><h6 id="Flink官方提供了连接工具flink-connector-kafka，直接帮我们实现了一个消费者FlinkKafkaConsumer，它就是用来读取Kafka数据的SourceFunction。"><a href="#Flink官方提供了连接工具flink-connector-kafka，直接帮我们实现了一个消费者FlinkKafkaConsumer，它就是用来读取Kafka数据的SourceFunction。" class="headerlink" title="Flink官方提供了连接工具flink-connector-kafka，直接帮我们实现了一个消费者FlinkKafkaConsumer，它就是用来读取Kafka数据的SourceFunction。"></a>Flink官方提供了连接工具flink-connector-kafka，直接帮我们实现了一个消费者FlinkKafkaConsumer，它就是用来读取Kafka数据的SourceFunction。</h6></li>
<li><h6 id="所以想要以Kafka作为数据源获取数据，我们只需要引入Kafka连接器的依赖。Flink官方提供的是一个通用的Kafka连接器，它会自动跟踪最新版本的Kafka客户端。目前最新版本只支持0-10-0版本以上的Kafka。这里我们需要导入的依赖如下。"><a href="#所以想要以Kafka作为数据源获取数据，我们只需要引入Kafka连接器的依赖。Flink官方提供的是一个通用的Kafka连接器，它会自动跟踪最新版本的Kafka客户端。目前最新版本只支持0-10-0版本以上的Kafka。这里我们需要导入的依赖如下。" class="headerlink" title="所以想要以Kafka作为数据源获取数据，我们只需要引入Kafka连接器的依赖。Flink官方提供的是一个通用的Kafka连接器，它会自动跟踪最新版本的Kafka客户端。目前最新版本只支持0.10.0版本以上的Kafka。这里我们需要导入的依赖如下。"></a>所以想要以Kafka作为数据源获取数据，我们只需要引入Kafka连接器的依赖。Flink官方提供的是一个通用的Kafka连接器，它会自动跟踪最新版本的Kafka客户端。目前最新版本只支持0.10.0版本以上的Kafka。这里我们需要导入的依赖如下。</h6></li>
</ul>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-connector-kafka<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;flink.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h3 id="代码如下："><a href="#代码如下：" class="headerlink" title="代码如下："></a>代码如下：</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.day02</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.serialization.<span class="type">SimpleStringSchema</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.scala._</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.connectors.kafka.<span class="type">FlinkKafkaConsumer</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.<span class="type">Properties</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">SourceKafkaTest</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> env = <span class="type">StreamExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line">    env.setParallelism(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 用Properties保存kafka连接的配置</span></span><br><span class="line">    <span class="keyword">val</span> properties = <span class="keyword">new</span> <span class="type">Properties</span>()</span><br><span class="line"></span><br><span class="line">    properties.setProperty(<span class="string">&quot;bootstrap.servers&quot;</span>, <span class="string">&quot;master:9092&quot;</span>)</span><br><span class="line">    properties.setProperty(<span class="string">&quot;group.id&quot;</span>, <span class="string">&quot;consumer-group&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> stream: <span class="type">DataStream</span>[<span class="type">String</span>] = &#123;</span><br><span class="line">      env.addSource(<span class="keyword">new</span> <span class="type">FlinkKafkaConsumer</span>[<span class="type">String</span>](<span class="string">&quot;hkjcpdd&quot;</span>, <span class="keyword">new</span> <span class="type">SimpleStringSchema</span>(), properties))</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    stream.print()</span><br><span class="line"></span><br><span class="line">    env.execute()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="1-4-从数据生成器读取数据"><a href="#1-4-从数据生成器读取数据" class="headerlink" title="1.4 从数据生成器读取数据"></a>1.4 从数据生成器读取数据</h3><h6 id="Flink从1-11开始提供了一个内置的DataGen-连接器，主要是用于生成一些随机数，用于在没有数据源的时候，进行流任务的测试以及性能测试等。1-17提供了新的Source写法，需要导入依赖："><a href="#Flink从1-11开始提供了一个内置的DataGen-连接器，主要是用于生成一些随机数，用于在没有数据源的时候，进行流任务的测试以及性能测试等。1-17提供了新的Source写法，需要导入依赖：" class="headerlink" title="Flink从1.11开始提供了一个内置的DataGen 连接器，主要是用于生成一些随机数，用于在没有数据源的时候，进行流任务的测试以及性能测试等。1.17提供了新的Source写法，需要导入依赖："></a>Flink从1.11开始提供了一个内置的DataGen 连接器，主要是用于生成一些随机数，用于在没有数据源的时候，进行流任务的测试以及性能测试等。1.17提供了新的Source写法，需要导入依赖：</h6><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-connector-datagen<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;flink.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h3 id="代码如下：-1"><a href="#代码如下：-1" class="headerlink" title="代码如下："></a>代码如下：</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">DataGeneratorDemo</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line"></span><br><span class="line">        <span class="type">StreamExecutionEnvironment</span> <span class="variable">env</span> <span class="operator">=</span> StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line">        env.setParallelism(<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">        DataGeneratorSource&lt;String&gt; dataGeneratorSource =</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">DataGeneratorSource</span>&lt;&gt;(</span><br><span class="line">                        <span class="keyword">new</span> <span class="title class_">GeneratorFunction</span>&lt;Long, String&gt;() &#123;</span><br><span class="line">                            <span class="meta">@Override</span></span><br><span class="line">                            <span class="keyword">public</span> String <span class="title function_">map</span><span class="params">(Long value)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">                                <span class="keyword">return</span> <span class="string">&quot;Number:&quot;</span>+value;</span><br><span class="line">                            &#125;</span><br><span class="line">                        &#125;,</span><br><span class="line">                        Long.MAX_VALUE,</span><br><span class="line">                        RateLimiterStrategy.perSecond(<span class="number">10</span>),</span><br><span class="line">                        Types.STRING</span><br><span class="line">                );</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        env</span><br><span class="line">                .fromSource(dataGeneratorSource, WatermarkStrategy.noWatermarks(), <span class="string">&quot;datagenerator&quot;</span>)</span><br><span class="line">                .print();</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        env.execute();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h3 id="1-5Flink支持的数据类型"><a href="#1-5Flink支持的数据类型" class="headerlink" title="1.5Flink支持的数据类型"></a>1.5Flink支持的数据类型</h3><ol>
<li><h5 id="Flink的类型系统"><a href="#Flink的类型系统" class="headerlink" title="Flink的类型系统"></a>Flink的类型系统</h5><p>Flink使用“类型信息”（TypeInformation）来统一表示数据类型。TypeInformation类是Flink中所有类型描述符的基类。它涵盖了类型的一些基本属性，并为每个数据类型生成特定的序列化器、反序列化器和比较器。</p>
</li>
<li><h5 id="Flink支持的数据类型"><a href="#Flink支持的数据类型" class="headerlink" title="Flink支持的数据类型"></a>Flink支持的数据类型</h5><p>对于常见的Java和Scala数据类型，Flink都是支持的。Flink在内部，Flink对支持不同的类型进行了划分，这些类型可以在Types工具类中找到：</p>
</li>
</ol>
<ul>
<li><h5 id="（1）基本类型"><a href="#（1）基本类型" class="headerlink" title="（1）基本类型"></a>（1）基本类型</h5><p>所有Java基本类型及其包装类，再加上Void、String、Date、BigDecimal和BigInteger。</p>
</li>
<li><h5 id="（2）数组类型"><a href="#（2）数组类型" class="headerlink" title="（2）数组类型"></a>（2）数组类型</h5><p>包括基本类型数组（PRIMITIVE_ARRAY）和对象数组（OBJECT_ARRAY）。</p>
</li>
<li><h5 id="（3）复合数据类型"><a href="#（3）复合数据类型" class="headerlink" title="（3）复合数据类型"></a>（3）复合数据类型</h5><ol>
<li><p>Java元组类型（TUPLE）：这是Flink内置的元组类型，是Java API的一部分。最多25个字段，也就是从Tuple0~Tuple25，不支持空字段。</p>
</li>
<li><h5 id="Scala-样例类及Scala元组：不支持空字段。"><a href="#Scala-样例类及Scala元组：不支持空字段。" class="headerlink" title="Scala 样例类及Scala元组：不支持空字段。"></a>Scala 样例类及Scala元组：不支持空字段。</h5></li>
<li><h5 id="行类型（ROW）：可以认为是具有任意个字段的元组，并支持空字段。"><a href="#行类型（ROW）：可以认为是具有任意个字段的元组，并支持空字段。" class="headerlink" title="行类型（ROW）：可以认为是具有任意个字段的元组，并支持空字段。"></a>行类型（ROW）：可以认为是具有任意个字段的元组，并支持空字段。</h5></li>
<li><h5 id="POJO：Flink自定义的类似于Java-bean模式的类。"><a href="#POJO：Flink自定义的类似于Java-bean模式的类。" class="headerlink" title="POJO：Flink自定义的类似于Java bean模式的类。"></a>POJO：Flink自定义的类似于Java bean模式的类。</h5></li>
</ol>
</li>
</ul>
<h4 id="（4）辅助类型"><a href="#（4）辅助类型" class="headerlink" title="（4）辅助类型"></a>（4）辅助类型</h4><ul>
<li><h5 id="Option、Either、List、Map等。"><a href="#Option、Either、List、Map等。" class="headerlink" title="Option、Either、List、Map等。"></a>Option、Either、List、Map等。</h5></li>
</ul>
<h4 id="（5）泛型类型（GENERIC）"><a href="#（5）泛型类型（GENERIC）" class="headerlink" title="（5）泛型类型（GENERIC）"></a>（5）泛型类型（GENERIC）</h4><ul>
<li><h6 id="Flink支持所有的Java类和Scala类。不过如果没有按照上面POJO类型的要求来定义，就会被Flink当作泛型类来处理。Flink会把泛型类型当作黑盒，无法获取它们内部的属性；它们也不是由Flink本身序列化的，而是由Kryo序列化的。"><a href="#Flink支持所有的Java类和Scala类。不过如果没有按照上面POJO类型的要求来定义，就会被Flink当作泛型类来处理。Flink会把泛型类型当作黑盒，无法获取它们内部的属性；它们也不是由Flink本身序列化的，而是由Kryo序列化的。" class="headerlink" title="Flink支持所有的Java类和Scala类。不过如果没有按照上面POJO类型的要求来定义，就会被Flink当作泛型类来处理。Flink会把泛型类型当作黑盒，无法获取它们内部的属性；它们也不是由Flink本身序列化的，而是由Kryo序列化的。"></a>Flink支持所有的Java类和Scala类。不过如果没有按照上面POJO类型的要求来定义，就会被Flink当作泛型类来处理。Flink会把泛型类型当作黑盒，无法获取它们内部的属性；它们也不是由Flink本身序列化的，而是由Kryo序列化的。</h6></li>
<li><h6 id="在这些类型中，元组类型和POJO类型最为灵活，因为它们支持创建复杂类型。而相比之下，POJO还支持在键（key）的定义中直接使用字段名，这会让我们的代码可读性大大增加。所以，在项目实践中，往往会将流处理程序中的元素类型定为Flink的POJO类型。"><a href="#在这些类型中，元组类型和POJO类型最为灵活，因为它们支持创建复杂类型。而相比之下，POJO还支持在键（key）的定义中直接使用字段名，这会让我们的代码可读性大大增加。所以，在项目实践中，往往会将流处理程序中的元素类型定为Flink的POJO类型。" class="headerlink" title="在这些类型中，元组类型和POJO类型最为灵活，因为它们支持创建复杂类型。而相比之下，POJO还支持在键（key）的定义中直接使用字段名，这会让我们的代码可读性大大增加。所以，在项目实践中，往往会将流处理程序中的元素类型定为Flink的POJO类型。"></a>在这些类型中，元组类型和POJO类型最为灵活，因为它们支持创建复杂类型。而相比之下，POJO还支持在键（key）的定义中直接使用字段名，这会让我们的代码可读性大大增加。所以，在项目实践中，往往会将流处理程序中的元素类型定为Flink的POJO类型。</h6></li>
<li><h6 id="Flink对POJO类型的要求如下："><a href="#Flink对POJO类型的要求如下：" class="headerlink" title="Flink对POJO类型的要求如下："></a>Flink对POJO类型的要求如下：</h6><ol>
<li><h6 id="类是公有（public）的"><a href="#类是公有（public）的" class="headerlink" title="类是公有（public）的"></a>类是公有（public）的</h6></li>
<li><h6 id="有一个无参的构造方法"><a href="#有一个无参的构造方法" class="headerlink" title="有一个无参的构造方法"></a>有一个无参的构造方法</h6></li>
<li><h6 id="所有属性都是公有（public）的"><a href="#所有属性都是公有（public）的" class="headerlink" title="所有属性都是公有（public）的"></a>所有属性都是公有（public）的</h6></li>
<li><h6 id="所有属性的类型都是可以序列化的"><a href="#所有属性的类型都是可以序列化的" class="headerlink" title="所有属性的类型都是可以序列化的"></a>所有属性的类型都是可以序列化的</h6></li>
</ol>
</li>
</ul>
<h4 id="3）类型提示（Type-Hints）"><a href="#3）类型提示（Type-Hints）" class="headerlink" title="3）类型提示（Type Hints）"></a>3）类型提示（Type Hints）</h4><h6 id="Flink还具有一个类型提取系统，可以分析函数的输入和返回类型，自动获取类型信息，从而获得对应的序列化器和反序列化器。但是，由于Java中泛型擦除的存在，在某些特殊情况下（比如Lambda表达式中），自动提取的信息是不够精细的——只告诉Flink当前的元素由“船头、船身、船尾”构成，根本无法重建出“大船”的模样；这时就需要显式地提供类型信息，才能使应用程序正常工作或提高其性能。"><a href="#Flink还具有一个类型提取系统，可以分析函数的输入和返回类型，自动获取类型信息，从而获得对应的序列化器和反序列化器。但是，由于Java中泛型擦除的存在，在某些特殊情况下（比如Lambda表达式中），自动提取的信息是不够精细的——只告诉Flink当前的元素由“船头、船身、船尾”构成，根本无法重建出“大船”的模样；这时就需要显式地提供类型信息，才能使应用程序正常工作或提高其性能。" class="headerlink" title="Flink还具有一个类型提取系统，可以分析函数的输入和返回类型，自动获取类型信息，从而获得对应的序列化器和反序列化器。但是，由于Java中泛型擦除的存在，在某些特殊情况下（比如Lambda表达式中），自动提取的信息是不够精细的——只告诉Flink当前的元素由“船头、船身、船尾”构成，根本无法重建出“大船”的模样；这时就需要显式地提供类型信息，才能使应用程序正常工作或提高其性能。"></a>Flink还具有一个类型提取系统，可以分析函数的输入和返回类型，自动获取类型信息，从而获得对应的序列化器和反序列化器。但是，由于Java中泛型擦除的存在，在某些特殊情况下（比如Lambda表达式中），自动提取的信息是不够精细的——只告诉Flink当前的元素由“船头、船身、船尾”构成，根本无法重建出“大船”的模样；这时就需要显式地提供类型信息，才能使应用程序正常工作或提高其性能。</h6><h6 id="为了解决这类问题，Java-API提供了专门的“类型提示”（type-hints）。"><a href="#为了解决这类问题，Java-API提供了专门的“类型提示”（type-hints）。" class="headerlink" title="为了解决这类问题，Java API提供了专门的“类型提示”（type hints）。"></a>为了解决这类问题，Java API提供了专门的“类型提示”（type hints）。</h6><h6 id="回忆一下之前的word-count流处理程序，我们在将String类型的每个词转换成（word，-count）二元组后，就明确地用returns指定了返回的类型。因为对于map里传入的Lambda表达式，系统只能推断出返回的是Tuple2类型，而无法得到Tuple2-lt-String-Long-gt-。只有显式地告诉系统当前的返回类型，才能正确地解析出完整数据。"><a href="#回忆一下之前的word-count流处理程序，我们在将String类型的每个词转换成（word，-count）二元组后，就明确地用returns指定了返回的类型。因为对于map里传入的Lambda表达式，系统只能推断出返回的是Tuple2类型，而无法得到Tuple2-lt-String-Long-gt-。只有显式地告诉系统当前的返回类型，才能正确地解析出完整数据。" class="headerlink" title="回忆一下之前的word count流处理程序，我们在将String类型的每个词转换成（word， count）二元组后，就明确地用returns指定了返回的类型。因为对于map里传入的Lambda表达式，系统只能推断出返回的是Tuple2类型，而无法得到Tuple2&lt;String, Long&gt;。只有显式地告诉系统当前的返回类型，才能正确地解析出完整数据。"></a>回忆一下之前的word count流处理程序，我们在将String类型的每个词转换成（word， count）二元组后，就明确地用returns指定了返回的类型。因为对于map里传入的Lambda表达式，系统只能推断出返回的是Tuple2类型，而无法得到Tuple2&lt;String, Long&gt;。只有显式地告诉系统当前的返回类型，才能正确地解析出完整数据。</h6><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">.map(word -&gt; <span class="type">Tuple2</span>.of(word, <span class="number">1</span>L))</span><br><span class="line">.returns(<span class="type">Types</span>.<span class="type">TUPLE</span>(<span class="type">Types</span>.<span class="type">STRING</span>, <span class="type">Types</span>.<span class="type">LONG</span>));</span><br></pre></td></tr></table></figure>

<h6 id="Flink还专门提供了TypeHint类，它可以捕获泛型的类型信息，并且一直记录下来，为运行时提供足够的信息。我们同样可以通过-returns-方法，明确地指定转换之后的DataStream里元素的类型。"><a href="#Flink还专门提供了TypeHint类，它可以捕获泛型的类型信息，并且一直记录下来，为运行时提供足够的信息。我们同样可以通过-returns-方法，明确地指定转换之后的DataStream里元素的类型。" class="headerlink" title="Flink还专门提供了TypeHint类，它可以捕获泛型的类型信息，并且一直记录下来，为运行时提供足够的信息。我们同样可以通过.returns()方法，明确地指定转换之后的DataStream里元素的类型。"></a>Flink还专门提供了TypeHint类，它可以捕获泛型的类型信息，并且一直记录下来，为运行时提供足够的信息。我们同样可以通过.returns()方法，明确地指定转换之后的DataStream里元素的类型。</h6><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">returns(<span class="keyword">new</span> <span class="type">TypeHint</span>&lt;<span class="type">Tuple2</span>&lt;<span class="type">Integer</span>, <span class="type">SomeType</span>&gt;&gt;()&#123;&#125;)</span><br></pre></td></tr></table></figure>



<h3 id="转换算子（Transformation）"><a href="#转换算子（Transformation）" class="headerlink" title="转换算子（Transformation）"></a>转换算子（Transformation）</h3><h5 id="数据源读入数据之后，我们就可以使用各种转换算子，将一个或多个DataStream转换为新的DataStream。"><a href="#数据源读入数据之后，我们就可以使用各种转换算子，将一个或多个DataStream转换为新的DataStream。" class="headerlink" title="数据源读入数据之后，我们就可以使用各种转换算子，将一个或多个DataStream转换为新的DataStream。"></a>数据源读入数据之后，我们就可以使用各种转换算子，将一个或多个DataStream转换为新的DataStream。</h5><p><img src= "/imgs/loading/loading.gif" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://pic1.imgdb.cn/item/678624a7d0e0a243d4f42b7c.png"></p>
<h3 id="1-基本转换算子（map-x2F-filter-x2F-flatMap）"><a href="#1-基本转换算子（map-x2F-filter-x2F-flatMap）" class="headerlink" title="1.基本转换算子（map&#x2F; filter&#x2F; flatMap）"></a>1.基本转换算子（map&#x2F; filter&#x2F; flatMap）</h3><h4 id="1-1-1映射（map）"><a href="#1-1-1映射（map）" class="headerlink" title="1.1.1映射（map）"></a>1.1.1映射（map）</h4><h6 id="map是大家非常熟悉的大数据操作算子，主要用于将数据流中的数据进行转换，形成新的数据流。简单来说，就是一个“一一映射”，消费一个元素就产出一个元素。"><a href="#map是大家非常熟悉的大数据操作算子，主要用于将数据流中的数据进行转换，形成新的数据流。简单来说，就是一个“一一映射”，消费一个元素就产出一个元素。" class="headerlink" title="map是大家非常熟悉的大数据操作算子，主要用于将数据流中的数据进行转换，形成新的数据流。简单来说，就是一个“一一映射”，消费一个元素就产出一个元素。"></a>map是大家非常熟悉的大数据操作算子，主要用于将数据流中的数据进行转换，形成新的数据流。简单来说，就是一个“一一映射”，消费一个元素就产出一个元素。</h6><p><img src= "/imgs/loading/loading.gif" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://pic1.imgdb.cn/item/6786250bd0e0a243d4f42bac.png"></p>
<h6 id="我们只需要基于DataStream调用map-方法就可以进行转换处理。方法需要传入的参数是接口MapFunction的实现；返回值类型还是DataStream，不过泛型（流中的元素类型）可能改变。"><a href="#我们只需要基于DataStream调用map-方法就可以进行转换处理。方法需要传入的参数是接口MapFunction的实现；返回值类型还是DataStream，不过泛型（流中的元素类型）可能改变。" class="headerlink" title="我们只需要基于DataStream调用map()方法就可以进行转换处理。方法需要传入的参数是接口MapFunction的实现；返回值类型还是DataStream，不过泛型（流中的元素类型）可能改变。"></a>我们只需要基于DataStream调用map()方法就可以进行转换处理。方法需要传入的参数是接口MapFunction的实现；返回值类型还是DataStream，不过泛型（流中的元素类型）可能改变。</h6><h6 id="下面的代码用不同的方式，实现了提取WaterSensor中的id字段的功能。"><a href="#下面的代码用不同的方式，实现了提取WaterSensor中的id字段的功能。" class="headerlink" title="下面的代码用不同的方式，实现了提取WaterSensor中的id字段的功能。"></a>下面的代码用不同的方式，实现了提取WaterSensor中的id字段的功能。</h6><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.day02</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.day02.<span class="type">SourceBoundedTest</span>.<span class="type">Event</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.functions.<span class="type">MapFunction</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.scala._</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">TransformMapTest</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> env = <span class="type">StreamExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line">    env.setParallelism(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> stream: <span class="type">DataStream</span>[<span class="type">Event</span>] = env.fromElements(</span><br><span class="line">      <span class="type">Event</span>(<span class="string">&quot;hkj&quot;</span>, <span class="string">&quot;www.baidu.com&quot;</span>, <span class="number">1000</span>L),</span><br><span class="line">      <span class="type">Event</span>(<span class="string">&quot;Bob&quot;</span>, <span class="string">&quot;www.bing.com&quot;</span>, <span class="number">2000</span>L)</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 提取每次点击事件的用户名</span></span><br><span class="line">    <span class="comment">// 1.使用匿名函数</span></span><br><span class="line">    stream.map( _.user ).print(<span class="string">&quot;1&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 2.实现mapFunction接口</span></span><br><span class="line">    stream.map(<span class="keyword">new</span> <span class="type">UserExtractor</span>).print(<span class="string">&quot;2&quot;</span>)</span><br><span class="line"></span><br><span class="line">    env.execute()</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="class"><span class="keyword">class</span> <span class="title">UserExtractor</span> <span class="keyword">extends</span> <span class="title">MapFunction</span>[<span class="type">Event</span>, <span class="type">String</span>] </span>&#123;</span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">map</span></span>(value: <span class="type">Event</span>): <span class="type">String</span> = value.user</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h6 id="上面代码中，MapFunction实现类的泛型类型，与输入数据类型和输出数据的类型有关。在实现MapFunction接口的时候，需要指定两个泛型，分别是输入事件和输出事件的类型，还需要重写一个map-方法，定义从一个输入事件转换为另一个输出事件的具体逻辑。"><a href="#上面代码中，MapFunction实现类的泛型类型，与输入数据类型和输出数据的类型有关。在实现MapFunction接口的时候，需要指定两个泛型，分别是输入事件和输出事件的类型，还需要重写一个map-方法，定义从一个输入事件转换为另一个输出事件的具体逻辑。" class="headerlink" title="上面代码中，MapFunction实现类的泛型类型，与输入数据类型和输出数据的类型有关。在实现MapFunction接口的时候，需要指定两个泛型，分别是输入事件和输出事件的类型，还需要重写一个map()方法，定义从一个输入事件转换为另一个输出事件的具体逻辑。"></a>上面代码中，MapFunction实现类的泛型类型，与输入数据类型和输出数据的类型有关。在实现MapFunction接口的时候，需要指定两个泛型，分别是输入事件和输出事件的类型，还需要重写一个map()方法，定义从一个输入事件转换为另一个输出事件的具体逻辑。</h6><h3 id="1-1-2过滤（filter）"><a href="#1-1-2过滤（filter）" class="headerlink" title="1.1.2过滤（filter）"></a>1.1.2过滤（filter）</h3><h5 id="filter转换操作，顾名思义是对数据流执行一个过滤，通过一个布尔条件表达式设置过滤条件，对于每一个流内元素进行判断，若为true则元素正常输出，若为false则元素被过滤掉。"><a href="#filter转换操作，顾名思义是对数据流执行一个过滤，通过一个布尔条件表达式设置过滤条件，对于每一个流内元素进行判断，若为true则元素正常输出，若为false则元素被过滤掉。" class="headerlink" title="filter转换操作，顾名思义是对数据流执行一个过滤，通过一个布尔条件表达式设置过滤条件，对于每一个流内元素进行判断，若为true则元素正常输出，若为false则元素被过滤掉。"></a>filter转换操作，顾名思义是对数据流执行一个过滤，通过一个布尔条件表达式设置过滤条件，对于每一个流内元素进行判断，若为true则元素正常输出，若为false则元素被过滤掉。</h5><p><img src= "/imgs/loading/loading.gif" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://pic1.imgdb.cn/item/6786255dd0e0a243d4f42bd8.png"></p>
<h6 id="进行filter转换之后的新数据流的数据类型与原数据流是相同的。filter转换需要传入的参数需要实现FilterFunction接口，而FilterFunction内要实现filter-方法，就相当于一个返回布尔类型的条件表达式。"><a href="#进行filter转换之后的新数据流的数据类型与原数据流是相同的。filter转换需要传入的参数需要实现FilterFunction接口，而FilterFunction内要实现filter-方法，就相当于一个返回布尔类型的条件表达式。" class="headerlink" title="进行filter转换之后的新数据流的数据类型与原数据流是相同的。filter转换需要传入的参数需要实现FilterFunction接口，而FilterFunction内要实现filter()方法，就相当于一个返回布尔类型的条件表达式。"></a>进行filter转换之后的新数据流的数据类型与原数据流是相同的。filter转换需要传入的参数需要实现FilterFunction接口，而FilterFunction内要实现filter()方法，就相当于一个返回布尔类型的条件表达式。</h6><h6 id="案例需求：下面的代码会将数据流中传感器id为sensor-1的数据过滤出来。"><a href="#案例需求：下面的代码会将数据流中传感器id为sensor-1的数据过滤出来。" class="headerlink" title="案例需求：下面的代码会将数据流中传感器id为sensor_1的数据过滤出来。"></a><strong>案例需求：</strong>下面的代码会将数据流中传感器id为sensor_1的数据过滤出来。</h6><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.day02</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.day02.<span class="type">SourceBoundedTest</span>.<span class="type">Event</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.functions.<span class="type">FilterFunction</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.scala._</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">TransformFilterTest</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> env = <span class="type">StreamExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line">    env.setParallelism(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> stream: <span class="type">DataStream</span>[<span class="type">Event</span>] = env.fromElements(</span><br><span class="line">      <span class="type">Event</span>(<span class="string">&quot;hkj&quot;</span>, <span class="string">&quot;www.baidu.com&quot;</span>, <span class="number">1000</span>L),</span><br><span class="line">      <span class="type">Event</span>(<span class="string">&quot;Bob&quot;</span>, <span class="string">&quot;www.bing.com&quot;</span>, <span class="number">2000</span>L)</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 过滤出用户为Marry的所有点击事件</span></span><br><span class="line">    <span class="comment">// 1.使用匿名函数</span></span><br><span class="line">    stream.filter( _.user == <span class="string">&quot;hkj&quot;</span> ).print(<span class="string">&quot;1&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 2.实现FilterFunction</span></span><br><span class="line">    stream.filter( <span class="keyword">new</span> <span class="type">UserFilter</span> ).print(<span class="string">&quot;2&quot;</span>)</span><br><span class="line"></span><br><span class="line">    env.execute()</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="class"><span class="keyword">class</span> <span class="title">UserFilter</span> <span class="keyword">extends</span> <span class="title">FilterFunction</span>[<span class="type">Event</span>] </span>&#123;</span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">filter</span></span>(value: <span class="type">Event</span>): <span class="type">Boolean</span> = value.user == <span class="string">&quot;Bob&quot;</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="1-1-3-扁平映射（flatMap）"><a href="#1-1-3-扁平映射（flatMap）" class="headerlink" title="1.1.3 扁平映射（flatMap）"></a>1.1.3 扁平映射（flatMap）</h4><h6 id="flatMap操作又称为扁平映射，主要是将数据流中的整体（一般是集合类型）拆分成一个一个的个体使用。消费一个元素，可以产生0到多个元素。flatMap可以认为是“扁平化”（flatten）和“映射”（map）两步操作的结合，也就是先按照某种规则对数据进行打散拆分，再对拆分后的元素做转换处理。"><a href="#flatMap操作又称为扁平映射，主要是将数据流中的整体（一般是集合类型）拆分成一个一个的个体使用。消费一个元素，可以产生0到多个元素。flatMap可以认为是“扁平化”（flatten）和“映射”（map）两步操作的结合，也就是先按照某种规则对数据进行打散拆分，再对拆分后的元素做转换处理。" class="headerlink" title="flatMap操作又称为扁平映射，主要是将数据流中的整体（一般是集合类型）拆分成一个一个的个体使用。消费一个元素，可以产生0到多个元素。flatMap可以认为是“扁平化”（flatten）和“映射”（map）两步操作的结合，也就是先按照某种规则对数据进行打散拆分，再对拆分后的元素做转换处理。"></a>flatMap操作又称为扁平映射，主要是将数据流中的整体（一般是集合类型）拆分成一个一个的个体使用。消费一个元素，可以产生0到多个元素。flatMap可以认为是“扁平化”（flatten）和“映射”（map）两步操作的结合，也就是先按照某种规则对数据进行打散拆分，再对拆分后的元素做转换处理。</h6><p><img src= "/imgs/loading/loading.gif" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://pic1.imgdb.cn/item/6786259fd0e0a243d4f42bf4.png"></p>
<h6 id="同map一样，flatMap也可以使用Lambda表达式或者FlatMapFunction接口实现类的方式来进行传参，返回值类型取决于所传参数的具体逻辑，可以与原数据流相同，也可以不同。"><a href="#同map一样，flatMap也可以使用Lambda表达式或者FlatMapFunction接口实现类的方式来进行传参，返回值类型取决于所传参数的具体逻辑，可以与原数据流相同，也可以不同。" class="headerlink" title="同map一样，flatMap也可以使用Lambda表达式或者FlatMapFunction接口实现类的方式来进行传参，返回值类型取决于所传参数的具体逻辑，可以与原数据流相同，也可以不同。"></a>同map一样，flatMap也可以使用Lambda表达式或者FlatMapFunction接口实现类的方式来进行传参，返回值类型取决于所传参数的具体逻辑，可以与原数据流相同，也可以不同。</h6><h6 id="案例需求：如果输入的数据是sensor-1，只打印vc；如果输入的数据是sensor-2，既打印ts又打印vc。"><a href="#案例需求：如果输入的数据是sensor-1，只打印vc；如果输入的数据是sensor-2，既打印ts又打印vc。" class="headerlink" title="案例需求：如果输入的数据是sensor_1，只打印vc；如果输入的数据是sensor_2，既打印ts又打印vc。"></a><strong>案例需求：</strong>如果输入的数据是sensor_1，只打印vc；如果输入的数据是sensor_2，既打印ts又打印vc。</h6><h6 id="实现代码如下："><a href="#实现代码如下：" class="headerlink" title="实现代码如下："></a>实现代码如下：</h6><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.day02</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.day02.<span class="type">SourceBoundedTest</span>.<span class="type">Event</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.functions.<span class="type">FlatMapFunction</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.scala._</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.util.<span class="type">Collector</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">TransformFlatMapTest</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> env = <span class="type">StreamExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line">    env.setParallelism(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> stream: <span class="type">DataStream</span>[<span class="type">Event</span>] = env.fromElements(</span><br><span class="line">      <span class="type">Event</span>(<span class="string">&quot;hkj&quot;</span>, <span class="string">&quot;www.baidu.com&quot;</span>, <span class="number">1000</span>L),</span><br><span class="line">      <span class="type">Event</span>(<span class="string">&quot;Bob&quot;</span>, <span class="string">&quot;www.bing.com&quot;</span>, <span class="number">2000</span>L),</span><br><span class="line">      <span class="type">Event</span>(<span class="string">&quot;Lisa&quot;</span>, <span class="string">&quot;www.hkjcpdd.com&quot;</span>, <span class="number">3000</span>L)</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 测试灵活输出形式</span></span><br><span class="line">    stream.flatMap(<span class="keyword">new</span> <span class="type">MyFlatMap</span>).print(<span class="string">&quot;1&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// lam表达式</span></span><br><span class="line">    <span class="keyword">val</span> stream1 = env.readTextFile(<span class="string">&quot;G:\\Flink学习\\FlinkStu\\data\\words.txt&quot;</span>)</span><br><span class="line">    stream1.flatMap( value =&gt; value.split(<span class="string">&quot;,&quot;</span>) ).map(value =&gt; (value, <span class="number">1</span>)).print(<span class="string">&quot;stream1&quot;</span>)</span><br><span class="line"></span><br><span class="line">    env.execute()</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 自定义实现flatMapFunction</span></span><br><span class="line">  <span class="class"><span class="keyword">class</span> <span class="title">MyFlatMap</span> <span class="keyword">extends</span> <span class="title">FlatMapFunction</span>[<span class="type">Event</span>, <span class="type">String</span>] </span>&#123;</span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">flatMap</span></span>(value: <span class="type">Event</span>, out: <span class="type">Collector</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">      <span class="comment">// 如果当前数据是hkj的点击事件那就直接输出user</span></span><br><span class="line">      <span class="keyword">if</span> (value.user == <span class="string">&quot;hkj&quot;</span>) &#123;</span><br><span class="line">        out.collect(value.user)</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="comment">// 如果当前数据是Bob的点击事件，那么就输出user和url</span></span><br><span class="line">      <span class="keyword">else</span> <span class="keyword">if</span> (value.user == <span class="string">&quot;Bob&quot;</span>) &#123;</span><br><span class="line">        out.collect(value.user)</span><br><span class="line">        out.collect(value.url)</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h3 id="1-2聚合算子（Aggregation）"><a href="#1-2聚合算子（Aggregation）" class="headerlink" title="1.2聚合算子（Aggregation）"></a>1.2聚合算子（Aggregation）</h3><h5 id="计算的结果不仅依赖当前数据，还跟之前的数据有关，相当于要把所有数据聚在一起进行汇总合并——这就是所谓的“聚合”（Aggregation），类似于MapReduce中的reduce操作。"><a href="#计算的结果不仅依赖当前数据，还跟之前的数据有关，相当于要把所有数据聚在一起进行汇总合并——这就是所谓的“聚合”（Aggregation），类似于MapReduce中的reduce操作。" class="headerlink" title="计算的结果不仅依赖当前数据，还跟之前的数据有关，相当于要把所有数据聚在一起进行汇总合并——这就是所谓的“聚合”（Aggregation），类似于MapReduce中的reduce操作。"></a>计算的结果不仅依赖当前数据，还跟之前的数据有关，相当于要把所有数据聚在一起进行汇总合并——这就是所谓的“聚合”（Aggregation），类似于MapReduce中的reduce操作。</h5><h4 id="1-2-1-按键分区（keyBy）"><a href="#1-2-1-按键分区（keyBy）" class="headerlink" title="1.2.1 按键分区（keyBy）"></a>1.2.1 按键分区（keyBy）</h4><ul>
<li><h6 id="对于Flink而言，DataStream是没有直接进行聚合的API的。因为我们对海量数据做聚合肯定要进行分区并行处理，这样才能提高效率。所以在Flink中，要做聚合，需要先进行分区；这个操作就是通过keyBy来完成的。"><a href="#对于Flink而言，DataStream是没有直接进行聚合的API的。因为我们对海量数据做聚合肯定要进行分区并行处理，这样才能提高效率。所以在Flink中，要做聚合，需要先进行分区；这个操作就是通过keyBy来完成的。" class="headerlink" title="对于Flink而言，DataStream是没有直接进行聚合的API的。因为我们对海量数据做聚合肯定要进行分区并行处理，这样才能提高效率。所以在Flink中，要做聚合，需要先进行分区；这个操作就是通过keyBy来完成的。"></a>对于Flink而言，DataStream是没有直接进行聚合的API的。因为我们对海量数据做聚合肯定要进行分区并行处理，这样才能提高效率。所以在Flink中，要做聚合，需要先进行分区；这个操作就是通过keyBy来完成的。</h6></li>
<li><h6 id="keyBy是聚合前必须要用到的一个算子。keyBy通过指定键（key），可以将一条流从逻辑上划分成不同的分区（partitions）。这里所说的分区，其实就是并行处理的子任务。"><a href="#keyBy是聚合前必须要用到的一个算子。keyBy通过指定键（key），可以将一条流从逻辑上划分成不同的分区（partitions）。这里所说的分区，其实就是并行处理的子任务。" class="headerlink" title="keyBy是聚合前必须要用到的一个算子。keyBy通过指定键（key），可以将一条流从逻辑上划分成不同的分区（partitions）。这里所说的分区，其实就是并行处理的子任务。"></a>keyBy是聚合前必须要用到的一个算子。keyBy通过指定键（key），可以将一条流从逻辑上划分成不同的分区（partitions）。这里所说的分区，其实就是并行处理的子任务。</h6></li>
<li><h6 id="基于不同的key，流中的数据将被分配到不同的分区中去；这样一来，所有具有相同的key的数据，都将被发往同一个分区。"><a href="#基于不同的key，流中的数据将被分配到不同的分区中去；这样一来，所有具有相同的key的数据，都将被发往同一个分区。" class="headerlink" title="基于不同的key，流中的数据将被分配到不同的分区中去；这样一来，所有具有相同的key的数据，都将被发往同一个分区。"></a>基于不同的key，流中的数据将被分配到不同的分区中去；这样一来，所有具有相同的key的数据，都将被发往同一个分区。</h6></li>
</ul>
<p><img src= "/imgs/loading/loading.gif" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://pic1.imgdb.cn/item/67862611d0e0a243d4f42c2f.png"></p>
<h6 id="在内部，是通过计算key的哈希值（hash-code），对分区数进行取模运算来实现的。所以这里key如果是POJO的话，必须要重写hashCode-方法。"><a href="#在内部，是通过计算key的哈希值（hash-code），对分区数进行取模运算来实现的。所以这里key如果是POJO的话，必须要重写hashCode-方法。" class="headerlink" title="在内部，是通过计算key的哈希值（hash code），对分区数进行取模运算来实现的。所以这里key如果是POJO的话，必须要重写hashCode()方法。"></a>在内部，是通过计算key的哈希值（hash code），对分区数进行取模运算来实现的。所以这里key如果是POJO的话，必须要重写hashCode()方法。</h6><h6 id="keyBy-方法需要传入一个参数，这个参数指定了一个或一组key。有很多不同的方法来指定key：比如对于Tuple数据类型，可以指定字段的位置或者多个位置的组合；对于POJO类型，可以指定字段的名称（String）；另外，还可以传入Lambda表达式或者实现一个键选择器（KeySelector），用于说明从数据中提取key的逻辑。"><a href="#keyBy-方法需要传入一个参数，这个参数指定了一个或一组key。有很多不同的方法来指定key：比如对于Tuple数据类型，可以指定字段的位置或者多个位置的组合；对于POJO类型，可以指定字段的名称（String）；另外，还可以传入Lambda表达式或者实现一个键选择器（KeySelector），用于说明从数据中提取key的逻辑。" class="headerlink" title="keyBy()方法需要传入一个参数，这个参数指定了一个或一组key。有很多不同的方法来指定key：比如对于Tuple数据类型，可以指定字段的位置或者多个位置的组合；对于POJO类型，可以指定字段的名称（String）；另外，还可以传入Lambda表达式或者实现一个键选择器（KeySelector），用于说明从数据中提取key的逻辑。"></a>keyBy()方法需要传入一个参数，这个参数指定了一个或一组key。有很多不同的方法来指定key：比如对于Tuple数据类型，可以指定字段的位置或者多个位置的组合；对于POJO类型，可以指定字段的名称（String）；另外，还可以传入Lambda表达式或者实现一个键选择器（KeySelector），用于说明从数据中提取key的逻辑。</h6><h6 id="我们可以以id作为key做一个分区操作，代码实现如下："><a href="#我们可以以id作为key做一个分区操作，代码实现如下：" class="headerlink" title="我们可以以id作为key做一个分区操作，代码实现如下："></a>我们可以以id作为key做一个分区操作，代码实现如下：</h6><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.day02</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.day02.<span class="type">SourceBoundedTest</span>.<span class="type">Event</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.java.functions.<span class="type">KeySelector</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.scala._</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">TransformKeyByTest</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> env = <span class="type">StreamExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line">    env.setParallelism(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> stream: <span class="type">DataStream</span>[<span class="type">Event</span>] = env.fromElements(</span><br><span class="line">      <span class="type">Event</span>(<span class="string">&quot;hkj&quot;</span>, <span class="string">&quot;www.baidu.com&quot;</span>, <span class="number">1000</span>L),</span><br><span class="line">      <span class="type">Event</span>(<span class="string">&quot;Bob&quot;</span>, <span class="string">&quot;www.bing.com&quot;</span>, <span class="number">2000</span>L),</span><br><span class="line">      <span class="type">Event</span>(<span class="string">&quot;Lisa&quot;</span>, <span class="string">&quot;www.hkjcpdd.com&quot;</span>, <span class="number">3000</span>L),</span><br><span class="line">      <span class="type">Event</span>(<span class="string">&quot;hkj&quot;</span>, <span class="string">&quot;www.by123.com&quot;</span>, <span class="number">8000</span>L),</span><br><span class="line">      <span class="type">Event</span>(<span class="string">&quot;Lisa&quot;</span>, <span class="string">&quot;www.hkjmjj.com&quot;</span>, <span class="number">1000</span>L)</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    stream.keyBy( <span class="keyword">new</span> <span class="type">MyKeySelector</span> )</span><br><span class="line">      .maxBy(<span class="string">&quot;timestamp&quot;</span>)</span><br><span class="line">      .print()</span><br><span class="line"></span><br><span class="line"><span class="comment">//    stream.keyBy( _.user).print(&quot;lam&quot;)</span></span><br><span class="line"></span><br><span class="line">    env.execute()</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="class"><span class="keyword">class</span> <span class="title">MyKeySelector</span> <span class="keyword">extends</span> <span class="title">KeySelector</span>[<span class="type">Event</span>, <span class="type">String</span>] </span>&#123;</span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">getKey</span></span>(value: <span class="type">Event</span>): <span class="type">String</span> = value.user</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h6 id="需要注意的是，keyBy得到的结果将不再是DataStream，而是会将DataStream转换为KeyedStream。KeyedStream可以认为是“分区流”或者“键控流”，它是对DataStream按照key的一个逻辑分区，所以泛型有两个类型：除去当前流中的元素类型外，还需要指定key的类型。"><a href="#需要注意的是，keyBy得到的结果将不再是DataStream，而是会将DataStream转换为KeyedStream。KeyedStream可以认为是“分区流”或者“键控流”，它是对DataStream按照key的一个逻辑分区，所以泛型有两个类型：除去当前流中的元素类型外，还需要指定key的类型。" class="headerlink" title="需要注意的是，keyBy得到的结果将不再是DataStream，而是会将DataStream转换为KeyedStream。KeyedStream可以认为是“分区流”或者“键控流”，它是对DataStream按照key的一个逻辑分区，所以泛型有两个类型：除去当前流中的元素类型外，还需要指定key的类型。"></a>需要注意的是，keyBy得到的结果将不再是DataStream，而是会将DataStream转换为KeyedStream。KeyedStream可以认为是“分区流”或者“键控流”，它是对DataStream按照key的一个逻辑分区，所以泛型有两个类型：除去当前流中的元素类型外，还需要指定key的类型。</h6><h6 id="KeyedStream也继承自DataStream，所以基于它的操作也都归属于DataStream-API。但它跟之前的转换操作得到的SingleOutputStreamOperator不同，只是一个流的分区操作，并不是一个转换算子。KeyedStream是一个非常重要的数据结构，只有基于它才可以做后续的聚合操作（比如sum，reduce）。"><a href="#KeyedStream也继承自DataStream，所以基于它的操作也都归属于DataStream-API。但它跟之前的转换操作得到的SingleOutputStreamOperator不同，只是一个流的分区操作，并不是一个转换算子。KeyedStream是一个非常重要的数据结构，只有基于它才可以做后续的聚合操作（比如sum，reduce）。" class="headerlink" title="KeyedStream也继承自DataStream，所以基于它的操作也都归属于DataStream API。但它跟之前的转换操作得到的SingleOutputStreamOperator不同，只是一个流的分区操作，并不是一个转换算子。KeyedStream是一个非常重要的数据结构，只有基于它才可以做后续的聚合操作（比如sum，reduce）。"></a>KeyedStream也继承自DataStream，所以基于它的操作也都归属于DataStream API。但它跟之前的转换操作得到的SingleOutputStreamOperator不同，只是一个流的分区操作，并不是一个转换算子。KeyedStream是一个非常重要的数据结构，只有基于它才可以做后续的聚合操作（比如sum，reduce）。</h6><h4 id="1-2-2-简单聚合（sum-x2F-min-x2F-max-x2F-minBy-x2F-maxBy）"><a href="#1-2-2-简单聚合（sum-x2F-min-x2F-max-x2F-minBy-x2F-maxBy）" class="headerlink" title="1.2.2 简单聚合（sum&#x2F;min&#x2F;max&#x2F;minBy&#x2F;maxBy）"></a>1.2.2 简单聚合（sum&#x2F;min&#x2F;max&#x2F;minBy&#x2F;maxBy）</h4><h6 id="有了按键分区的数据流KeyedStream，我们就可以基于它进行聚合操作了。Flink为我们内置实现了一些最基本、最简单的聚合API，主要有以下几种："><a href="#有了按键分区的数据流KeyedStream，我们就可以基于它进行聚合操作了。Flink为我们内置实现了一些最基本、最简单的聚合API，主要有以下几种：" class="headerlink" title="有了按键分区的数据流KeyedStream，我们就可以基于它进行聚合操作了。Flink为我们内置实现了一些最基本、最简单的聚合API，主要有以下几种："></a>有了按键分区的数据流KeyedStream，我们就可以基于它进行聚合操作了。Flink为我们内置实现了一些最基本、最简单的聚合API，主要有以下几种：</h6><ol>
<li><h6 id="sum-：在输入流上，对指定的字段做叠加求和的操作。"><a href="#sum-：在输入流上，对指定的字段做叠加求和的操作。" class="headerlink" title="sum()：在输入流上，对指定的字段做叠加求和的操作。"></a>sum()：在输入流上，对指定的字段做叠加求和的操作。</h6></li>
<li><h6 id="min-：在输入流上，对指定的字段求最小值。"><a href="#min-：在输入流上，对指定的字段求最小值。" class="headerlink" title="min()：在输入流上，对指定的字段求最小值。"></a>min()：在输入流上，对指定的字段求最小值。</h6></li>
<li><h6 id="max-：在输入流上，对指定的字段求最大值。"><a href="#max-：在输入流上，对指定的字段求最大值。" class="headerlink" title="max()：在输入流上，对指定的字段求最大值。"></a>max()：在输入流上，对指定的字段求最大值。</h6></li>
<li><h6 id="minBy-：与min-类似，在输入流上针对指定字段求最小值。不同的是，min-只计算指定字段的最小值，其他字段会保留最初第一个数据的值；而minBy-则会返回包含字段最小值的整条数据。"><a href="#minBy-：与min-类似，在输入流上针对指定字段求最小值。不同的是，min-只计算指定字段的最小值，其他字段会保留最初第一个数据的值；而minBy-则会返回包含字段最小值的整条数据。" class="headerlink" title="minBy()：与min()类似，在输入流上针对指定字段求最小值。不同的是，min()只计算指定字段的最小值，其他字段会保留最初第一个数据的值；而minBy()则会返回包含字段最小值的整条数据。"></a>minBy()：与min()类似，在输入流上针对指定字段求最小值。不同的是，min()只计算指定字段的最小值，其他字段会保留最初第一个数据的值；而minBy()则会返回包含字段最小值的整条数据。</h6></li>
<li><h6 id="maxBy-：与max-类似，在输入流上针对指定字段求最大值。两者区别与min-x2F-minBy-完全一致。"><a href="#maxBy-：与max-类似，在输入流上针对指定字段求最大值。两者区别与min-x2F-minBy-完全一致。" class="headerlink" title="maxBy()：与max()类似，在输入流上针对指定字段求最大值。两者区别与min()&#x2F;minBy()完全一致。"></a>maxBy()：与max()类似，在输入流上针对指定字段求最大值。两者区别与min()&#x2F;minBy()完全一致。</h6></li>
</ol>
<h5 id="简单聚合算子使用非常方便，语义也非常明确。这些聚合方法调用时，也需要传入参数；但并不像基本转换算子那样需要实现自定义函数，只要说明聚合指定的字段就可以了。指定字段的方式有两种：指定位置，和指定名称。"><a href="#简单聚合算子使用非常方便，语义也非常明确。这些聚合方法调用时，也需要传入参数；但并不像基本转换算子那样需要实现自定义函数，只要说明聚合指定的字段就可以了。指定字段的方式有两种：指定位置，和指定名称。" class="headerlink" title="简单聚合算子使用非常方便，语义也非常明确。这些聚合方法调用时，也需要传入参数；但并不像基本转换算子那样需要实现自定义函数，只要说明聚合指定的字段就可以了。指定字段的方式有两种：指定位置，和指定名称。"></a>简单聚合算子使用非常方便，语义也非常明确。这些聚合方法调用时，也需要传入参数；但并不像基本转换算子那样需要实现自定义函数，只要说明聚合指定的字段就可以了。指定字段的方式有两种：指定位置，和指定名称。</h5><h6 id="对于元组类型的数据，可以使用这两种方式来指定字段。需要注意的是，元组中字段的名称，是以f0、f1、f2、…来命名的。"><a href="#对于元组类型的数据，可以使用这两种方式来指定字段。需要注意的是，元组中字段的名称，是以f0、f1、f2、…来命名的。" class="headerlink" title="对于元组类型的数据，可以使用这两种方式来指定字段。需要注意的是，元组中字段的名称，是以f0、f1、f2、…来命名的。"></a>对于元组类型的数据，可以使用这两种方式来指定字段。需要注意的是，元组中字段的名称，是以f0、f1、f2、…来命名的。</h6><h6 id="如果数据流的类型是POJO类，那么就只能通过字段名称来指定，不能通过位置来指定了。"><a href="#如果数据流的类型是POJO类，那么就只能通过字段名称来指定，不能通过位置来指定了。" class="headerlink" title="如果数据流的类型是POJO类，那么就只能通过字段名称来指定，不能通过位置来指定了。"></a>如果数据流的类型是POJO类，那么就只能通过字段名称来指定，不能通过位置来指定了。</h6><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">TransAggregation</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line"></span><br><span class="line">        <span class="type">StreamExecutionEnvironment</span> <span class="variable">env</span> <span class="operator">=</span> StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line"></span><br><span class="line">        DataStreamSource&lt;WaterSensor&gt; stream = env.fromElements(</span><br><span class="line"><span class="keyword">new</span> <span class="title class_">WaterSensor</span>(<span class="string">&quot;sensor_1&quot;</span>, <span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line"><span class="keyword">new</span> <span class="title class_">WaterSensor</span>(<span class="string">&quot;sensor_1&quot;</span>, <span class="number">2</span>, <span class="number">2</span>),</span><br><span class="line"><span class="keyword">new</span> <span class="title class_">WaterSensor</span>(<span class="string">&quot;sensor_2&quot;</span>, <span class="number">2</span>, <span class="number">2</span>),</span><br><span class="line"><span class="keyword">new</span> <span class="title class_">WaterSensor</span>(<span class="string">&quot;sensor_3&quot;</span>, <span class="number">3</span>, <span class="number">3</span>)</span><br><span class="line">        );</span><br><span class="line"></span><br><span class="line">        stream.keyBy(e -&gt; e.id).max(<span class="string">&quot;vc&quot;</span>);    <span class="comment">// 指定字段名称</span></span><br><span class="line"></span><br><span class="line">        env.execute();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h5 id="简单聚合算子返回的，同样是一个SingleOutputStreamOperator，也就是从KeyedStream又转换成了常规的DataStream。所以可以这样理解：keyBy和聚合是成对出现的，先分区、后聚合，得到的依然是一个DataStream。而且经过简单聚合之后的数据流，元素的数据类型保持不变。"><a href="#简单聚合算子返回的，同样是一个SingleOutputStreamOperator，也就是从KeyedStream又转换成了常规的DataStream。所以可以这样理解：keyBy和聚合是成对出现的，先分区、后聚合，得到的依然是一个DataStream。而且经过简单聚合之后的数据流，元素的数据类型保持不变。" class="headerlink" title="简单聚合算子返回的，同样是一个SingleOutputStreamOperator，也就是从KeyedStream又转换成了常规的DataStream。所以可以这样理解：keyBy和聚合是成对出现的，先分区、后聚合，得到的依然是一个DataStream。而且经过简单聚合之后的数据流，元素的数据类型保持不变。"></a>简单聚合算子返回的，同样是一个SingleOutputStreamOperator，也就是从KeyedStream又转换成了常规的DataStream。所以可以这样理解：keyBy和聚合是成对出现的，先分区、后聚合，得到的依然是一个DataStream。而且经过简单聚合之后的数据流，元素的数据类型保持不变。</h5><h5 id="一个聚合算子，会为每一个key保存一个聚合的值，在Flink中我们把它叫作“状态”（state）。所以每当有一个新的数据输入，算子就会更新保存的聚合结果，并发送一个带有更新后聚合值的事件到下游算子。对于无界流来说，这些状态是永远不会被清除的，所以我们使用聚合算子，应该只用在含有有限个key的数据流上。"><a href="#一个聚合算子，会为每一个key保存一个聚合的值，在Flink中我们把它叫作“状态”（state）。所以每当有一个新的数据输入，算子就会更新保存的聚合结果，并发送一个带有更新后聚合值的事件到下游算子。对于无界流来说，这些状态是永远不会被清除的，所以我们使用聚合算子，应该只用在含有有限个key的数据流上。" class="headerlink" title="一个聚合算子，会为每一个key保存一个聚合的值，在Flink中我们把它叫作“状态”（state）。所以每当有一个新的数据输入，算子就会更新保存的聚合结果，并发送一个带有更新后聚合值的事件到下游算子。对于无界流来说，这些状态是永远不会被清除的，所以我们使用聚合算子，应该只用在含有有限个key的数据流上。"></a>一个聚合算子，会为每一个key保存一个聚合的值，在Flink中我们把它叫作“状态”（state）。所以每当有一个新的数据输入，算子就会更新保存的聚合结果，并发送一个带有更新后聚合值的事件到下游算子。对于无界流来说，这些状态是永远不会被清除的，所以我们使用聚合算子，应该只用在含有有限个key的数据流上。</h5><h4 id="1-2-3-归约聚合（reduce）"><a href="#1-2-3-归约聚合（reduce）" class="headerlink" title="1.2.3 归约聚合（reduce）"></a>1.2.3 归约聚合（reduce）</h4><h5 id="reduce可以对已有的数据进行归约处理，把每一个新输入的数据和当前已经归约出来的值，再做一个聚合计算。"><a href="#reduce可以对已有的数据进行归约处理，把每一个新输入的数据和当前已经归约出来的值，再做一个聚合计算。" class="headerlink" title="reduce可以对已有的数据进行归约处理，把每一个新输入的数据和当前已经归约出来的值，再做一个聚合计算。"></a>reduce可以对已有的数据进行归约处理，把每一个新输入的数据和当前已经归约出来的值，再做一个聚合计算。</h5><h5 id="reduce操作也会将KeyedStream转换为DataStream。它不会改变流的元素数据类型，所以输出类型和输入类型是一样的。"><a href="#reduce操作也会将KeyedStream转换为DataStream。它不会改变流的元素数据类型，所以输出类型和输入类型是一样的。" class="headerlink" title="reduce操作也会将KeyedStream转换为DataStream。它不会改变流的元素数据类型，所以输出类型和输入类型是一样的。"></a>reduce操作也会将KeyedStream转换为DataStream。它不会改变流的元素数据类型，所以输出类型和输入类型是一样的。</h5><h5 id="调用KeyedStream的reduce方法时，需要传入一个参数，实现ReduceFunction接口。接口在源码中的定义如下："><a href="#调用KeyedStream的reduce方法时，需要传入一个参数，实现ReduceFunction接口。接口在源码中的定义如下：" class="headerlink" title="调用KeyedStream的reduce方法时，需要传入一个参数，实现ReduceFunction接口。接口在源码中的定义如下："></a>调用KeyedStream的reduce方法时，需要传入一个参数，实现ReduceFunction接口。接口在源码中的定义如下：</h5><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">interface</span> <span class="title class_">ReduceFunction</span>&lt;T&gt; <span class="keyword">extends</span> <span class="title class_">Function</span>, Serializable &#123;</span><br><span class="line">    T <span class="title function_">reduce</span><span class="params">(T value1, T value2)</span> <span class="keyword">throws</span> Exception;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h5 id="ReduceFunction接口里需要实现reduce-方法，这个方法接收两个输入事件，经过转换处理之后输出一个相同类型的事件。在流处理的底层实现过程中，实际上是将中间“合并的结果”作为任务的一个状态保存起来的；之后每来一个新的数据，就和之前的聚合状态进一步做归约。"><a href="#ReduceFunction接口里需要实现reduce-方法，这个方法接收两个输入事件，经过转换处理之后输出一个相同类型的事件。在流处理的底层实现过程中，实际上是将中间“合并的结果”作为任务的一个状态保存起来的；之后每来一个新的数据，就和之前的聚合状态进一步做归约。" class="headerlink" title="ReduceFunction接口里需要实现reduce()方法，这个方法接收两个输入事件，经过转换处理之后输出一个相同类型的事件。在流处理的底层实现过程中，实际上是将中间“合并的结果”作为任务的一个状态保存起来的；之后每来一个新的数据，就和之前的聚合状态进一步做归约。"></a>ReduceFunction接口里需要实现reduce()方法，这个方法接收两个输入事件，经过转换处理之后输出一个相同类型的事件。在流处理的底层实现过程中，实际上是将中间“合并的结果”作为任务的一个状态保存起来的；之后每来一个新的数据，就和之前的聚合状态进一步做归约。</h5><h5 id="我们可以单独定义一个函数类实现ReduceFunction接口，也可以直接传入一个匿名类。当然，同样也可以通过传入Lambda表达式实现类似的功能。"><a href="#我们可以单独定义一个函数类实现ReduceFunction接口，也可以直接传入一个匿名类。当然，同样也可以通过传入Lambda表达式实现类似的功能。" class="headerlink" title="我们可以单独定义一个函数类实现ReduceFunction接口，也可以直接传入一个匿名类。当然，同样也可以通过传入Lambda表达式实现类似的功能。"></a>我们可以单独定义一个函数类实现ReduceFunction接口，也可以直接传入一个匿名类。当然，同样也可以通过传入Lambda表达式实现类似的功能。</h5><h5 id="为了方便后续使用，定义一个WaterSensorMapFunction："><a href="#为了方便后续使用，定义一个WaterSensorMapFunction：" class="headerlink" title="为了方便后续使用，定义一个WaterSensorMapFunction："></a>为了方便后续使用，定义一个WaterSensorMapFunction：</h5><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">WaterSensorMapFunction</span> <span class="keyword">implements</span> <span class="title class_">MapFunction</span>&lt;String,WaterSensor&gt; &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> WaterSensor <span class="title function_">map</span><span class="params">(String value)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        String[] datas = value.split(<span class="string">&quot;,&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">WaterSensor</span>(datas[<span class="number">0</span>],Long.valueOf(datas[<span class="number">1</span>]) ,Integer.valueOf(datas[<span class="number">2</span>]) );</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h5 id="案例：使用reduce实现max和maxBy的功能。"><a href="#案例：使用reduce实现max和maxBy的功能。" class="headerlink" title="案例：使用reduce实现max和maxBy的功能。"></a>案例：使用reduce实现max和maxBy的功能。</h5><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.day02</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.day02.<span class="type">SourceBoundedTest</span>.<span class="type">Event</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.functions.<span class="type">ReduceFunction</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.scala._</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">TransformReduceTest</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> env = <span class="type">StreamExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line">    env.setParallelism(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> stream: <span class="type">DataStream</span>[<span class="type">Event</span>] = env.fromElements(</span><br><span class="line">      <span class="type">Event</span>(<span class="string">&quot;hkj&quot;</span>, <span class="string">&quot;www.baidu.com&quot;</span>, <span class="number">1000</span>L),</span><br><span class="line">      <span class="type">Event</span>(<span class="string">&quot;Bob&quot;</span>, <span class="string">&quot;www.bing.com&quot;</span>, <span class="number">2000</span>L),</span><br><span class="line">      <span class="type">Event</span>(<span class="string">&quot;Bob&quot;</span>, <span class="string">&quot;www.bing.com&quot;</span>, <span class="number">2000</span>L),</span><br><span class="line">      <span class="type">Event</span>(<span class="string">&quot;Lisa&quot;</span>, <span class="string">&quot;www.hkjcpdd.com&quot;</span>, <span class="number">3000</span>L),</span><br><span class="line">      <span class="type">Event</span>(<span class="string">&quot;Lisa&quot;</span>, <span class="string">&quot;www.hkjcpdd.com&quot;</span>, <span class="number">3000</span>L),</span><br><span class="line">      <span class="type">Event</span>(<span class="string">&quot;Lisa&quot;</span>, <span class="string">&quot;www.hkjcpdd.com&quot;</span>, <span class="number">3000</span>L),</span><br><span class="line">      <span class="type">Event</span>(<span class="string">&quot;hkj&quot;</span>, <span class="string">&quot;www.by123.com&quot;</span>, <span class="number">8000</span>L),</span><br><span class="line">      <span class="type">Event</span>(<span class="string">&quot;Lisa&quot;</span>, <span class="string">&quot;www.hkjmjj.com&quot;</span>, <span class="number">1000</span>L)</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="comment">// reduce归约聚合,提取当前最活跃用户</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//    data =&gt; true 的作用</span></span><br><span class="line"><span class="comment">//    1.keyBy 的作用：keyBy 是 Flink 中的一个算子，用于将数据流按照指定的键进行分组。</span></span><br><span class="line"><span class="comment">//                  分组后，相同键的数据会被分配到同一个分区中。</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//    2.data =&gt; true 的含义：</span></span><br><span class="line"><span class="comment">//              这里的 data =&gt; true 是一个匿名函数，它对每条数据返回固定的 true 值。</span></span><br><span class="line"><span class="comment">//              由于所有数据的键都是 true，因此所有数据都会被分配到同一个分区中。</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//    3.为什么需要 data =&gt; true：</span></span><br><span class="line"><span class="comment">//          在统计最活跃用户时，需要将所有用户的活跃度数据集中到一个分区中，才能进行比较和筛选。</span></span><br><span class="line"><span class="comment">//          如果不使用 keyBy(data =&gt; true)，数据会分散在多个分区中，无法直接进行比较。</span></span><br><span class="line"></span><br><span class="line">    stream.map( data =&gt; (data.user, <span class="number">1</span>L) )</span><br><span class="line">      .keyBy(_._1)</span><br><span class="line">      .reduce( <span class="keyword">new</span> <span class="type">MySum</span> )  <span class="comment">// 统计每个用户的活跃度</span></span><br><span class="line">      .keyBy(data =&gt; <span class="literal">true</span>)  <span class="comment">// 将所有数据按照同样的key分到同一个组中</span></span><br><span class="line">      .reduce( (state, data) =&gt; <span class="keyword">if</span> (data._2 &gt;= state._2) data <span class="keyword">else</span> state ) <span class="comment">// 选取当前最活跃的用户</span></span><br><span class="line">      .print()</span><br><span class="line"></span><br><span class="line">    env.execute()</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="class"><span class="keyword">class</span> <span class="title">MySum</span> <span class="keyword">extends</span> <span class="title">ReduceFunction</span>[(<span class="type">String</span>, <span class="type">Long</span>)] </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">reduce</span></span>(value1: (<span class="type">String</span>, <span class="type">Long</span>), value2: (<span class="type">String</span>, <span class="type">Long</span>)): (<span class="type">String</span>, <span class="type">Long</span>) = (value1._1, value2._2 + value1._2)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h5 id="reduce同简单聚合算子一样，也要针对每一个key保存状态。因为状态不会清空，所以我们需要将reduce算子作用在一个有限key的流上。"><a href="#reduce同简单聚合算子一样，也要针对每一个key保存状态。因为状态不会清空，所以我们需要将reduce算子作用在一个有限key的流上。" class="headerlink" title="reduce同简单聚合算子一样，也要针对每一个key保存状态。因为状态不会清空，所以我们需要将reduce算子作用在一个有限key的流上。"></a>reduce同简单聚合算子一样，也要针对每一个key保存状态。因为状态不会清空，所以我们需要将reduce算子作用在一个有限key的流上。</h5><h3 id="1-3-3-用户自定义函数（UDF）"><a href="#1-3-3-用户自定义函数（UDF）" class="headerlink" title="1.3.3 用户自定义函数（UDF）"></a>1.3.3 用户自定义函数（UDF）</h3><h5 id="用户自定义函数（user-defined-function，UDF），即用户可以根据自身需求，重新实现算子的逻辑。"><a href="#用户自定义函数（user-defined-function，UDF），即用户可以根据自身需求，重新实现算子的逻辑。" class="headerlink" title="用户自定义函数（user-defined function，UDF），即用户可以根据自身需求，重新实现算子的逻辑。"></a>用户自定义函数（user-defined function，UDF），即用户可以根据自身需求，重新实现算子的逻辑。</h5><h5 id="用户自定义函数分为：函数类、匿名函数、富函数类。"><a href="#用户自定义函数分为：函数类、匿名函数、富函数类。" class="headerlink" title="用户自定义函数分为：函数类、匿名函数、富函数类。"></a>用户自定义函数分为：函数类、匿名函数、富函数类。</h5><h4 id="需求：用来从用户的点击数据中筛选包含“sensor-1”的内容："><a href="#需求：用来从用户的点击数据中筛选包含“sensor-1”的内容：" class="headerlink" title="需求：用来从用户的点击数据中筛选包含“sensor_1”的内容："></a><strong>需求：</strong>用来从用户的点击数据中筛选包含“sensor_1”的内容：</h4><h4 id="方式一：实现FilterFunction接口"><a href="#方式一：实现FilterFunction接口" class="headerlink" title="方式一：实现FilterFunction接口"></a><strong>方式一：</strong>实现FilterFunction接口</h4><h4 id="方式二：通过匿名类来实现FilterFunction接口："><a href="#方式二：通过匿名类来实现FilterFunction接口：" class="headerlink" title="方式二：通过匿名类来实现FilterFunction接口："></a><strong>方式二：</strong>通过匿名类来实现FilterFunction接口：</h4><h5 id="方式二的优化：为了类可以更加通用，我们还可以将用于过滤的关键字”home”抽象出来作为类的属性，调用构造方法时传进去。"><a href="#方式二的优化：为了类可以更加通用，我们还可以将用于过滤的关键字”home”抽象出来作为类的属性，调用构造方法时传进去。" class="headerlink" title="方式二的优化：为了类可以更加通用，我们还可以将用于过滤的关键字”home”抽象出来作为类的属性，调用构造方法时传进去。"></a><strong>方式二的优化：</strong>为了类可以更加通用，我们还可以将用于过滤的关键字”home”抽象出来作为类的属性，调用构造方法时传进去。</h5><h5 id="方式三：采用匿名函数（Lambda）"><a href="#方式三：采用匿名函数（Lambda）" class="headerlink" title="方式三：采用匿名函数（Lambda）"></a><strong>方式三：</strong>采用匿名函数（Lambda）</h5><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.day02</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.day02.<span class="type">SourceBoundedTest</span>.<span class="type">Event</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.functions.<span class="type">FilterFunction</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.scala._</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">TransformUDFTest</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> env = <span class="type">StreamExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line">    env.setParallelism(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> stream: <span class="type">DataStream</span>[<span class="type">Event</span>] = env.fromElements(</span><br><span class="line">      <span class="type">Event</span>(<span class="string">&quot;hkj&quot;</span>, <span class="string">&quot;www.baidu.com&quot;</span>, <span class="number">1000</span>L),</span><br><span class="line">      <span class="type">Event</span>(<span class="string">&quot;Bob&quot;</span>, <span class="string">&quot;www.bing.com&quot;</span>, <span class="number">2000</span>L),</span><br><span class="line">      <span class="type">Event</span>(<span class="string">&quot;Bob&quot;</span>, <span class="string">&quot;www.bing.com&quot;</span>, <span class="number">2000</span>L),</span><br><span class="line">      <span class="type">Event</span>(<span class="string">&quot;Lisa&quot;</span>, <span class="string">&quot;www.hkjcpdd.com&quot;</span>, <span class="number">3000</span>L),</span><br><span class="line">      <span class="type">Event</span>(<span class="string">&quot;Lisa&quot;</span>, <span class="string">&quot;www.hkjcpdd.com&quot;</span>, <span class="number">3000</span>L),</span><br><span class="line">      <span class="type">Event</span>(<span class="string">&quot;Lisa&quot;</span>, <span class="string">&quot;www.hkjcpdd.com&quot;</span>, <span class="number">3000</span>L),</span><br><span class="line">      <span class="type">Event</span>(<span class="string">&quot;hkj&quot;</span>, <span class="string">&quot;www.by123.com&quot;</span>, <span class="number">8000</span>L),</span><br><span class="line">      <span class="type">Event</span>(<span class="string">&quot;Lisa&quot;</span>, <span class="string">&quot;www.hkjmjj.com&quot;</span>, <span class="number">1000</span>L)</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 测试UDF的用法,筛选url中包含某个关键字hkjcpdd的Event事件</span></span><br><span class="line">    <span class="comment">// 1.实现一个自定义的函数类</span></span><br><span class="line">    stream.filter( <span class="keyword">new</span> <span class="type">MyFilterFunction</span>(<span class="string">&quot;hkjcpdd&quot;</span>) ).print(<span class="string">&quot;1&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 2. 使用匿名类</span></span><br><span class="line">    stream.filter( <span class="keyword">new</span> <span class="type">FilterFunction</span>[<span class="type">Event</span>] &#123;</span><br><span class="line">      <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">filter</span></span>(value: <span class="type">Event</span>): <span class="type">Boolean</span> = value.url.contains(<span class="string">&quot;hkjmjj&quot;</span>)</span><br><span class="line">    &#125; ).print(<span class="string">&quot;2&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 3. 使用lambda表达式</span></span><br><span class="line">    stream.filter( _.url.contains(<span class="string">&quot;hkjmjj&quot;</span>) ).print()</span><br><span class="line"></span><br><span class="line">    env.execute()</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 实现自定义个filterfunction</span></span><br><span class="line">  <span class="class"><span class="keyword">class</span> <span class="title">MyFilterFunction</span>(<span class="params">keyWord: <span class="type">String</span></span>) <span class="keyword">extends</span> <span class="title">FilterFunction</span>[<span class="type">Event</span>] </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// contains是指是否包含某些字段</span></span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">filter</span></span>(value: <span class="type">Event</span>): <span class="type">Boolean</span> = value.url.contains(keyWord)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h4 id="1-3-2-富函数类（Rich-Function-Classes）"><a href="#1-3-2-富函数类（Rich-Function-Classes）" class="headerlink" title="1.3.2 富函数类（Rich Function Classes）"></a>1.3.2 富函数类（Rich Function Classes）</h4><h6 id="“富函数类”也是DataStream-API提供的一个函数类的接口，所有的Flink函数类都有其Rich版本。富函数类一般是以抽象类的形式出现的。例如：RichMapFunction、RichFilterFunction、RichReduceFunction等。"><a href="#“富函数类”也是DataStream-API提供的一个函数类的接口，所有的Flink函数类都有其Rich版本。富函数类一般是以抽象类的形式出现的。例如：RichMapFunction、RichFilterFunction、RichReduceFunction等。" class="headerlink" title="“富函数类”也是DataStream API提供的一个函数类的接口，所有的Flink函数类都有其Rich版本。富函数类一般是以抽象类的形式出现的。例如：RichMapFunction、RichFilterFunction、RichReduceFunction等。"></a>“富函数类”也是DataStream API提供的一个函数类的接口，所有的Flink函数类都有其Rich版本。富函数类一般是以抽象类的形式出现的。例如：RichMapFunction、RichFilterFunction、RichReduceFunction等。</h6><h6 id="与常规函数类的不同主要在于，富函数类可以获取运行环境的上下文，并拥有一些生命周期方法，所以可以实现更复杂的功能。"><a href="#与常规函数类的不同主要在于，富函数类可以获取运行环境的上下文，并拥有一些生命周期方法，所以可以实现更复杂的功能。" class="headerlink" title="与常规函数类的不同主要在于，富函数类可以获取运行环境的上下文，并拥有一些生命周期方法，所以可以实现更复杂的功能。"></a>与常规函数类的不同主要在于，富函数类可以获取运行环境的上下文，并拥有一些生命周期方法，所以可以实现更复杂的功能。</h6><h6 id="Rich-Function有生命周期的概念。典型的生命周期方法有："><a href="#Rich-Function有生命周期的概念。典型的生命周期方法有：" class="headerlink" title="Rich Function有生命周期的概念。典型的生命周期方法有："></a>Rich Function有生命周期的概念。典型的生命周期方法有：</h6><ul>
<li><h6 id="open-方法，是Rich-Function的初始化方法，也就是会开启一个算子的生命周期。当一个算子的实际工作方法例如map-或者filter-方法被调用之前，open-会首先被调用。"><a href="#open-方法，是Rich-Function的初始化方法，也就是会开启一个算子的生命周期。当一个算子的实际工作方法例如map-或者filter-方法被调用之前，open-会首先被调用。" class="headerlink" title="open()方法，是Rich Function的初始化方法，也就是会开启一个算子的生命周期。当一个算子的实际工作方法例如map()或者filter()方法被调用之前，open()会首先被调用。"></a>open()方法，是Rich Function的初始化方法，也就是会开启一个算子的生命周期。当一个算子的实际工作方法例如map()或者filter()方法被调用之前，open()会首先被调用。</h6></li>
<li><h6 id="close-方法，是生命周期中的最后一个调用的方法，类似于结束方法。一般用来做一些清理工作。"><a href="#close-方法，是生命周期中的最后一个调用的方法，类似于结束方法。一般用来做一些清理工作。" class="headerlink" title="close()方法，是生命周期中的最后一个调用的方法，类似于结束方法。一般用来做一些清理工作。"></a>close()方法，是生命周期中的最后一个调用的方法，类似于结束方法。一般用来做一些清理工作。</h6></li>
</ul>
<h6 id="需要注意的是，这里的生命周期方法，对于一个并行子任务来说只会调用一次；而对应的，实际工作方法，例如RichMapFunction中的map-，在每条数据到来后都会触发一次调用。"><a href="#需要注意的是，这里的生命周期方法，对于一个并行子任务来说只会调用一次；而对应的，实际工作方法，例如RichMapFunction中的map-，在每条数据到来后都会触发一次调用。" class="headerlink" title="需要注意的是，这里的生命周期方法，对于一个并行子任务来说只会调用一次；而对应的，实际工作方法，例如RichMapFunction中的map()，在每条数据到来后都会触发一次调用。"></a>需要注意的是，这里的生命周期方法，对于一个并行子任务来说只会调用一次；而对应的，实际工作方法，例如RichMapFunction中的map()，在每条数据到来后都会触发一次调用。</h6><h6 id="来看一个例子说明："><a href="#来看一个例子说明：" class="headerlink" title="来看一个例子说明："></a>来看一个例子说明：</h6><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.day02</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.day02.<span class="type">SourceBoundedTest</span>.<span class="type">Event</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.functions.<span class="type">RichMapFunction</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.configuration.<span class="type">Configuration</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.scala._</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">TransformRichFunctionTest</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> env = <span class="type">StreamExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line">    env.setParallelism(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> stream: <span class="type">DataStream</span>[<span class="type">Event</span>] = env.fromElements(</span><br><span class="line">      <span class="type">Event</span>(<span class="string">&quot;hkj&quot;</span>, <span class="string">&quot;www.baidu.com&quot;</span>, <span class="number">1000</span>L),</span><br><span class="line">      <span class="type">Event</span>(<span class="string">&quot;Bob&quot;</span>, <span class="string">&quot;www.bing.com&quot;</span>, <span class="number">2000</span>L),</span><br><span class="line">      <span class="type">Event</span>(<span class="string">&quot;Bob&quot;</span>, <span class="string">&quot;www.bing.com&quot;</span>, <span class="number">2000</span>L),</span><br><span class="line">      <span class="type">Event</span>(<span class="string">&quot;Lisa&quot;</span>, <span class="string">&quot;www.hkjcpdd.com&quot;</span>, <span class="number">3000</span>L),</span><br><span class="line">      <span class="type">Event</span>(<span class="string">&quot;Lisa&quot;</span>, <span class="string">&quot;www.hkjcpdd.com&quot;</span>, <span class="number">3000</span>L),</span><br><span class="line">      <span class="type">Event</span>(<span class="string">&quot;Lisa&quot;</span>, <span class="string">&quot;www.hkjcpdd.com&quot;</span>, <span class="number">3000</span>L),</span><br><span class="line">      <span class="type">Event</span>(<span class="string">&quot;hkj&quot;</span>, <span class="string">&quot;www.by123.com&quot;</span>, <span class="number">8000</span>L),</span><br><span class="line">      <span class="type">Event</span>(<span class="string">&quot;Lisa&quot;</span>, <span class="string">&quot;www.hkjmjj.com&quot;</span>, <span class="number">1000</span>L)</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 自定义一个RichMapFunction，测试复函数类的功能</span></span><br><span class="line">    stream.map( <span class="keyword">new</span> <span class="type">MyRichMap</span>() ).print()</span><br><span class="line"></span><br><span class="line">    env.execute()</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="class"><span class="keyword">class</span> <span class="title">MyRichMap</span>(<span class="params"></span>) <span class="keyword">extends</span> <span class="title">RichMapFunction</span>[<span class="type">Event</span>, <span class="type">Long</span>] </span>&#123;</span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">open</span></span>(parameters: <span class="type">Configuration</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">      println(<span class="string">&quot;索引号为：&quot;</span> + getRuntimeContext.getIndexOfThisSubtask + <span class="string">&quot;的任务开始&quot;</span>)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">map</span></span>(value: <span class="type">Event</span>): <span class="type">Long</span> = value.timestamp</span><br><span class="line"></span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">close</span></span>(): <span class="type">Unit</span> = &#123;</span><br><span class="line">      println(<span class="string">&quot;索引号为：&quot;</span> + getRuntimeContext.getIndexOfThisSubtask + <span class="string">&quot;的任务结束&quot;</span>)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h3 id="5-3-4-物理分区算子（Physical-Partitioning）"><a href="#5-3-4-物理分区算子（Physical-Partitioning）" class="headerlink" title="5.3.4 物理分区算子（Physical Partitioning）"></a>5.3.4 物理分区算子（Physical Partitioning）</h3><h5 id="常见的物理分区策略有：随机分配（Random）、轮询分配（Round-Robin）、重缩放（Rescale）和广播（Broadcast）。"><a href="#常见的物理分区策略有：随机分配（Random）、轮询分配（Round-Robin）、重缩放（Rescale）和广播（Broadcast）。" class="headerlink" title="常见的物理分区策略有：随机分配（Random）、轮询分配（Round-Robin）、重缩放（Rescale）和广播（Broadcast）。"></a>常见的物理分区策略有：随机分配（Random）、轮询分配（Round-Robin）、重缩放（Rescale）和广播（Broadcast）。</h5><h3 id="1-4-1-随机分区（shuffle）"><a href="#1-4-1-随机分区（shuffle）" class="headerlink" title="1.4.1 随机分区（shuffle）"></a>1.4.1 随机分区（shuffle）</h3><h5 id="最简单的重分区方式就是直接“洗牌”。通过调用DataStream的-shuffle-方法，将数据随机地分配到下游算子的并行任务中去。"><a href="#最简单的重分区方式就是直接“洗牌”。通过调用DataStream的-shuffle-方法，将数据随机地分配到下游算子的并行任务中去。" class="headerlink" title="最简单的重分区方式就是直接“洗牌”。通过调用DataStream的.shuffle()方法，将数据随机地分配到下游算子的并行任务中去。"></a>最简单的重分区方式就是直接“洗牌”。通过调用DataStream的.shuffle()方法，将数据随机地分配到下游算子的并行任务中去。</h5><h5 id="随机分区服从均匀分布（uniform-distribution），所以可以把流中的数据随机打乱，均匀地传递到下游任务分区。因为是完全随机的，所以对于同样的输入数据-每次执行得到的结果也不会相同。"><a href="#随机分区服从均匀分布（uniform-distribution），所以可以把流中的数据随机打乱，均匀地传递到下游任务分区。因为是完全随机的，所以对于同样的输入数据-每次执行得到的结果也不会相同。" class="headerlink" title="随机分区服从均匀分布（uniform distribution），所以可以把流中的数据随机打乱，均匀地传递到下游任务分区。因为是完全随机的，所以对于同样的输入数据, 每次执行得到的结果也不会相同。"></a>随机分区服从均匀分布（uniform distribution），所以可以把流中的数据随机打乱，均匀地传递到下游任务分区。因为是完全随机的，所以对于同样的输入数据, 每次执行得到的结果也不会相同。</h5><p><img src= "/imgs/loading/loading.gif" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://pic1.imgdb.cn/item/67862896d0e0a243d4f42d1b.png"></p>
<h5 id="经过随机分区之后，得到的依然是一个DataStream。"><a href="#经过随机分区之后，得到的依然是一个DataStream。" class="headerlink" title="经过随机分区之后，得到的依然是一个DataStream。"></a>经过随机分区之后，得到的依然是一个DataStream。</h5><h5 id="我们可以做个简单测试：将数据读入之后直接打印到控制台，将输出的并行度设置为2，中间经历一次shuffle。执行多次，观察结果是否相同。"><a href="#我们可以做个简单测试：将数据读入之后直接打印到控制台，将输出的并行度设置为2，中间经历一次shuffle。执行多次，观察结果是否相同。" class="headerlink" title="我们可以做个简单测试：将数据读入之后直接打印到控制台，将输出的并行度设置为2，中间经历一次shuffle。执行多次，观察结果是否相同。"></a>我们可以做个简单测试：将数据读入之后直接打印到控制台，将输出的并行度设置为2，中间经历一次shuffle。执行多次，观察结果是否相同。</h5><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">ShuffleExample</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line"></span><br><span class="line">        <span class="type">StreamExecutionEnvironment</span> <span class="variable">env</span> <span class="operator">=</span> StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line"></span><br><span class="line">		 env.setParallelism(<span class="number">2</span>);</span><br><span class="line"></span><br><span class="line">        DataStreamSource&lt;Integer&gt; stream = env.socketTextStream(<span class="string">&quot;hadoop102&quot;</span>, <span class="number">7777</span>);;</span><br><span class="line"></span><br><span class="line">        stream.shuffle().print()</span><br><span class="line"></span><br><span class="line">        env.execute();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="1-4-2-轮询分区（Round-Robin）"><a href="#1-4-2-轮询分区（Round-Robin）" class="headerlink" title="1.4.2 轮询分区（Round-Robin）"></a>1.4.2 轮询分区（Round-Robin）</h4><h5 id="轮询，简单来说就是“发牌”，按照先后顺序将数据做依次分发。通过调用DataStream的-rebalance-方法，就可以实现轮询重分区。rebalance使用的是Round-Robin负载均衡算法，可以将输入流数据平均分配到下游的并行任务中去。"><a href="#轮询，简单来说就是“发牌”，按照先后顺序将数据做依次分发。通过调用DataStream的-rebalance-方法，就可以实现轮询重分区。rebalance使用的是Round-Robin负载均衡算法，可以将输入流数据平均分配到下游的并行任务中去。" class="headerlink" title="轮询，简单来说就是“发牌”，按照先后顺序将数据做依次分发。通过调用DataStream的.rebalance()方法，就可以实现轮询重分区。rebalance使用的是Round-Robin负载均衡算法，可以将输入流数据平均分配到下游的并行任务中去。"></a>轮询，简单来说就是“发牌”，按照先后顺序将数据做依次分发。通过调用DataStream的.rebalance()方法，就可以实现轮询重分区。rebalance使用的是Round-Robin负载均衡算法，可以将输入流数据平均分配到下游的并行任务中去。</h5><p><img src= "/imgs/loading/loading.gif" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://pic1.imgdb.cn/item/678628c7d0e0a243d4f42d3e.png"></p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">stream.rebalance()</span><br></pre></td></tr></table></figure>

<h4 id="1-4-3-重缩放分区（rescale）"><a href="#1-4-3-重缩放分区（rescale）" class="headerlink" title="1.4.3 重缩放分区（rescale）"></a>1.4.3 重缩放分区（rescale）</h4><h5 id="重缩放分区和轮询分区非常相似。当调用rescale-方法时，其实底层也是使用Round-Robin算法进行轮询，但是只会将数据轮询发送到下游并行任务的一部分中。rescale的做法是分成小团体，发牌人只给自己团体内的所有人轮流发牌。"><a href="#重缩放分区和轮询分区非常相似。当调用rescale-方法时，其实底层也是使用Round-Robin算法进行轮询，但是只会将数据轮询发送到下游并行任务的一部分中。rescale的做法是分成小团体，发牌人只给自己团体内的所有人轮流发牌。" class="headerlink" title="重缩放分区和轮询分区非常相似。当调用rescale()方法时，其实底层也是使用Round-Robin算法进行轮询，但是只会将数据轮询发送到下游并行任务的一部分中。rescale的做法是分成小团体，发牌人只给自己团体内的所有人轮流发牌。"></a>重缩放分区和轮询分区非常相似。当调用rescale()方法时，其实底层也是使用Round-Robin算法进行轮询，但是只会将数据轮询发送到下游并行任务的一部分中。rescale的做法是分成小团体，发牌人只给自己团体内的所有人轮流发牌。</h5><p><img src= "/imgs/loading/loading.gif" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://pic1.imgdb.cn/item/678628e9d0e0a243d4f42d59.png"></p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">stream.rescale()</span><br></pre></td></tr></table></figure>

<h4 id="1-4-4-广播（broadcast）"><a href="#1-4-4-广播（broadcast）" class="headerlink" title="1.4.4 广播（broadcast）"></a>1.4.4 广播（broadcast）</h4><h5 id="这种方式其实不应该叫做“重分区”，因为经过广播之后，数据会在不同的分区都保留一份，可能进行重复处理。可以通过调用DataStream的broadcast-方法，将输入数据复制并发送到下游算子的所有并行任务中去。"><a href="#这种方式其实不应该叫做“重分区”，因为经过广播之后，数据会在不同的分区都保留一份，可能进行重复处理。可以通过调用DataStream的broadcast-方法，将输入数据复制并发送到下游算子的所有并行任务中去。" class="headerlink" title="这种方式其实不应该叫做“重分区”，因为经过广播之后，数据会在不同的分区都保留一份，可能进行重复处理。可以通过调用DataStream的broadcast()方法，将输入数据复制并发送到下游算子的所有并行任务中去。"></a>这种方式其实不应该叫做“重分区”，因为经过广播之后，数据会在不同的分区都保留一份，可能进行重复处理。可以通过调用DataStream的broadcast()方法，将输入数据复制并发送到下游算子的所有并行任务中去。</h5><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">stream.broadcast()</span><br></pre></td></tr></table></figure>



<h4 id="1-4-5-全局分区（global）"><a href="#1-4-5-全局分区（global）" class="headerlink" title="1.4.5 全局分区（global）"></a>1.4.5 全局分区（global）</h4><h5 id="全局分区也是一种特殊的分区方式。这种做法非常极端，通过调用-global-方法，会将所有的输入流数据都发送到下游算子的第一个并行子任务中去。这就相当于强行让下游任务并行度变成了1，所以使用这个操作需要非常谨慎，可能对程序造成很大的压力。"><a href="#全局分区也是一种特殊的分区方式。这种做法非常极端，通过调用-global-方法，会将所有的输入流数据都发送到下游算子的第一个并行子任务中去。这就相当于强行让下游任务并行度变成了1，所以使用这个操作需要非常谨慎，可能对程序造成很大的压力。" class="headerlink" title="全局分区也是一种特殊的分区方式。这种做法非常极端，通过调用.global()方法，会将所有的输入流数据都发送到下游算子的第一个并行子任务中去。这就相当于强行让下游任务并行度变成了1，所以使用这个操作需要非常谨慎，可能对程序造成很大的压力。"></a>全局分区也是一种特殊的分区方式。这种做法非常极端，通过调用.global()方法，会将所有的输入流数据都发送到下游算子的第一个并行子任务中去。这就相当于强行让下游任务并行度变成了1，所以使用这个操作需要非常谨慎，可能对程序造成很大的压力。</h5><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">stream.global()</span><br></pre></td></tr></table></figure>



<h4 id="1-4-6-自定义分区（Custom）"><a href="#1-4-6-自定义分区（Custom）" class="headerlink" title="1.4.6 自定义分区（Custom）"></a>1.4.6 自定义分区（Custom）</h4><h5 id="当Flink提供的所有分区策略都不能满足用户的需求时，我们可以通过使用partitionCustom-方法来自定义分区策略。"><a href="#当Flink提供的所有分区策略都不能满足用户的需求时，我们可以通过使用partitionCustom-方法来自定义分区策略。" class="headerlink" title="当Flink提供的所有分区策略都不能满足用户的需求时，我们可以通过使用partitionCustom()方法来自定义分区策略。"></a>当Flink提供的所有分区策略都不能满足用户的需求时，我们可以通过使用partitionCustom()方法来自定义分区策略。</h5><h4 id="1-自定义分区器"><a href="#1-自定义分区器" class="headerlink" title="1)自定义分区器"></a>1)自定义分区器</h4><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.day02</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.day02.<span class="type">SourceBoundedTest</span>.<span class="type">Event</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.functions.source.&#123;<span class="type">ParallelSourceFunction</span>, <span class="type">SourceFunction</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.watermark.<span class="type">Watermark</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.<span class="type">Calendar</span></span><br><span class="line"><span class="keyword">import</span> scala.util.<span class="type">Random</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//SourceFunction是并行度1的</span></span><br><span class="line"><span class="comment">//ParallelSourceFunction就是并行多的</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ClickSource</span> <span class="keyword">extends</span> <span class="title">ParallelSourceFunction</span>[<span class="type">Event</span>] </span>&#123;</span><br><span class="line">  <span class="comment">// 标志位</span></span><br><span class="line">  <span class="keyword">var</span> running = <span class="literal">true</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">run</span></span>(ctx: <span class="type">SourceFunction</span>.<span class="type">SourceContext</span>[<span class="type">Event</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">// 随机数生成器</span></span><br><span class="line">    <span class="keyword">val</span> random = <span class="keyword">new</span> <span class="type">Random</span>()</span><br><span class="line">    <span class="comment">// 定义数据随机选择的范围</span></span><br><span class="line">    <span class="keyword">val</span> users = <span class="type">Array</span>(<span class="string">&quot;Marry&quot;</span>, <span class="string">&quot;Hkj&quot;</span>, <span class="string">&quot;Bob&quot;</span>, <span class="string">&quot;Cary&quot;</span>)</span><br><span class="line">    <span class="keyword">val</span> urls = <span class="type">Array</span>(<span class="string">&quot;./home&quot;</span>, <span class="string">&quot;./cart&quot;</span>, <span class="string">&quot;./fav&quot;</span>, <span class="string">&quot;./prod?id=1&quot;</span>, <span class="string">&quot;./prod?id=2&quot;</span>,<span class="string">&quot;./prod?id=3&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 关键流程， 用标志位作为循环的判断条件，不停的发出数据</span></span><br><span class="line">    <span class="keyword">while</span> (running) &#123;</span><br><span class="line">      <span class="keyword">val</span> event = <span class="type">Event</span>(</span><br><span class="line">        users(random.nextInt(users.length)),</span><br><span class="line">        urls(random.nextInt(users.length)),</span><br><span class="line">        <span class="type">Calendar</span>.getInstance.getTimeInMillis</span><br><span class="line">      )</span><br><span class="line"><span class="comment">//      // 为要发送的数据分配时间戳</span></span><br><span class="line"><span class="comment">//      ctx.collectWithTimestamp(event, event.timestamp)</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">//      // 向下游直接发送水位线</span></span><br><span class="line"><span class="comment">//      ctx.emitWatermark(new Watermark(event.timestamp - 1L))</span></span><br><span class="line"></span><br><span class="line">      <span class="comment">// 调用ctx的方法向下游发送数据</span></span><br><span class="line">      ctx.collect(event)</span><br><span class="line"></span><br><span class="line">      <span class="comment">// 每隔一秒发送过一条数据</span></span><br><span class="line">      <span class="type">Thread</span>.sleep(<span class="number">1000</span>)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">cancel</span></span>(): <span class="type">Unit</span> = <span class="literal">false</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h5 id="2）使用自定义分区器"><a href="#2）使用自定义分区器" class="headerlink" title="2）使用自定义分区器"></a>2）使用自定义分区器</h5><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.day02</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.scala._</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">PartitionReblanceTest</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> env = <span class="type">StreamExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line">    env.setParallelism(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 读取自定义的数据流</span></span><br><span class="line">    <span class="keyword">val</span> stream = env.addSource(<span class="keyword">new</span> <span class="type">ClickSource</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 轮询重分区之后打印输出</span></span><br><span class="line">    stream.rebalance.print(<span class="string">&quot;shuffle&quot;</span>).setParallelism(<span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">    env.execute()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h3 id="1-3-5分流"><a href="#1-3-5分流" class="headerlink" title="1.3.5分流"></a>1.3.5分流</h3><h4 id="所谓“分流”，就是将一条数据流拆分成完全独立的两条、甚至多条流。也就是基于一个DataStream，定义一些筛选条件，将符合条件的数据拣选出来放到对应的流里。"><a href="#所谓“分流”，就是将一条数据流拆分成完全独立的两条、甚至多条流。也就是基于一个DataStream，定义一些筛选条件，将符合条件的数据拣选出来放到对应的流里。" class="headerlink" title="所谓“分流”，就是将一条数据流拆分成完全独立的两条、甚至多条流。也就是基于一个DataStream，定义一些筛选条件，将符合条件的数据拣选出来放到对应的流里。"></a>所谓“分流”，就是将一条数据流拆分成完全独立的两条、甚至多条流。也就是基于一个DataStream，定义一些筛选条件，将符合条件的数据拣选出来放到对应的流里。</h4><p><img src= "/imgs/loading/loading.gif" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://pic1.imgdb.cn/item/6786298ad0e0a243d4f42daf.png"></p>
<h4 id="1-3-5-1-简单实现"><a href="#1-3-5-1-简单实现" class="headerlink" title="1.3.5.1 简单实现"></a>1.3.5.1 简单实现</h4><p>其实根据条件筛选数据的需求，本身非常容易实现：只要针对同一条流多次独立调用.filter()方法进行筛选，就可以得到拆分之后的流了。</p>
<p><strong>案例需求：</strong>读取一个整数数字流，将数据流划分为奇数流和偶数流。</p>
<p><strong>代码实现：</strong></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SplitStreamByFilter</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line">        <span class="type">StreamExecutionEnvironment</span> <span class="variable">env</span> <span class="operator">=</span> StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line">      </span><br><span class="line">        SingleOutputStreamOperator&lt;Integer&gt; ds = env.socketTextStream(<span class="string">&quot;hadoop102&quot;</span>, <span class="number">7777</span>)</span><br><span class="line">                                                           .map(Integer::valueOf);</span><br><span class="line">        <span class="comment">//将ds 分为两个流 ，一个是奇数流，一个是偶数流</span></span><br><span class="line">        <span class="comment">//使用filter 过滤两次</span></span><br><span class="line">        SingleOutputStreamOperator&lt;Integer&gt; ds1 = ds.filter(x -&gt; x % <span class="number">2</span> == <span class="number">0</span>);</span><br><span class="line">        SingleOutputStreamOperator&lt;Integer&gt; ds2 = ds.filter(x -&gt; x % <span class="number">2</span> == <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">        ds1.print(<span class="string">&quot;偶数&quot;</span>);</span><br><span class="line">        ds2.print(<span class="string">&quot;奇数&quot;</span>);</span><br><span class="line">        </span><br><span class="line">        env.execute();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h5 id="这种实现非常简单，但代码显得有些冗余——我们的处理逻辑对拆分出的三条流其实是一样的，却重复写了三次。而且这段代码背后的含义，是将原始数据流stream复制三份，然后对每一份分别做筛选；这明显是不够高效的。我们自然想到，能不能不用复制流，直接用一个算子就把它们都拆分开呢？"><a href="#这种实现非常简单，但代码显得有些冗余——我们的处理逻辑对拆分出的三条流其实是一样的，却重复写了三次。而且这段代码背后的含义，是将原始数据流stream复制三份，然后对每一份分别做筛选；这明显是不够高效的。我们自然想到，能不能不用复制流，直接用一个算子就把它们都拆分开呢？" class="headerlink" title="这种实现非常简单，但代码显得有些冗余——我们的处理逻辑对拆分出的三条流其实是一样的，却重复写了三次。而且这段代码背后的含义，是将原始数据流stream复制三份，然后对每一份分别做筛选；这明显是不够高效的。我们自然想到，能不能不用复制流，直接用一个算子就把它们都拆分开呢？"></a>这种实现非常简单，但代码显得有些冗余——我们的处理逻辑对拆分出的三条流其实是一样的，却重复写了三次。而且这段代码背后的含义，是将原始数据流stream复制三份，然后对每一份分别做筛选；这明显是不够高效的。我们自然想到，能不能不用复制流，直接用一个算子就把它们都拆分开呢？</h5><h4 id="1-3-5-2-使用侧输出流"><a href="#1-3-5-2-使用侧输出流" class="headerlink" title="1.3.5.2 使用侧输出流"></a>1.3.5.2 使用侧输出流</h4><p>关于处理函数中侧输出流的用法，我们已经在7.5节做了详细介绍。简单来说，只需要调用上下文ctx的.output()方法，就可以输出任意类型的数据了。而侧输出流的标记和提取，都离不开一个“输出标签”（OutputTag），指定了侧输出流的id和类型。</p>
<p><strong>代码实现：</strong>将WaterSensor按照Id类型进行分流。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SplitStreamByOutputTag</span> &#123;    </span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        <span class="type">StreamExecutionEnvironment</span> <span class="variable">env</span> <span class="operator">=</span> StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line"></span><br><span class="line">        SingleOutputStreamOperator&lt;WaterSensor&gt; ds = env.socketTextStream(<span class="string">&quot;hadoop102&quot;</span>, <span class="number">7777</span>)</span><br><span class="line">              .map(<span class="keyword">new</span> <span class="title class_">WaterSensorMapFunction</span>());</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        OutputTag&lt;WaterSensor&gt; s1 = <span class="keyword">new</span> <span class="title class_">OutputTag</span>&lt;&gt;(<span class="string">&quot;s1&quot;</span>, Types.POJO(WaterSensor.class))&#123;&#125;;</span><br><span class="line">        OutputTag&lt;WaterSensor&gt; s2 = <span class="keyword">new</span> <span class="title class_">OutputTag</span>&lt;&gt;(<span class="string">&quot;s2&quot;</span>, Types.POJO(WaterSensor.class))&#123;&#125;;</span><br><span class="line">       <span class="comment">//返回的都是主流</span></span><br><span class="line">        SingleOutputStreamOperator&lt;WaterSensor&gt; ds1 = ds.process(<span class="keyword">new</span> <span class="title class_">ProcessFunction</span>&lt;WaterSensor, WaterSensor&gt;()</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">processElement</span><span class="params">(WaterSensor value, Context ctx, Collector&lt;WaterSensor&gt; out)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> (<span class="string">&quot;s1&quot;</span>.equals(value.getId())) &#123;</span><br><span class="line">                    ctx.output(s1, value);</span><br><span class="line">                &#125; <span class="keyword">else</span> <span class="keyword">if</span> (<span class="string">&quot;s2&quot;</span>.equals(value.getId())) &#123;</span><br><span class="line">                    ctx.output(s2, value);</span><br><span class="line">                &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                    <span class="comment">//主流</span></span><br><span class="line">                    out.collect(value);</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line"></span><br><span class="line">        ds1.print(<span class="string">&quot;主流，非s1,s2的传感器&quot;</span>);</span><br><span class="line">        SideOutputDataStream&lt;WaterSensor&gt; s1DS = ds1.getSideOutput(s1);</span><br><span class="line">        SideOutputDataStream&lt;WaterSensor&gt; s2DS = ds1.getSideOutput(s2);</span><br><span class="line"></span><br><span class="line">        s1DS.printToErr(<span class="string">&quot;s1&quot;</span>);</span><br><span class="line">        s2DS.printToErr(<span class="string">&quot;s2&quot;</span>);</span><br><span class="line">        </span><br><span class="line">        env.execute();</span><br><span class="line"> </span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h3 id="1-3-6-基本合流操作"><a href="#1-3-6-基本合流操作" class="headerlink" title="1.3.6 基本合流操作"></a><strong>1.3.6</strong> <strong>基本合流操作</strong></h3><h5 id="在实际应用中，我们经常会遇到来源不同的多条流，需要将它们的数据进行联合处理。所以Flink中合流的操作会更加普遍，对应的API也更加丰富。"><a href="#在实际应用中，我们经常会遇到来源不同的多条流，需要将它们的数据进行联合处理。所以Flink中合流的操作会更加普遍，对应的API也更加丰富。" class="headerlink" title="在实际应用中，我们经常会遇到来源不同的多条流，需要将它们的数据进行联合处理。所以Flink中合流的操作会更加普遍，对应的API也更加丰富。"></a>在实际应用中，我们经常会遇到来源不同的多条流，需要将它们的数据进行联合处理。所以Flink中合流的操作会更加普遍，对应的API也更加丰富。</h5><h3 id="1-3-6-1"><a href="#1-3-6-1" class="headerlink" title="1.3.6.1"></a>1.3.6.1</h3><h4 id="最简单的合流操作，就是直接将多条流合在一起，叫作流的“联合”（union）。联合操作要求必须流中的数据类型必须相同，合并之后的新流会包括所有流中的元素，数据类型不变。"><a href="#最简单的合流操作，就是直接将多条流合在一起，叫作流的“联合”（union）。联合操作要求必须流中的数据类型必须相同，合并之后的新流会包括所有流中的元素，数据类型不变。" class="headerlink" title="最简单的合流操作，就是直接将多条流合在一起，叫作流的“联合”（union）。联合操作要求必须流中的数据类型必须相同，合并之后的新流会包括所有流中的元素，数据类型不变。"></a>最简单的合流操作，就是直接将多条流合在一起，叫作流的“联合”（union）。联合操作要求必须流中的数据类型必须相同，合并之后的新流会包括所有流中的元素，数据类型不变。</h4><p><img src= "/imgs/loading/loading.gif" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://pic1.imgdb.cn/item/6786448fd0e0a243d4f434cf.png"></p>
<h5 id="在代码中，我们只要基于DataStream直接调用-union-方法，传入其他DataStream作为参数，就可以实现流的联合了；得到的依然是一个DataStream："><a href="#在代码中，我们只要基于DataStream直接调用-union-方法，传入其他DataStream作为参数，就可以实现流的联合了；得到的依然是一个DataStream：" class="headerlink" title="在代码中，我们只要基于DataStream直接调用.union()方法，传入其他DataStream作为参数，就可以实现流的联合了；得到的依然是一个DataStream："></a>在代码中，我们只要基于DataStream直接调用.union()方法，传入其他DataStream作为参数，就可以实现流的联合了；得到的依然是一个DataStream：</h5><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">stream1.union(stream2, stream3, ...)</span><br></pre></td></tr></table></figure>

<h4 id="注意：union-的参数可以是多个DataStream，所以联合操作可以实现多条流的合并。"><a href="#注意：union-的参数可以是多个DataStream，所以联合操作可以实现多条流的合并。" class="headerlink" title="注意：union()的参数可以是多个DataStream，所以联合操作可以实现多条流的合并。"></a>注意：union()的参数可以是多个DataStream，所以联合操作可以实现多条流的合并。</h4><p><strong>代码实现：</strong>我们可以用下面的代码做一个简单测试：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">UnionExample</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line"></span><br><span class="line">        <span class="type">StreamExecutionEnvironment</span> <span class="variable">env</span> <span class="operator">=</span> StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line"></span><br><span class="line">        env.setParallelism(<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">        DataStreamSource&lt;Integer&gt; ds1 = env.fromElements(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>);</span><br><span class="line">        DataStreamSource&lt;Integer&gt; ds2 = env.fromElements(<span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>);</span><br><span class="line">        DataStreamSource&lt;String&gt; ds3 = env.fromElements(<span class="string">&quot;2&quot;</span>, <span class="string">&quot;2&quot;</span>, <span class="string">&quot;3&quot;</span>);</span><br><span class="line"></span><br><span class="line">        ds1.union(ds2,ds3.map(Integer::valueOf))</span><br><span class="line">           .print();</span><br><span class="line"></span><br><span class="line">        env.execute();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="1-3-6-2-连接（Connect）"><a href="#1-3-6-2-连接（Connect）" class="headerlink" title="1.3.6.2 连接（Connect）"></a>1.3.6.2 连接（Connect）</h4><h4 id="流的联合虽然简单，不过受限于数据类型不能改变，灵活性大打折扣，所以实际应用较少出现。除了联合（union），Flink还提供了另外一种方便的合流操作——连接（connect）。"><a href="#流的联合虽然简单，不过受限于数据类型不能改变，灵活性大打折扣，所以实际应用较少出现。除了联合（union），Flink还提供了另外一种方便的合流操作——连接（connect）。" class="headerlink" title="流的联合虽然简单，不过受限于数据类型不能改变，灵活性大打折扣，所以实际应用较少出现。除了联合（union），Flink还提供了另外一种方便的合流操作——连接（connect）。"></a>流的联合虽然简单，不过受限于数据类型不能改变，灵活性大打折扣，所以实际应用较少出现。除了联合（union），Flink还提供了另外一种方便的合流操作——连接（connect）。</h4><h5 id="1）连接流（ConnectedStreams）"><a href="#1）连接流（ConnectedStreams）" class="headerlink" title="1）连接流（ConnectedStreams）"></a>1）连接流（ConnectedStreams）</h5><p><img src= "/imgs/loading/loading.gif" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://pic1.imgdb.cn/item/67864547d0e0a243d4f4350b.png"></p>
<p><strong>代码实现：</strong>需要分为两步：首先基于一条DataStream调用.connect()方法，传入另外一条DataStream作为参数，将两条流连接起来，得到一个ConnectedStreams；然后再调用同处理方法得到DataStream。这里可以的调用的同处理方法有.map()&#x2F;.flatMap()，以及.process()方法。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">ConnectDemo</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line"></span><br><span class="line">        <span class="type">StreamExecutionEnvironment</span> <span class="variable">env</span> <span class="operator">=</span> StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line">        env.setParallelism(<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">//        DataStreamSource&lt;Integer&gt; source1 = env.fromElements(1, 2, 3);</span></span><br><span class="line"><span class="comment">//        DataStreamSource&lt;String&gt; source2 = env.fromElements(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;);</span></span><br><span class="line"></span><br><span class="line">        SingleOutputStreamOperator&lt;Integer&gt; source1 = env</span><br><span class="line">                .socketTextStream(<span class="string">&quot;hadoop102&quot;</span>, <span class="number">7777</span>)</span><br><span class="line">                .map(i -&gt; Integer.parseInt(i));</span><br><span class="line"></span><br><span class="line">        DataStreamSource&lt;String&gt; source2 = env.socketTextStream(<span class="string">&quot;hadoop102&quot;</span>, <span class="number">8888</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">         * TODO 使用 connect 合流</span></span><br><span class="line"><span class="comment">         * 1、一次只能连接 2条流</span></span><br><span class="line"><span class="comment">         * 2、流的数据类型可以不一样</span></span><br><span class="line"><span class="comment">         * 3、 连接后可以调用 map、flatmap、process来处理，但是各处理各的</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        ConnectedStreams&lt;Integer, String&gt; connect = source1.connect(source2);</span><br><span class="line"></span><br><span class="line">        SingleOutputStreamOperator&lt;String&gt; result = connect.map(<span class="keyword">new</span> <span class="title class_">CoMapFunction</span>&lt;Integer, String, String&gt;() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="keyword">public</span> String <span class="title function_">map1</span><span class="params">(Integer value)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">                <span class="keyword">return</span> <span class="string">&quot;来源于数字流:&quot;</span> + value.toString();</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="keyword">public</span> String <span class="title function_">map2</span><span class="params">(String value)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">                <span class="keyword">return</span> <span class="string">&quot;来源于字母流:&quot;</span> + value;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line"></span><br><span class="line">        result.print();</span><br><span class="line"></span><br><span class="line">        env.execute();    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>上面的代码中，ConnectedStreams有两个类型参数，分别表示内部包含的两条流各自的数据类型；由于需要“一国两制”，因此调用.map()方法时传入的不再是一个简单的MapFunction，而是一个CoMapFunction，表示分别对两条流中的数据执行map操作。这个接口有三个类型参数，依次表示第一条流、第二条流，以及合并后的流中的数据类型。需要实现的方法也非常直白：.map1()就是对第一条流中数据的map操作，.map2()则是针对第二条流。</p>
<p>2）CoProcessFunction</p>
<p>与CoMapFunction类似，如果是调用.map()就需要传入一个CoMapFunction，需要实现map1()、map2()两个方法；而调用.process()时，传入的则是一个CoProcessFunction。它也是“处理函数”家族中的一员，用法非常相似。它需要实现的就是processElement1()、processElement2()两个方法，在每个数据到来时，会根据来源的流调用其中的一个方法进行处理。</p>
<p>值得一提的是，ConnectedStreams也可以直接调用.keyBy()进行按键分区的操作，得到的还是一个ConnectedStreams：</p>
<p>connectedStreams.keyBy(keySelector1, keySelector2);</p>
<p>这里传入两个参数keySelector1和keySelector2，是两条流中各自的键选择器；当然也可以直接传入键的位置值（keyPosition），或者键的字段名（field），这与普通的keyBy用法完全一致。ConnectedStreams进行keyBy操作，其实就是把两条流中key相同的数据放到了一起，然后针对来源的流再做各自处理，这在一些场景下非常有用。</p>
<p>案例需求：连接两条流，输出能根据id匹配上的数据（类似inner join效果）</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">ConnectKeybyDemo</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        <span class="type">StreamExecutionEnvironment</span> <span class="variable">env</span> <span class="operator">=</span> StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line">        env.setParallelism(<span class="number">2</span>);</span><br><span class="line"></span><br><span class="line">        DataStreamSource&lt;Tuple2&lt;Integer, String&gt;&gt; source1 = env.fromElements(</span><br><span class="line">                Tuple2.of(<span class="number">1</span>, <span class="string">&quot;a1&quot;</span>),</span><br><span class="line">                Tuple2.of(<span class="number">1</span>, <span class="string">&quot;a2&quot;</span>),</span><br><span class="line">                Tuple2.of(<span class="number">2</span>, <span class="string">&quot;b&quot;</span>),</span><br><span class="line">                Tuple2.of(<span class="number">3</span>, <span class="string">&quot;c&quot;</span>)</span><br><span class="line">        );</span><br><span class="line">        DataStreamSource&lt;Tuple3&lt;Integer, String, Integer&gt;&gt; source2 = env.fromElements(</span><br><span class="line">                Tuple3.of(<span class="number">1</span>, <span class="string">&quot;aa1&quot;</span>, <span class="number">1</span>),</span><br><span class="line">                Tuple3.of(<span class="number">1</span>, <span class="string">&quot;aa2&quot;</span>, <span class="number">2</span>),</span><br><span class="line">                Tuple3.of(<span class="number">2</span>, <span class="string">&quot;bb&quot;</span>, <span class="number">1</span>),</span><br><span class="line">                Tuple3.of(<span class="number">3</span>, <span class="string">&quot;cc&quot;</span>, <span class="number">1</span>)</span><br><span class="line">        );</span><br><span class="line"></span><br><span class="line">        ConnectedStreams&lt;Tuple2&lt;Integer, String&gt;, Tuple3&lt;Integer, String, Integer&gt;&gt; connect = source1.connect(source2);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 多并行度下，需要根据 关联条件 进行keyby，才能保证key相同的数据到一起去，才能匹配上</span></span><br><span class="line">        ConnectedStreams&lt;Tuple2&lt;Integer, String&gt;, Tuple3&lt;Integer, String, Integer&gt;&gt; connectKey = connect.keyBy(s1 -&gt; s1.f0, s2 -&gt; s2.f0);</span><br><span class="line"></span><br><span class="line">        SingleOutputStreamOperator&lt;String&gt; result = connectKey.process(</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">CoProcessFunction</span>&lt;Tuple2&lt;Integer, String&gt;, Tuple3&lt;Integer, String, Integer&gt;, String&gt;() &#123;</span><br><span class="line">                    <span class="comment">// 定义 HashMap，缓存来过的数据，key=id，value=list&lt;数据&gt;</span></span><br><span class="line">                    Map&lt;Integer, List&lt;Tuple2&lt;Integer, String&gt;&gt;&gt; s1Cache = <span class="keyword">new</span> <span class="title class_">HashMap</span>&lt;&gt;();</span><br><span class="line">                    Map&lt;Integer, List&lt;Tuple3&lt;Integer, String, Integer&gt;&gt;&gt; s2Cache = <span class="keyword">new</span> <span class="title class_">HashMap</span>&lt;&gt;();</span><br><span class="line"></span><br><span class="line">                    <span class="meta">@Override</span></span><br><span class="line">                    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">processElement1</span><span class="params">(Tuple2&lt;Integer, String&gt; value, Context ctx, Collector&lt;String&gt; out)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">                        <span class="type">Integer</span> <span class="variable">id</span> <span class="operator">=</span> value.f0;</span><br><span class="line">                        <span class="comment">// TODO 1.来过的s1数据，都存起来</span></span><br><span class="line">                        <span class="keyword">if</span> (!s1Cache.containsKey(id)) &#123;</span><br><span class="line">                            <span class="comment">// 1.1 第一条数据，初始化 value的list，放入 hashmap</span></span><br><span class="line">                            List&lt;Tuple2&lt;Integer, String&gt;&gt; s1Values = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br><span class="line">                            s1Values.add(value);</span><br><span class="line">                            s1Cache.put(id, s1Values);</span><br><span class="line">                        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                            <span class="comment">// 1.2 不是第一条，直接添加到 list中</span></span><br><span class="line">                            s1Cache.get(id).add(value);</span><br><span class="line">                        &#125;</span><br><span class="line"></span><br><span class="line">                        <span class="comment">//TODO 2.根据id，查找s2的数据，只输出 匹配上 的数据</span></span><br><span class="line">                        <span class="keyword">if</span> (s2Cache.containsKey(id)) &#123;</span><br><span class="line">                            <span class="keyword">for</span> (Tuple3&lt;Integer, String, Integer&gt; s2Element : s2Cache.get(id)) &#123;</span><br><span class="line">                                out.collect(<span class="string">&quot;s1:&quot;</span> + value + <span class="string">&quot;&lt;---------&gt;s2:&quot;</span> + s2Element);</span><br><span class="line">                            &#125;</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line"></span><br><span class="line">                    <span class="meta">@Override</span></span><br><span class="line">                    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">processElement2</span><span class="params">(Tuple3&lt;Integer, String, Integer&gt; value, Context ctx, Collector&lt;String&gt; out)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">                        <span class="type">Integer</span> <span class="variable">id</span> <span class="operator">=</span> value.f0;</span><br><span class="line">                        <span class="comment">// TODO 1.来过的s2数据，都存起来</span></span><br><span class="line">                        <span class="keyword">if</span> (!s2Cache.containsKey(id)) &#123;</span><br><span class="line">                            <span class="comment">// 1.1 第一条数据，初始化 value的list，放入 hashmap</span></span><br><span class="line">                            List&lt;Tuple3&lt;Integer, String, Integer&gt;&gt; s2Values = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br><span class="line">                            s2Values.add(value);</span><br><span class="line">                            s2Cache.put(id, s2Values);</span><br><span class="line">                        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                            <span class="comment">// 1.2 不是第一条，直接添加到 list中</span></span><br><span class="line">                            s2Cache.get(id).add(value);</span><br><span class="line">                        &#125;</span><br><span class="line"></span><br><span class="line">                        <span class="comment">//TODO 2.根据id，查找s1的数据，只输出 匹配上 的数据</span></span><br><span class="line">                        <span class="keyword">if</span> (s1Cache.containsKey(id)) &#123;</span><br><span class="line">                            <span class="keyword">for</span> (Tuple2&lt;Integer, String&gt; s1Element : s1Cache.get(id)) &#123;</span><br><span class="line">                                out.collect(<span class="string">&quot;s1:&quot;</span> + s1Element + <span class="string">&quot;&lt;---------&gt;s2:&quot;</span> + value);</span><br><span class="line">                            &#125;</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;);</span><br><span class="line"></span><br><span class="line">        result.print();</span><br><span class="line"></span><br><span class="line">        env.execute();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="1-4输出算子"><a href="#1-4输出算子" class="headerlink" title="1.4输出算子"></a>1.4输出算子</h3><h4 id="Flink作为数据处理框架，最终还是要把计算处理的结果写入外部存储，为外部应用提供支持。"><a href="#Flink作为数据处理框架，最终还是要把计算处理的结果写入外部存储，为外部应用提供支持。" class="headerlink" title="Flink作为数据处理框架，最终还是要把计算处理的结果写入外部存储，为外部应用提供支持。"></a>Flink作为数据处理框架，最终还是要把计算处理的结果写入外部存储，为外部应用提供支持。</h4><p><img src= "/imgs/loading/loading.gif" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://pic1.imgdb.cn/item/678645c8d0e0a243d4f43592.png"></p>
<h3 id="1-4-1-连接到外部系统"><a href="#1-4-1-连接到外部系统" class="headerlink" title="1.4.1 连接到外部系统"></a><strong>1.4.1</strong> <strong>连接到外部系统</strong></h3><h4 id="Flink的DataStream-API专门提供了向外部写入数据的方法：addSink。与addSource类似，addSink方法对应着一个“Sink”算子，主要就是用来实现与外部系统连接、并将数据提交写入的；Flink程序中所有对外的输出操作，一般都是利用Sink算子完成的。"><a href="#Flink的DataStream-API专门提供了向外部写入数据的方法：addSink。与addSource类似，addSink方法对应着一个“Sink”算子，主要就是用来实现与外部系统连接、并将数据提交写入的；Flink程序中所有对外的输出操作，一般都是利用Sink算子完成的。" class="headerlink" title="Flink的DataStream API专门提供了向外部写入数据的方法：addSink。与addSource类似，addSink方法对应着一个“Sink”算子，主要就是用来实现与外部系统连接、并将数据提交写入的；Flink程序中所有对外的输出操作，一般都是利用Sink算子完成的。"></a>Flink的DataStream API专门提供了向外部写入数据的方法：addSink。与addSource类似，addSink方法对应着一个“Sink”算子，主要就是用来实现与外部系统连接、并将数据提交写入的；Flink程序中所有对外的输出操作，一般都是利用Sink算子完成的。</h4><h5 id="Flink1-12以前，Sink算子的创建是通过调用DataStream的-addSink-方法实现的。"><a href="#Flink1-12以前，Sink算子的创建是通过调用DataStream的-addSink-方法实现的。" class="headerlink" title="Flink1.12以前，Sink算子的创建是通过调用DataStream的.addSink()方法实现的。"></a>Flink1.12以前，Sink算子的创建是通过调用DataStream的.addSink()方法实现的。</h5><h5 id="stream-addSink-new-SinkFunction-…"><a href="#stream-addSink-new-SinkFunction-…" class="headerlink" title="stream.addSink(new SinkFunction(…));"></a>stream.addSink(new SinkFunction(…));</h5><h5 id="addSink方法同样需要传入一个参数，实现的是SinkFunction接口。在这个接口中只需要重写一个方法invoke-，用来将指定的值写入到外部系统中。这个方法在每条数据记录到来时都会调用。"><a href="#addSink方法同样需要传入一个参数，实现的是SinkFunction接口。在这个接口中只需要重写一个方法invoke-，用来将指定的值写入到外部系统中。这个方法在每条数据记录到来时都会调用。" class="headerlink" title="addSink方法同样需要传入一个参数，实现的是SinkFunction接口。在这个接口中只需要重写一个方法invoke()，用来将指定的值写入到外部系统中。这个方法在每条数据记录到来时都会调用。"></a>addSink方法同样需要传入一个参数，实现的是SinkFunction接口。在这个接口中只需要重写一个方法invoke()，用来将指定的值写入到外部系统中。这个方法在每条数据记录到来时都会调用。</h5><h5 id="Flink1-12开始，同样重构了Sink架构，"><a href="#Flink1-12开始，同样重构了Sink架构，" class="headerlink" title="Flink1.12开始，同样重构了Sink架构，"></a>Flink1.12开始，同样重构了Sink架构，</h5><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">stream.sinkTo(…)</span><br></pre></td></tr></table></figure>

<h4 id="当然，Sink多数情况下同样并不需要我们自己实现。之前我们一直在使用的print方法其实就是一种Sink，它表示将数据流写入标准控制台打印输出。Flink官方为我们提供了一部分的框架的Sink连接器。如下图所示，列出了Flink官方目前支持的第三方系统连接器："><a href="#当然，Sink多数情况下同样并不需要我们自己实现。之前我们一直在使用的print方法其实就是一种Sink，它表示将数据流写入标准控制台打印输出。Flink官方为我们提供了一部分的框架的Sink连接器。如下图所示，列出了Flink官方目前支持的第三方系统连接器：" class="headerlink" title="当然，Sink多数情况下同样并不需要我们自己实现。之前我们一直在使用的print方法其实就是一种Sink，它表示将数据流写入标准控制台打印输出。Flink官方为我们提供了一部分的框架的Sink连接器。如下图所示，列出了Flink官方目前支持的第三方系统连接器："></a>当然，Sink多数情况下同样并不需要我们自己实现。之前我们一直在使用的print方法其实就是一种Sink，它表示将数据流写入标准控制台打印输出。Flink官方为我们提供了一部分的框架的Sink连接器。如下图所示，列出了Flink官方目前支持的第三方系统连接器：</h4><p><img src= "/imgs/loading/loading.gif" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://pic1.imgdb.cn/item/678645f5d0e0a243d4f435e2.png"></p>
<h4 id="我们可以看到，像Kafka之类流式系统，Flink提供了完美对接，source-x2F-sink两端都能连接，可读可写；而对于Elasticsearch、JDBC等数据存储系统，则只提供了输出写入的sink连接器。"><a href="#我们可以看到，像Kafka之类流式系统，Flink提供了完美对接，source-x2F-sink两端都能连接，可读可写；而对于Elasticsearch、JDBC等数据存储系统，则只提供了输出写入的sink连接器。" class="headerlink" title="我们可以看到，像Kafka之类流式系统，Flink提供了完美对接，source&#x2F;sink两端都能连接，可读可写；而对于Elasticsearch、JDBC等数据存储系统，则只提供了输出写入的sink连接器。"></a>我们可以看到，像Kafka之类流式系统，Flink提供了完美对接，source&#x2F;sink两端都能连接，可读可写；而对于Elasticsearch、JDBC等数据存储系统，则只提供了输出写入的sink连接器。</h4><h4 id="除Flink官方之外，Apache-Bahir框架，也实现了一些其他第三方系统与Flink的连接器。"><a href="#除Flink官方之外，Apache-Bahir框架，也实现了一些其他第三方系统与Flink的连接器。" class="headerlink" title="除Flink官方之外，Apache Bahir框架，也实现了一些其他第三方系统与Flink的连接器。"></a>除Flink官方之外，Apache Bahir框架，也实现了一些其他第三方系统与Flink的连接器。</h4><p><img src= "/imgs/loading/loading.gif" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://pic1.imgdb.cn/item/6786460cd0e0a243d4f43614.png"></p>
<h4 id="除此以外，就需要用户自定义实现sink连接器了。"><a href="#除此以外，就需要用户自定义实现sink连接器了。" class="headerlink" title="除此以外，就需要用户自定义实现sink连接器了。"></a>除此以外，就需要用户自定义实现sink连接器了。</h4><h3 id="5-4-2-输出到文件"><a href="#5-4-2-输出到文件" class="headerlink" title="5.4.2 输出到文件"></a><strong>5.4.2</strong> <strong>输出到文件</strong></h3><h4 id="Flink专门提供了一个流式文件系统的连接器：FileSink，为批处理和流处理提供了一个统一的Sink，它可以将分区文件写入Flink支持的文件系统。"><a href="#Flink专门提供了一个流式文件系统的连接器：FileSink，为批处理和流处理提供了一个统一的Sink，它可以将分区文件写入Flink支持的文件系统。" class="headerlink" title="Flink专门提供了一个流式文件系统的连接器：FileSink，为批处理和流处理提供了一个统一的Sink，它可以将分区文件写入Flink支持的文件系统。"></a>Flink专门提供了一个流式文件系统的连接器：FileSink，为批处理和流处理提供了一个统一的Sink，它可以将分区文件写入Flink支持的文件系统。</h4><h4 id="FileSink支持行编码（Row-encoded）和批量编码（Bulk-encoded）格式。这两种不同的方式都有各自的构建器（builder），可以直接调用FileSink的静态方法："><a href="#FileSink支持行编码（Row-encoded）和批量编码（Bulk-encoded）格式。这两种不同的方式都有各自的构建器（builder），可以直接调用FileSink的静态方法：" class="headerlink" title="FileSink支持行编码（Row-encoded）和批量编码（Bulk-encoded）格式。这两种不同的方式都有各自的构建器（builder），可以直接调用FileSink的静态方法："></a>FileSink支持行编码（Row-encoded）和批量编码（Bulk-encoded）格式。这两种不同的方式都有各自的构建器（builder），可以直接调用FileSink的静态方法：</h4><ul>
<li>行编码： FileSink.forRowFormat（basePath，rowEncoder）。</li>
<li>批量编码： FileSink.forBulkFormat（basePath，bulkWriterFactory）。</li>
</ul>
<h4 id="实例："><a href="#实例：" class="headerlink" title="实例："></a>实例：</h4><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.day02</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> ch.qos.logback.core.util.<span class="type">TimeUtil</span></span><br><span class="line"><span class="keyword">import</span> com.day02.<span class="type">SourceBoundedTest</span>.<span class="type">Event</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.serialization.<span class="type">SimpleStringEncoder</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.core.fs.<span class="type">Path</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.functions.sink.filesystem.<span class="type">StreamingFileSink</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.scala._</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">SinkToFileTest</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> env = <span class="type">StreamExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line">    env.setParallelism(<span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> stream: <span class="type">DataStream</span>[<span class="type">Event</span>] = env.fromElements(</span><br><span class="line">      <span class="type">Event</span>(<span class="string">&quot;hkj&quot;</span>, <span class="string">&quot;www.baidu.com&quot;</span>, <span class="number">1000</span>L),</span><br><span class="line">      <span class="type">Event</span>(<span class="string">&quot;Bob&quot;</span>, <span class="string">&quot;www.bing.com&quot;</span>, <span class="number">2000</span>L),</span><br><span class="line">      <span class="type">Event</span>(<span class="string">&quot;Bob&quot;</span>, <span class="string">&quot;www.bing.com&quot;</span>, <span class="number">2000</span>L),</span><br><span class="line">      <span class="type">Event</span>(<span class="string">&quot;Lisa&quot;</span>, <span class="string">&quot;www.hkjcpdd.com&quot;</span>, <span class="number">3000</span>L),</span><br><span class="line">      <span class="type">Event</span>(<span class="string">&quot;Lisa&quot;</span>, <span class="string">&quot;www.hkjcpdd.com&quot;</span>, <span class="number">3000</span>L),</span><br><span class="line">      <span class="type">Event</span>(<span class="string">&quot;Lisa&quot;</span>, <span class="string">&quot;www.hkjcpdd.com&quot;</span>, <span class="number">3000</span>L),</span><br><span class="line">      <span class="type">Event</span>(<span class="string">&quot;hkj&quot;</span>, <span class="string">&quot;www.by123.com&quot;</span>, <span class="number">8000</span>L),</span><br><span class="line">      <span class="type">Event</span>(<span class="string">&quot;Lisa&quot;</span>, <span class="string">&quot;www.hkjmjj.com&quot;</span>, <span class="number">1000</span>L)</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 直接以文本形式分布式的写入到文件中</span></span><br><span class="line">    <span class="comment">// SimpleStringEncoder作用是将String转成char方便写入</span></span><br><span class="line">    <span class="keyword">val</span> fileSink = <span class="type">StreamingFileSink</span></span><br><span class="line">      .forRowFormat(<span class="keyword">new</span> <span class="type">Path</span>(<span class="string">&quot;./output&quot;</span>), <span class="keyword">new</span> <span class="type">SimpleStringEncoder</span>[<span class="type">String</span>](<span class="string">&quot;utf-8&quot;</span>))</span><br><span class="line">      .build()</span><br><span class="line"></span><br><span class="line">    stream.broadcast.map(_.toString).addSink(fileSink)</span><br><span class="line"></span><br><span class="line">    env.execute()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="1-4-3-输出到Kafka"><a href="#1-4-3-输出到Kafka" class="headerlink" title="1.4.3 输出到Kafka"></a><strong>1.4.3</strong> 输出到Kafka</h3><h3 id="（1）添加Kafka-连接器依赖"><a href="#（1）添加Kafka-连接器依赖" class="headerlink" title="（1）添加Kafka 连接器依赖"></a>（1）添加Kafka 连接器依赖</h3><h3 id="由于我们已经测试过从Kafka数据源读取数据，连接器相关依赖已经引入，这里就不重复介绍了。"><a href="#由于我们已经测试过从Kafka数据源读取数据，连接器相关依赖已经引入，这里就不重复介绍了。" class="headerlink" title="由于我们已经测试过从Kafka数据源读取数据，连接器相关依赖已经引入，这里就不重复介绍了。"></a>由于我们已经测试过从Kafka数据源读取数据，连接器相关依赖已经引入，这里就不重复介绍了。</h3><h3 id="（2）启动Kafka集群"><a href="#（2）启动Kafka集群" class="headerlink" title="（2）启动Kafka集群"></a>（2）启动Kafka集群</h3><h3 id="（3）编写输出到Kafka的示例代码"><a href="#（3）编写输出到Kafka的示例代码" class="headerlink" title="（3）编写输出到Kafka的示例代码"></a>（3）编写输出到Kafka的示例代码</h3><h3 id="输出无key的record"><a href="#输出无key的record" class="headerlink" title="输出无key的record:"></a>输出无key的record:</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.day02</span><br><span class="line"><span class="keyword">import</span> com.day02.<span class="type">SourceBoundedTest</span>.<span class="type">Event</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.serialization.<span class="type">SimpleStringSchema</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.scala._</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.connectors.kafka.&#123;<span class="type">FlinkKafkaConsumer</span>, <span class="type">FlinkKafkaProducer</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.<span class="type">Properties</span></span><br><span class="line"><span class="keyword">import</span> scala.util.<span class="type">Properties</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">SinkToKafkaTest</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> env = <span class="type">StreamExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line">    env.setParallelism(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> properties = <span class="keyword">new</span> <span class="type">Properties</span>()</span><br><span class="line">    properties.setProperty(<span class="string">&quot;bootstrap.servers&quot;</span>, <span class="string">&quot;master:9092&quot;</span>)</span><br><span class="line">    properties.setProperty(<span class="string">&quot;group.id&quot;</span>, <span class="string">&quot;consumer-group&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 读取文件数据</span></span><br><span class="line">    <span class="keyword">val</span> stream = env.addSource(<span class="keyword">new</span> <span class="type">FlinkKafkaConsumer</span>[<span class="type">String</span>](<span class="string">&quot;lhxcpdd&quot;</span>, <span class="keyword">new</span> <span class="type">SimpleStringSchema</span>(), properties))</span><br><span class="line">      .map(data =&gt; &#123;</span><br><span class="line">        <span class="keyword">val</span> fields = data.split(<span class="string">&quot;,&quot;</span>)</span><br><span class="line">        <span class="comment">// trim就是去空格</span></span><br><span class="line">        <span class="type">Event</span>(fields(<span class="number">0</span>).trim, fields(<span class="number">1</span>).trim, fields(<span class="number">2</span>).trim.toLong).toString</span><br><span class="line">      &#125;)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 讲数据写入到kafka</span></span><br><span class="line">    stream.addSink(<span class="keyword">new</span> <span class="type">FlinkKafkaProducer</span>[<span class="type">String</span>](<span class="string">&quot;master:9092&quot;</span>, <span class="string">&quot;hkjcpdd&quot;</span>, <span class="keyword">new</span> <span class="type">SimpleStringSchema</span>()))</span><br><span class="line"></span><br><span class="line">    env.execute()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="然后开一个消费者查看是否到数据"><a href="#然后开一个消费者查看是否到数据" class="headerlink" title="然后开一个消费者查看是否到数据"></a>然后开一个消费者查看是否到数据</h3><h3 id="1-4-4-输出到MySQL（JDBC）"><a href="#1-4-4-输出到MySQL（JDBC）" class="headerlink" title="1.4.4 输出到MySQL（JDBC）"></a>1.4.4 输出到MySQL（JDBC）</h3><h3 id="写入数据的MySQL的测试步骤如下。"><a href="#写入数据的MySQL的测试步骤如下。" class="headerlink" title="写入数据的MySQL的测试步骤如下。"></a>写入数据的MySQL的测试步骤如下。</h3><h3 id="（1）添加依赖"><a href="#（1）添加依赖" class="headerlink" title="（1）添加依赖"></a>（1）添加依赖</h3><h3 id="添加MySQL驱动："><a href="#添加MySQL驱动：" class="headerlink" title="添加MySQL驱动："></a>添加MySQL驱动：</h3><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>mysql<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>mysql-connector-java<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>8.0.27<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h4 id="官方还未提供flink-connector-jdbc的1-17-0的正式依赖，暂时从apache-snapshot仓库下载，pom文件中指定仓库路径："><a href="#官方还未提供flink-connector-jdbc的1-17-0的正式依赖，暂时从apache-snapshot仓库下载，pom文件中指定仓库路径：" class="headerlink" title="官方还未提供flink-connector-jdbc的1.17.0的正式依赖，暂时从apache snapshot仓库下载，pom文件中指定仓库路径："></a>官方还未提供flink-connector-jdbc的1.17.0的正式依赖，暂时从apache snapshot仓库下载，pom文件中指定仓库路径：</h4><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">repositories</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">repository</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">id</span>&gt;</span>apache-snapshots<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>apache snapshots<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">url</span>&gt;</span>https://repository.apache.org/content/repositories/snapshots/<span class="tag">&lt;/<span class="name">url</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">repository</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">repositories</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h4 id="添加依赖："><a href="#添加依赖：" class="headerlink" title="添加依赖："></a>添加依赖：</h4><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-connector-jdbc<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.17-SNAPSHOT<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h4 id="如果不生效，还需要修改本地maven的配置文件，mirrorOf中添加如下标红内容："><a href="#如果不生效，还需要修改本地maven的配置文件，mirrorOf中添加如下标红内容：" class="headerlink" title="如果不生效，还需要修改本地maven的配置文件，mirrorOf中添加如下标红内容："></a>如果不生效，还需要修改本地maven的配置文件，mirrorOf中添加如下标红内容：</h4><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;mirror&gt;</span><br><span class="line">            &lt;id&gt;aliyunmaven&lt;/id&gt;</span><br><span class="line">            &lt;mirrorOf&gt;*,!apache-snapshots&lt;/mirrorOf&gt;</span><br><span class="line">            &lt;name&gt;阿里云公共仓库&lt;/name&gt;</span><br><span class="line">            &lt;url&gt;https:<span class="comment">//maven.aliyun.com/repository/public&lt;/url&gt;</span></span><br><span class="line">&lt;/mirror&gt;</span><br></pre></td></tr></table></figure>

<h4 id="（2）启动MySQL，在test库下建表ws"><a href="#（2）启动MySQL，在test库下建表ws" class="headerlink" title="（2）启动MySQL，在test库下建表ws"></a>（2）启动MySQL，在test库下建表ws</h4><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span>     </span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> `ws` (</span><br><span class="line">  `id` <span class="type">varchar</span>(<span class="number">100</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span>,</span><br><span class="line">  `ts` <span class="type">bigint</span>(<span class="number">20</span>) <span class="keyword">DEFAULT</span> <span class="keyword">NULL</span>,</span><br><span class="line">  `vc` <span class="type">int</span>(<span class="number">11</span>) <span class="keyword">DEFAULT</span> <span class="keyword">NULL</span>,</span><br><span class="line">  <span class="keyword">PRIMARY</span> KEY (`id`)</span><br><span class="line">) ENGINE<span class="operator">=</span>InnoDB <span class="keyword">DEFAULT</span> CHARSET<span class="operator">=</span>utf8</span><br></pre></td></tr></table></figure>

<h4 id="（3）编写输出到MySQL的示例代码"><a href="#（3）编写输出到MySQL的示例代码" class="headerlink" title="（3）编写输出到MySQL的示例代码"></a>（3）编写输出到MySQL的示例代码</h4><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.day02</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.day02.<span class="type">SourceBoundedTest</span>.<span class="type">Event</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.connector.jdbc.&#123;<span class="type">JdbcConnectionOptions</span>, <span class="type">JdbcSink</span>, <span class="type">JdbcStatementBuilder</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.scala._</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.sql.<span class="type">PreparedStatement</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">SinkToMysqlTest</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> env = <span class="type">StreamExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line">    env.setParallelism(<span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> stream: <span class="type">DataStream</span>[<span class="type">Event</span>] = env.fromElements(</span><br><span class="line">      <span class="type">Event</span>(<span class="string">&quot;hkj&quot;</span>, <span class="string">&quot;www.baidu.com&quot;</span>, <span class="number">1000</span>L),</span><br><span class="line">      <span class="type">Event</span>(<span class="string">&quot;Bob&quot;</span>, <span class="string">&quot;www.bing.com&quot;</span>, <span class="number">2000</span>L),</span><br><span class="line">      <span class="type">Event</span>(<span class="string">&quot;Bob&quot;</span>, <span class="string">&quot;www.bing.com&quot;</span>, <span class="number">2000</span>L),</span><br><span class="line">      <span class="type">Event</span>(<span class="string">&quot;Lisa&quot;</span>, <span class="string">&quot;www.hkjcpdd.com&quot;</span>, <span class="number">3000</span>L),</span><br><span class="line">      <span class="type">Event</span>(<span class="string">&quot;Lisa&quot;</span>, <span class="string">&quot;www.hkjcpdd.com&quot;</span>, <span class="number">3000</span>L),</span><br><span class="line">      <span class="type">Event</span>(<span class="string">&quot;Lisa&quot;</span>, <span class="string">&quot;www.hkjcpdd.com&quot;</span>, <span class="number">3000</span>L),</span><br><span class="line">      <span class="type">Event</span>(<span class="string">&quot;hkj&quot;</span>, <span class="string">&quot;www.by123.com&quot;</span>, <span class="number">8000</span>L),</span><br><span class="line">      <span class="type">Event</span>(<span class="string">&quot;Lisa&quot;</span>, <span class="string">&quot;www.hkjmjj.com&quot;</span>, <span class="number">1000</span>L)</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    stream.print()</span><br><span class="line"></span><br><span class="line">    stream.addSink(<span class="type">JdbcSink</span>.sink(</span><br><span class="line">      <span class="string">&quot;insert into shop (name, area, dizhi, price) values(?, ?, ?, ?)&quot;</span>, <span class="comment">// 定义写入Mysql的语句</span></span><br><span class="line">      <span class="keyword">new</span> <span class="type">JdbcStatementBuilder</span>[<span class="type">Event</span>] &#123;</span><br><span class="line">        <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">accept</span></span>(t: <span class="type">PreparedStatement</span>, u: <span class="type">Event</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">          t.setString(<span class="number">1</span>, u.user)</span><br><span class="line">          t.setString(<span class="number">2</span>, u.url)</span><br><span class="line">          t.setString(<span class="number">3</span>, u.url)</span><br><span class="line">          t.setString(<span class="number">4</span>, u.url)</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;,</span><br><span class="line">      <span class="keyword">new</span> <span class="type">JdbcConnectionOptions</span>.<span class="type">JdbcConnectionOptionsBuilder</span>()</span><br><span class="line">        .withUrl(<span class="string">&quot;jdbc:mysql://master:3306/test?useSSL=false&quot;</span>)</span><br><span class="line">        .withDriverName(<span class="string">&quot;com.mysql.jdbc.Driver&quot;</span>)</span><br><span class="line">        .withUsername(<span class="string">&quot;root&quot;</span>)</span><br><span class="line">        .withPassword(<span class="string">&quot;123456&quot;</span>)</span><br><span class="line">        .build()</span><br><span class="line">    ))</span><br><span class="line"></span><br><span class="line">    env.execute()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="（4）运行代码，用客户端连接MySQL，查看是否成功写入数据。"><a href="#（4）运行代码，用客户端连接MySQL，查看是否成功写入数据。" class="headerlink" title="（4）运行代码，用客户端连接MySQL，查看是否成功写入数据。"></a>（4）运行代码，用客户端连接MySQL，查看是否成功写入数据。</h4><h3 id="1-4-5-自定义Sink输出"><a href="#1-4-5-自定义Sink输出" class="headerlink" title="1.4.5 自定义Sink输出"></a><strong>1.4.5</strong> <strong>自定义Sink输出</strong></h3><h4 id="如果我们想将数据存储到我们自己的存储设备中，而Flink并没有提供可以直接使用的连接器，就只能自定义Sink进行输出了。与Source类似，Flink为我们提供了通用的SinkFunction接口和对应的RichSinkDunction抽象类，只要实现它，通过简单地调用DataStream的-addSink-方法就可以自定义写入任何外部存储。"><a href="#如果我们想将数据存储到我们自己的存储设备中，而Flink并没有提供可以直接使用的连接器，就只能自定义Sink进行输出了。与Source类似，Flink为我们提供了通用的SinkFunction接口和对应的RichSinkDunction抽象类，只要实现它，通过简单地调用DataStream的-addSink-方法就可以自定义写入任何外部存储。" class="headerlink" title="如果我们想将数据存储到我们自己的存储设备中，而Flink并没有提供可以直接使用的连接器，就只能自定义Sink进行输出了。与Source类似，Flink为我们提供了通用的SinkFunction接口和对应的RichSinkDunction抽象类，只要实现它，通过简单地调用DataStream的.addSink()方法就可以自定义写入任何外部存储。"></a>如果我们想将数据存储到我们自己的存储设备中，而Flink并没有提供可以直接使用的连接器，就只能自定义Sink进行输出了。与Source类似，Flink为我们提供了通用的SinkFunction接口和对应的RichSinkDunction抽象类，只要实现它，通过简单地调用DataStream的.addSink()方法就可以自定义写入任何外部存储。</h4><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">stream.addSink(<span class="keyword">new</span> <span class="type">MySinkFunction</span>&lt;<span class="type">String</span>&gt;());</span><br></pre></td></tr></table></figure>

<h4 id="在实现SinkFunction的时候，需要重写的一个关键方法invoke-，在这个方法中我们就可以实现将流里的数据发送出去的逻辑。"><a href="#在实现SinkFunction的时候，需要重写的一个关键方法invoke-，在这个方法中我们就可以实现将流里的数据发送出去的逻辑。" class="headerlink" title="在实现SinkFunction的时候，需要重写的一个关键方法invoke()，在这个方法中我们就可以实现将流里的数据发送出去的逻辑。"></a>在实现SinkFunction的时候，需要重写的一个关键方法invoke()，在这个方法中我们就可以实现将流里的数据发送出去的逻辑。</h4><h4 id="这种方式比较通用，对于任何外部存储系统都有效；不过自定义Sink想要实现状态一致性并不容易，所以一般只在没有其它选择时使用。实际项目中用到的外部连接器Flink官方基本都已实现，而且在不断地扩充，因此自定义的场景并不常见。"><a href="#这种方式比较通用，对于任何外部存储系统都有效；不过自定义Sink想要实现状态一致性并不容易，所以一般只在没有其它选择时使用。实际项目中用到的外部连接器Flink官方基本都已实现，而且在不断地扩充，因此自定义的场景并不常见。" class="headerlink" title="这种方式比较通用，对于任何外部存储系统都有效；不过自定义Sink想要实现状态一致性并不容易，所以一般只在没有其它选择时使用。实际项目中用到的外部连接器Flink官方基本都已实现，而且在不断地扩充，因此自定义的场景并不常见。"></a>这种方式比较通用，对于任何外部存储系统都有效；不过自定义Sink想要实现状态一致性并不容易，所以一般只在没有其它选择时使用。实际项目中用到的外部连接器Flink官方基本都已实现，而且在不断地扩充，因此自定义的场景并不常见。</h4></article><div class="post-copyright"><div class="copyright-cc-box"><i class="anzhiyufont anzhiyu-icon-copyright"></i></div><div class="post-copyright__author_box"><a class="post-copyright__author_img" href="/about" title="头像"><img class="post-copyright__author_img_back" src= "/imgs/loading/loading.gif" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/imgs/avatar.webp" title="头像" alt="头像"><img class="post-copyright__author_img_front" src= "/imgs/loading/loading.gif" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/imgs/avatar.webp" title="头像" alt="头像"></a><div class="post-copyright__author_name">曦</div><div class="post-copyright__author_desc">曦</div></div><div class="post-copyright__post__info"><a class="post-copyright__original" title="该文章为原创文章，注意版权协议" href="https://bigdata-yx.github.io/posts/pd14.html">原创</a><a class="post-copyright-title"><span onclick="rm.copyPageUrl('https://bigdata-yx.github.io/posts/pd14.html')">Flink的DataStreamAPI</span></a></div><div class="post-tools" id="post-tools"><div class="post-tools-left"><div class="rewardLeftButton"><div class="post-reward" onclick="anzhiyu.addRewardMask()"><div class="reward-button button--animated" title="赞赏作者"><i class="anzhiyufont anzhiyu-icon-hand-heart-fill"></i>打赏作者</div><div class="reward-main"><div class="reward-all"><span class="reward-title">感谢你赐予我前进的力量</span><ul class="reward-group"><li class="reward-item"><a href="https://blogyx.top/" target="_blank"><img class="post-qr-code-img" src= "/imgs/loading/loading.gif" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/imgs/reward/alipay.webp" alt="alipay"/></a><div class="post-qr-code-desc">alipay</div></li><li class="reward-item"><a href="https://blogyx.top/" target="_blank"><img class="post-qr-code-img" src= "/imgs/loading/loading.gif" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/imgs/reward/wechat.webp" alt="wechat"/></a><div class="post-qr-code-desc">wechat</div></li></ul><a class="reward-main-btn" href="/about/#about-reward" target="_blank"><div class="reward-text">赞赏者名单</div><div class="reward-dec">因为你们的支持让我意识到写文章的价值🙏</div></a></div></div></div><div id="quit-box" onclick="anzhiyu.removeRewardMask()" style="display: none"></div></div><div class="shareRight"><div class="share-link mobile"><div class="share-qrcode"><div class="share-button" title="使用手机访问这篇文章"><i class="anzhiyufont anzhiyu-icon-qrcode"></i></div><div class="share-main"><div class="share-main-all"><div id="qrcode" title="https://bigdata-yx.github.io/posts/pd14.html"></div><div class="reward-dec">使用手机访问这篇文章</div></div></div></div></div><div class="share-link weibo"><a class="share-button" target="_blank" href="https://service.weibo.com/share/share.php?title=Flink的DataStreamAPI&amp;url=https://bigdata-yx.github.io/posts/pd14.html&amp;pic=https://pic1.imgdb.cn/item/6784bd24d0e0a243d4f3d4a3.png?_r_=c31f22a8-5d93-17a1-e2f3-b175d5805f0e" rel="external nofollow noreferrer noopener"><i class="anzhiyufont anzhiyu-icon-weibo"></i></a></div><script>function copyCurrentPageUrl() {
  var currentPageUrl = window.location.href;
  var input = document.createElement("input");
  input.setAttribute("value", currentPageUrl);
  document.body.appendChild(input);
  input.select();
  input.setSelectionRange(0, 99999);
  document.execCommand("copy");
  document.body.removeChild(input);
}</script><div class="share-link copyurl"><div class="share-button" id="post-share-url" title="复制链接" onclick="copyCurrentPageUrl()"><i class="anzhiyufont anzhiyu-icon-link"></i></div></div></div></div></div><div class="post-copyright__notice"><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://bigdata-yx.github.io" target="_blank">曦</a>！</span></div></div><div class="post-tools-right"><div class="tag_share"><div class="post-meta__box"><div class="post-meta__box__tag-list"><a class="post-meta__box__tags" href="/tags/%E7%A4%BA%E4%BE%8B/"><span class="tags-punctuation"> <i class="anzhiyufont anzhiyu-icon-tag"></i></span>示例<span class="tagsPageCount">88</span></a><a class="post-meta__box__tags" href="/tags/Flink/"><span class="tags-punctuation"> <i class="anzhiyufont anzhiyu-icon-tag"></i></span>Flink<span class="tagsPageCount">5</span></a></div></div></div><div class="post_share"><div class="social-share" data-image="https://pic1.imgdb.cn/item/6784bd24d0e0a243d4f3d4a3.png?_r_=587f5087-8fbf-9eed-bdbb-47994d663c44" data-sites="wechat,weibo,qq,facebook,twitter"></div><link rel="stylesheet" href="https://unpkg.com/butterfly-extsrc@1.1.3/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"/><script src="https://unpkg.com/butterfly-extsrc@1.1.3/sharejs/dist/js/social-share.min.js" defer="defer"></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/posts/pd15.html"><img class="prev-cover" src= "/imgs/loading/loading.gif" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://pic1.imgdb.cn/item/6784be70d0e0a243d4f3d51b.png?_r_=bbdb563c-df35-ca66-d550-2f49dc6d4af8" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">Flink中的时间和窗口、水位线、</div></div></a></div><div class="next-post pull-right"><a href="/posts/1083.html"><img class="next-cover" src= "/imgs/loading/loading.gif" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://pic1.imgdb.cn/item/6784be57d0e0a243d4f3d50d.png?_r_=b3ae473c-d5c1-777b-8565-25289ee13591" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">数据可视化学习路线</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="anzhiyufont anzhiyu-icon-thumbs-up fa-fw" style="font-size: 1.5rem; margin-right: 4px"></i><span>喜欢这篇文章的人也看了</span></div><div class="relatedPosts-list"><div><a href="/posts/fe66.html" title="Flume Sink Processors sink处理器"><img class="cover" src= "/imgs/loading/loading.gif" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://pic1.imgdb.cn/item/6784bd24d0e0a243d4f3d4a3.png?_r_=6adfae9a-31f3-b36f-673e-7145164cece2" alt="cover"><div class="content is-center"><div class="date"><i class="anzhiyufont anzhiyu-icon-calendar-days fa-fw"></i> 2025-01-13</div><div class="title">Flume Sink Processors sink处理器</div></div></a></div><div><a href="/posts/fe69.html" title="Flume"><img class="cover" src= "/imgs/loading/loading.gif" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://pic1.imgdb.cn/item/6784be57d0e0a243d4f3d50d.png?_r_=5e4b378c-d90e-30f7-45bc-7b4372d64a8c" alt="cover"><div class="content is-center"><div class="date"><i class="anzhiyufont anzhiyu-icon-calendar-days fa-fw"></i> 2025-01-13</div><div class="title">Flume</div></div></a></div><div><a href="/posts/pd11.html" title="Flink"><img class="cover" src= "/imgs/loading/loading.gif" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://pic1.imgdb.cn/item/6784bd24d0e0a243d4f3d4a3.png?_r_=1f5e0b0b-0429-1f41-e508-7eac12c82eb9" alt="cover"><div class="content is-center"><div class="date"><i class="anzhiyufont anzhiyu-icon-calendar-days fa-fw"></i> 2025-01-14</div><div class="title">Flink</div></div></a></div><div><a href="/posts/pd13.html" title="Flink快速上手"><img class="cover" src= "/imgs/loading/loading.gif" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://pic1.imgdb.cn/item/6784bd24d0e0a243d4f3d4a3.png?_r_=e5028726-225d-203f-bd57-b78a8ed4a21c" alt="cover"><div class="content is-center"><div class="date"><i class="anzhiyufont anzhiyu-icon-calendar-days fa-fw"></i> 2025-01-14</div><div class="title">Flink快速上手</div></div></a></div><div><a href="/posts/pd12.html" title="Flink集群部署搭建"><img class="cover" src= "/imgs/loading/loading.gif" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://pic1.imgdb.cn/item/6784be57d0e0a243d4f3d50d.png?_r_=275dd360-18db-fe50-7c2b-fa88ebc5a3b8" alt="cover"><div class="content is-center"><div class="date"><i class="anzhiyufont anzhiyu-icon-calendar-days fa-fw"></i> 2025-01-14</div><div class="title">Flink集群部署搭建</div></div></a></div><div><a href="/posts/pd15.html" title="Flink中的时间和窗口、水位线、"><img class="cover" src= "/imgs/loading/loading.gif" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://pic1.imgdb.cn/item/6784be70d0e0a243d4f3d51b.png?_r_=bbdb563c-df35-ca66-d550-2f49dc6d4af8" alt="cover"><div class="content is-center"><div class="date"><i class="anzhiyufont anzhiyu-icon-calendar-days fa-fw"></i> 2025-01-14</div><div class="title">Flink中的时间和窗口、水位线、</div></div></a></div></div></div><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="anzhiyufont anzhiyu-icon-comments"></i><span> 评论</span></div><div class="comment-randomInfo"><a onclick="anzhiyu.addRandomCommentInfo()" href="javascript:void(0)">匿名评论</a><a href="/privacy" style="margin-left: 4px">隐私政策</a></div><div class="comment-tips" id="comment-tips"><span>✅ 你无需删除空行，直接评论以获取最佳展示效果</span></div></div><div class="comment-wrap"><div><div id="twikoo-wrap"></div></div></div></div><div class="comment-barrage"></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="card-content"><div class="author-info__sayhi" id="author-info__sayhi" onclick="anzhiyu.changeSayHelloText()"></div><div class="author-info-avatar"><img class="avatar-img" src= "/imgs/loading/loading.gif" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/imgs/avatar.webp" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/><div class="author-status"><img class="g-status" src= "/imgs/loading/loading.gif" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://bu.dusays.com/2023/08/24/64e6ce9c507bb.png" alt="status"/></div></div><div class="author-info__description">日出天地正，煌煌辟晨曦。</div><div class="author-info__bottom-group"><a class="author-info__bottom-group-left" href="/about"><h1 class="author-info__name">曦</h1><div class="author-info__desc">曦</div></a><div class="card-info-social-icons is-center"><a class="social-icon faa-parent animated-hover" href="https://blogyx.top/" target="_blank" title="Github"><i class="anzhiyufont anzhiyu-icon-github"></i></a><a class="social-icon faa-parent animated-hover" href="/foshana@163.com" target="_blank" title="Email"><i class="anzhiyufont anzhiyu-icon-envelope"></i></a><a class="social-icon faa-parent animated-hover" href="tencent://Message/?Uin=3493373920&amp;amp;websiteName=local.edu.com:8888=&amp;amp;Menu=yes" target="_blank" title="QQ"><i class="anzhiyufont anzhiyu-icon-qq"></i></a></div></div></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="anzhiyufont anzhiyu-icon-bullhorn anzhiyu-shake"></i><span>公告</span></div><div class="announcement_content"><div id="welcome-info"></div></div></div><div class="card-widget anzhiyu-right-widget" id="card-wechat" onclick="null"><div id="flip-wrapper"><div id="flip-content"><div class="face" style="background: url(https://tool.lu/netcard/) center center / 100% no-repeat"></div><div class="back face" style="background: url(/imgs/default/cover3.webp) center center / 100% no-repeat"></div></div></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="anzhiyufont anzhiyu-icon-bars"></i><span>文章目录</span><span class="toc-percentage"></span></div><div class="toc-content is-expand"><ol class="toc"><li class="toc-item toc-level-5"><a class="toc-link" href="#DataStream-API%E6%98%AFFlink%E7%9A%84%E6%A0%B8%E5%BF%83%E5%B1%82API%E3%80%82%E4%B8%80%E4%B8%AAFlink%E7%A8%8B%E5%BA%8F%EF%BC%8C%E5%85%B6%E5%AE%9E%E5%B0%B1%E6%98%AF%E5%AF%B9DataStream%E7%9A%84%E5%90%84%E7%A7%8D%E8%BD%AC%E6%8D%A2%E3%80%82%E5%85%B7%E4%BD%93%E6%9D%A5%E8%AF%B4%EF%BC%8C%E4%BB%A3%E7%A0%81%E5%9F%BA%E6%9C%AC%E4%B8%8A%E9%83%BD%E7%94%B1%E4%BB%A5%E4%B8%8B%E5%87%A0%E9%83%A8%E5%88%86%E6%9E%84%E6%88%90%EF%BC%9A"><span class="toc-number">1.</span> <span class="toc-text">DataStream API是Flink的核心层API。一个Flink程序，其实就是对DataStream的各种转换。具体来说，代码基本上都由以下几部分构成：</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%9C%A8Flink1-12%E4%BB%A5%E5%89%8D%EF%BC%8C%E6%97%A7%E7%9A%84%E6%B7%BB%E5%8A%A0source%E7%9A%84%E6%96%B9%E5%BC%8F%EF%BC%8C%E6%98%AF%E8%B0%83%E7%94%A8%E6%89%A7%E8%A1%8C%E7%8E%AF%E5%A2%83%E7%9A%84addSource-%E6%96%B9%E6%B3%95%EF%BC%9A"><span class="toc-number">2.</span> <span class="toc-text">在Flink1.12以前，旧的添加source的方式，是调用执行环境的addSource()方法：</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%96%B9%E6%B3%95%E4%BC%A0%E5%85%A5%E7%9A%84%E5%8F%82%E6%95%B0%E6%98%AF%E4%B8%80%E4%B8%AA%E2%80%9C%E6%BA%90%E5%87%BD%E6%95%B0%E2%80%9D%EF%BC%88source-function%EF%BC%89%EF%BC%8C%E9%9C%80%E8%A6%81%E5%AE%9E%E7%8E%B0SourceFunction%E6%8E%A5%E5%8F%A3%E3%80%82"><span class="toc-number">3.</span> <span class="toc-text">方法传入的参数是一个“源函数”（source function），需要实现SourceFunction接口。</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E4%BB%8EFlink1-12%E5%BC%80%E5%A7%8B%EF%BC%8C%E4%B8%BB%E8%A6%81%E4%BD%BF%E7%94%A8%E6%B5%81%E6%89%B9%E7%BB%9F%E4%B8%80%E7%9A%84%E6%96%B0Source%E6%9E%B6%E6%9E%84%EF%BC%9A"><span class="toc-number">4.</span> <span class="toc-text">从Flink1.12开始，主要使用流批统一的新Source架构：</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Flink%E7%9B%B4%E6%8E%A5%E6%8F%90%E4%BE%9B%E4%BA%86%E5%BE%88%E5%A4%9A%E9%A2%84%E5%AE%9E%E7%8E%B0%E7%9A%84%E6%8E%A5%E5%8F%A3%EF%BC%8C%E6%AD%A4%E5%A4%96%E8%BF%98%E6%9C%89%E5%BE%88%E5%A4%9A%E5%A4%96%E9%83%A8%E8%BF%9E%E6%8E%A5%E5%B7%A5%E5%85%B7%E4%B9%9F%E5%B8%AE%E6%88%91%E4%BB%AC%E5%AE%9E%E7%8E%B0%E4%BA%86%E5%AF%B9%E5%BA%94%E7%9A%84Source%EF%BC%8C%E9%80%9A%E5%B8%B8%E6%83%85%E5%86%B5%E4%B8%8B%E8%B6%B3%E4%BB%A5%E5%BA%94%E5%AF%B9%E6%88%91%E4%BB%AC%E7%9A%84%E5%AE%9E%E9%99%85%E9%9C%80%E6%B1%82%E3%80%82"><span class="toc-number">5.</span> <span class="toc-text">Flink直接提供了很多预实现的接口，此外还有很多外部连接工具也帮我们实现了对应的Source，通常情况下足以应对我们的实际需求。</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%87%86%E5%A4%87%E5%B7%A5%E4%BD%9C"><span class="toc-number"></span> <span class="toc-text">准备工作:</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E4%B8%BA%E4%BA%86%E6%96%B9%E4%BE%BF%E7%BB%83%E4%B9%A0%EF%BC%8C%E8%BF%99%E9%87%8C%E4%BD%BF%E7%94%A8WaterSensor%E4%BD%9C%E4%B8%BA%E6%95%B0%E6%8D%AE%E6%A8%A1%E5%9E%8B%E3%80%82"><span class="toc-number">1.</span> <span class="toc-text">为了方便练习，这里使用WaterSensor作为数据模型。</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%85%B7%E4%BD%93%E4%BB%A3%E7%A0%81%E5%A6%82%E4%B8%8B%EF%BC%9A"><span class="toc-number"></span> <span class="toc-text">具体代码如下：</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%BF%99%E9%87%8C%E9%9C%80%E8%A6%81%E6%B3%A8%E6%84%8F%EF%BC%8C%E6%88%91%E4%BB%AC%E5%AE%9A%E4%B9%89%E7%9A%84WaterSensor%EF%BC%8C%E6%9C%89%E8%BF%99%E6%A0%B7%E5%87%A0%E4%B8%AA%E7%89%B9%E7%82%B9%EF%BC%9A"><span class="toc-number"></span> <span class="toc-text">这里需要注意，我们定义的WaterSensor，有这样几个特点：</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#Flink%E4%BC%9A%E6%8A%8A%E8%BF%99%E6%A0%B7%E7%9A%84%E7%B1%BB%E4%BD%9C%E4%B8%BA%E4%B8%80%E7%A7%8D%E7%89%B9%E6%AE%8A%E7%9A%84POJO%EF%BC%88Plain-Ordinary-Java-Object%E7%AE%80%E5%8D%95%E7%9A%84Java%E5%AF%B9%E8%B1%A1%EF%BC%8C%E5%AE%9E%E9%99%85%E5%B0%B1%E6%98%AF%E6%99%AE%E9%80%9AJavaBeans%EF%BC%89%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%E6%9D%A5%E5%AF%B9%E5%BE%85%EF%BC%8C%E6%96%B9%E4%BE%BF%E6%95%B0%E6%8D%AE%E7%9A%84%E8%A7%A3%E6%9E%90%E5%92%8C%E5%BA%8F%E5%88%97%E5%8C%96%E3%80%82%E5%8F%A6%E5%A4%96%E6%88%91%E4%BB%AC%E5%9C%A8%E7%B1%BB%E4%B8%AD%E8%BF%98%E9%87%8D%E5%86%99%E4%BA%86toString%E6%96%B9%E6%B3%95%EF%BC%8C%E4%B8%BB%E8%A6%81%E6%98%AF%E4%B8%BA%E4%BA%86%E6%B5%8B%E8%AF%95%E8%BE%93%E5%87%BA%E6%98%BE%E7%A4%BA%E6%9B%B4%E6%B8%85%E6%99%B0%E3%80%82"><span class="toc-number">0.1.</span> <span class="toc-text">Flink会把这样的类作为一种特殊的POJO（Plain Ordinary Java Object简单的Java对象，实际就是普通JavaBeans）数据类型来对待，方便数据的解析和序列化。另外我们在类中还重写了toString方法，主要是为了测试输出显示更清晰。</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#%E6%88%91%E4%BB%AC%E8%BF%99%E9%87%8C%E8%87%AA%E5%AE%9A%E4%B9%89%E7%9A%84POJO%E7%B1%BB%E4%BC%9A%E5%9C%A8%E5%90%8E%E9%9D%A2%E7%9A%84%E4%BB%A3%E7%A0%81%E4%B8%AD%E9%A2%91%E7%B9%81%E4%BD%BF%E7%94%A8%EF%BC%8C%E6%89%80%E4%BB%A5%E5%9C%A8%E5%90%8E%E9%9D%A2%E7%9A%84%E4%BB%A3%E7%A0%81%E4%B8%AD%E7%A2%B0%E5%88%B0%EF%BC%8C%E6%8A%8A%E8%BF%99%E9%87%8C%E7%9A%84POJO%E7%B1%BB%E5%AF%BC%E5%85%A5%E5%B0%B1%E5%A5%BD%E4%BA%86%E3%80%82"><span class="toc-number">0.2.</span> <span class="toc-text">我们这里自定义的POJO类会在后面的代码中频繁使用，所以在后面的代码中碰到，把这里的POJO类导入就好了。</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E4%BB%8E%E9%9B%86%E5%90%88%E3%80%81%E6%96%87%E4%BB%B6%E3%80%81%E5%85%83%E7%B4%A0%E4%B8%AD%E8%AF%BB%E5%8F%96%E6%95%B0%E6%8D%AE"><span class="toc-number"></span> <span class="toc-text">1.从集合、文件、元素中读取数据</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%9C%80%E7%AE%80%E5%8D%95%E7%9A%84%E8%AF%BB%E5%8F%96%E6%95%B0%E6%8D%AE%E7%9A%84%E6%96%B9%E5%BC%8F%EF%BC%8C%E5%B0%B1%E6%98%AF%E5%9C%A8%E4%BB%A3%E7%A0%81%E4%B8%AD%E7%9B%B4%E6%8E%A5%E5%88%9B%E5%BB%BA%E4%B8%80%E4%B8%AAJava%E9%9B%86%E5%90%88%EF%BC%8C%E7%84%B6%E5%90%8E%E8%B0%83%E7%94%A8%E6%89%A7%E8%A1%8C%E7%8E%AF%E5%A2%83%E7%9A%84fromCollection%E6%96%B9%E6%B3%95%E8%BF%9B%E8%A1%8C%E8%AF%BB%E5%8F%96%E3%80%82%E8%BF%99%E7%9B%B8%E5%BD%93%E4%BA%8E%E5%B0%86%E6%95%B0%E6%8D%AE%E4%B8%B4%E6%97%B6%E5%AD%98%E5%82%A8%E5%88%B0%E5%86%85%E5%AD%98%E4%B8%AD%EF%BC%8C%E5%BD%A2%E6%88%90%E7%89%B9%E6%AE%8A%E7%9A%84%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%90%8E%EF%BC%8C%E4%BD%9C%E4%B8%BA%E6%95%B0%E6%8D%AE%E6%BA%90%E4%BD%BF%E7%94%A8%EF%BC%8C%E4%B8%80%E8%88%AC%E7%94%A8%E4%BA%8E%E6%B5%8B%E8%AF%95%E3%80%82"><span class="toc-number">1.</span> <span class="toc-text">最简单的读取数据的方式，就是在代码中直接创建一个Java集合，然后调用执行环境的fromCollection方法进行读取。这相当于将数据临时存储到内存中，形成特殊的数据结构后，作为数据源使用，一般用于测试。</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-2%E4%BB%8ESocket%E8%AF%BB%E5%8F%96%E6%95%B0%E6%8D%AE"><span class="toc-number"></span> <span class="toc-text">1.2从Socket读取数据</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#%E4%B8%8D%E8%AE%BA%E4%BB%8E%E9%9B%86%E5%90%88%E8%BF%98%E6%98%AF%E6%96%87%E4%BB%B6%EF%BC%8C%E6%88%91%E4%BB%AC%E8%AF%BB%E5%8F%96%E7%9A%84%E5%85%B6%E5%AE%9E%E9%83%BD%E6%98%AF%E6%9C%89%E7%95%8C%E6%95%B0%E6%8D%AE%E3%80%82%E5%9C%A8%E6%B5%81%E5%A4%84%E7%90%86%E7%9A%84%E5%9C%BA%E6%99%AF%E4%B8%AD%EF%BC%8C%E6%95%B0%E6%8D%AE%E5%BE%80%E5%BE%80%E6%98%AF%E6%97%A0%E7%95%8C%E7%9A%84%E3%80%82"><span class="toc-number">0.1.</span> <span class="toc-text">不论从集合还是文件，我们读取的其实都是有界数据。在流处理的场景中，数据往往是无界的。</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#%E6%88%91%E4%BB%AC%E4%B9%8B%E5%89%8D%E7%94%A8%E5%88%B0%E7%9A%84%E8%AF%BB%E5%8F%96socket%E6%96%87%E6%9C%AC%E6%B5%81%EF%BC%8C%E5%B0%B1%E6%98%AF%E6%B5%81%E5%A4%84%E7%90%86%E5%9C%BA%E6%99%AF%E3%80%82%E4%BD%86%E6%98%AF%E8%BF%99%E7%A7%8D%E6%96%B9%E5%BC%8F%E7%94%B1%E4%BA%8E%E5%90%9E%E5%90%90%E9%87%8F%E5%B0%8F%E3%80%81%E7%A8%B3%E5%AE%9A%E6%80%A7%E8%BE%83%E5%B7%AE%EF%BC%8C%E4%B8%80%E8%88%AC%E4%B9%9F%E6%98%AF%E7%94%A8%E4%BA%8E%E6%B5%8B%E8%AF%95%E3%80%82"><span class="toc-number">0.2.</span> <span class="toc-text">我们之前用到的读取socket文本流，就是流处理场景。但是这种方式由于吞吐量小、稳定性较差，一般也是用于测试。</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-3%E4%BB%8EKafka%E4%B8%AD%E8%AF%BB%E5%8F%96%E6%95%B0%E6%8D%AE"><span class="toc-number"></span> <span class="toc-text">1.3从Kafka中读取数据</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#Flink%E5%AE%98%E6%96%B9%E6%8F%90%E4%BE%9B%E4%BA%86%E8%BF%9E%E6%8E%A5%E5%B7%A5%E5%85%B7flink-connector-kafka%EF%BC%8C%E7%9B%B4%E6%8E%A5%E5%B8%AE%E6%88%91%E4%BB%AC%E5%AE%9E%E7%8E%B0%E4%BA%86%E4%B8%80%E4%B8%AA%E6%B6%88%E8%B4%B9%E8%80%85FlinkKafkaConsumer%EF%BC%8C%E5%AE%83%E5%B0%B1%E6%98%AF%E7%94%A8%E6%9D%A5%E8%AF%BB%E5%8F%96Kafka%E6%95%B0%E6%8D%AE%E7%9A%84SourceFunction%E3%80%82"><span class="toc-number">0.1.</span> <span class="toc-text">Flink官方提供了连接工具flink-connector-kafka，直接帮我们实现了一个消费者FlinkKafkaConsumer，它就是用来读取Kafka数据的SourceFunction。</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#%E6%89%80%E4%BB%A5%E6%83%B3%E8%A6%81%E4%BB%A5Kafka%E4%BD%9C%E4%B8%BA%E6%95%B0%E6%8D%AE%E6%BA%90%E8%8E%B7%E5%8F%96%E6%95%B0%E6%8D%AE%EF%BC%8C%E6%88%91%E4%BB%AC%E5%8F%AA%E9%9C%80%E8%A6%81%E5%BC%95%E5%85%A5Kafka%E8%BF%9E%E6%8E%A5%E5%99%A8%E7%9A%84%E4%BE%9D%E8%B5%96%E3%80%82Flink%E5%AE%98%E6%96%B9%E6%8F%90%E4%BE%9B%E7%9A%84%E6%98%AF%E4%B8%80%E4%B8%AA%E9%80%9A%E7%94%A8%E7%9A%84Kafka%E8%BF%9E%E6%8E%A5%E5%99%A8%EF%BC%8C%E5%AE%83%E4%BC%9A%E8%87%AA%E5%8A%A8%E8%B7%9F%E8%B8%AA%E6%9C%80%E6%96%B0%E7%89%88%E6%9C%AC%E7%9A%84Kafka%E5%AE%A2%E6%88%B7%E7%AB%AF%E3%80%82%E7%9B%AE%E5%89%8D%E6%9C%80%E6%96%B0%E7%89%88%E6%9C%AC%E5%8F%AA%E6%94%AF%E6%8C%810-10-0%E7%89%88%E6%9C%AC%E4%BB%A5%E4%B8%8A%E7%9A%84Kafka%E3%80%82%E8%BF%99%E9%87%8C%E6%88%91%E4%BB%AC%E9%9C%80%E8%A6%81%E5%AF%BC%E5%85%A5%E7%9A%84%E4%BE%9D%E8%B5%96%E5%A6%82%E4%B8%8B%E3%80%82"><span class="toc-number">0.2.</span> <span class="toc-text">所以想要以Kafka作为数据源获取数据，我们只需要引入Kafka连接器的依赖。Flink官方提供的是一个通用的Kafka连接器，它会自动跟踪最新版本的Kafka客户端。目前最新版本只支持0.10.0版本以上的Kafka。这里我们需要导入的依赖如下。</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BB%A3%E7%A0%81%E5%A6%82%E4%B8%8B%EF%BC%9A"><span class="toc-number"></span> <span class="toc-text">代码如下：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-4-%E4%BB%8E%E6%95%B0%E6%8D%AE%E7%94%9F%E6%88%90%E5%99%A8%E8%AF%BB%E5%8F%96%E6%95%B0%E6%8D%AE"><span class="toc-number"></span> <span class="toc-text">1.4 从数据生成器读取数据</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#Flink%E4%BB%8E1-11%E5%BC%80%E5%A7%8B%E6%8F%90%E4%BE%9B%E4%BA%86%E4%B8%80%E4%B8%AA%E5%86%85%E7%BD%AE%E7%9A%84DataGen-%E8%BF%9E%E6%8E%A5%E5%99%A8%EF%BC%8C%E4%B8%BB%E8%A6%81%E6%98%AF%E7%94%A8%E4%BA%8E%E7%94%9F%E6%88%90%E4%B8%80%E4%BA%9B%E9%9A%8F%E6%9C%BA%E6%95%B0%EF%BC%8C%E7%94%A8%E4%BA%8E%E5%9C%A8%E6%B2%A1%E6%9C%89%E6%95%B0%E6%8D%AE%E6%BA%90%E7%9A%84%E6%97%B6%E5%80%99%EF%BC%8C%E8%BF%9B%E8%A1%8C%E6%B5%81%E4%BB%BB%E5%8A%A1%E7%9A%84%E6%B5%8B%E8%AF%95%E4%BB%A5%E5%8F%8A%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E7%AD%89%E3%80%821-17%E6%8F%90%E4%BE%9B%E4%BA%86%E6%96%B0%E7%9A%84Source%E5%86%99%E6%B3%95%EF%BC%8C%E9%9C%80%E8%A6%81%E5%AF%BC%E5%85%A5%E4%BE%9D%E8%B5%96%EF%BC%9A"><span class="toc-number">0.1.</span> <span class="toc-text">Flink从1.11开始提供了一个内置的DataGen 连接器，主要是用于生成一些随机数，用于在没有数据源的时候，进行流任务的测试以及性能测试等。1.17提供了新的Source写法，需要导入依赖：</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BB%A3%E7%A0%81%E5%A6%82%E4%B8%8B%EF%BC%9A-1"><span class="toc-number"></span> <span class="toc-text">代码如下：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-5Flink%E6%94%AF%E6%8C%81%E7%9A%84%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B"><span class="toc-number"></span> <span class="toc-text">1.5Flink支持的数据类型</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#Flink%E7%9A%84%E7%B1%BB%E5%9E%8B%E7%B3%BB%E7%BB%9F"><span class="toc-number">1.</span> <span class="toc-text">Flink的类型系统</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Flink%E6%94%AF%E6%8C%81%E7%9A%84%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B"><span class="toc-number">2.</span> <span class="toc-text">Flink支持的数据类型</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%EF%BC%881%EF%BC%89%E5%9F%BA%E6%9C%AC%E7%B1%BB%E5%9E%8B"><span class="toc-number">3.</span> <span class="toc-text">（1）基本类型</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%EF%BC%882%EF%BC%89%E6%95%B0%E7%BB%84%E7%B1%BB%E5%9E%8B"><span class="toc-number">4.</span> <span class="toc-text">（2）数组类型</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%EF%BC%883%EF%BC%89%E5%A4%8D%E5%90%88%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B"><span class="toc-number">5.</span> <span class="toc-text">（3）复合数据类型</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Scala-%E6%A0%B7%E4%BE%8B%E7%B1%BB%E5%8F%8AScala%E5%85%83%E7%BB%84%EF%BC%9A%E4%B8%8D%E6%94%AF%E6%8C%81%E7%A9%BA%E5%AD%97%E6%AE%B5%E3%80%82"><span class="toc-number">6.</span> <span class="toc-text">Scala 样例类及Scala元组：不支持空字段。</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E8%A1%8C%E7%B1%BB%E5%9E%8B%EF%BC%88ROW%EF%BC%89%EF%BC%9A%E5%8F%AF%E4%BB%A5%E8%AE%A4%E4%B8%BA%E6%98%AF%E5%85%B7%E6%9C%89%E4%BB%BB%E6%84%8F%E4%B8%AA%E5%AD%97%E6%AE%B5%E7%9A%84%E5%85%83%E7%BB%84%EF%BC%8C%E5%B9%B6%E6%94%AF%E6%8C%81%E7%A9%BA%E5%AD%97%E6%AE%B5%E3%80%82"><span class="toc-number">7.</span> <span class="toc-text">行类型（ROW）：可以认为是具有任意个字段的元组，并支持空字段。</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#POJO%EF%BC%9AFlink%E8%87%AA%E5%AE%9A%E4%B9%89%E7%9A%84%E7%B1%BB%E4%BC%BC%E4%BA%8EJava-bean%E6%A8%A1%E5%BC%8F%E7%9A%84%E7%B1%BB%E3%80%82"><span class="toc-number">8.</span> <span class="toc-text">POJO：Flink自定义的类似于Java bean模式的类。</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%EF%BC%884%EF%BC%89%E8%BE%85%E5%8A%A9%E7%B1%BB%E5%9E%8B"><span class="toc-number"></span> <span class="toc-text">（4）辅助类型</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#Option%E3%80%81Either%E3%80%81List%E3%80%81Map%E7%AD%89%E3%80%82"><span class="toc-number">1.</span> <span class="toc-text">Option、Either、List、Map等。</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%EF%BC%885%EF%BC%89%E6%B3%9B%E5%9E%8B%E7%B1%BB%E5%9E%8B%EF%BC%88GENERIC%EF%BC%89"><span class="toc-number"></span> <span class="toc-text">（5）泛型类型（GENERIC）</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#Flink%E6%94%AF%E6%8C%81%E6%89%80%E6%9C%89%E7%9A%84Java%E7%B1%BB%E5%92%8CScala%E7%B1%BB%E3%80%82%E4%B8%8D%E8%BF%87%E5%A6%82%E6%9E%9C%E6%B2%A1%E6%9C%89%E6%8C%89%E7%85%A7%E4%B8%8A%E9%9D%A2POJO%E7%B1%BB%E5%9E%8B%E7%9A%84%E8%A6%81%E6%B1%82%E6%9D%A5%E5%AE%9A%E4%B9%89%EF%BC%8C%E5%B0%B1%E4%BC%9A%E8%A2%ABFlink%E5%BD%93%E4%BD%9C%E6%B3%9B%E5%9E%8B%E7%B1%BB%E6%9D%A5%E5%A4%84%E7%90%86%E3%80%82Flink%E4%BC%9A%E6%8A%8A%E6%B3%9B%E5%9E%8B%E7%B1%BB%E5%9E%8B%E5%BD%93%E4%BD%9C%E9%BB%91%E7%9B%92%EF%BC%8C%E6%97%A0%E6%B3%95%E8%8E%B7%E5%8F%96%E5%AE%83%E4%BB%AC%E5%86%85%E9%83%A8%E7%9A%84%E5%B1%9E%E6%80%A7%EF%BC%9B%E5%AE%83%E4%BB%AC%E4%B9%9F%E4%B8%8D%E6%98%AF%E7%94%B1Flink%E6%9C%AC%E8%BA%AB%E5%BA%8F%E5%88%97%E5%8C%96%E7%9A%84%EF%BC%8C%E8%80%8C%E6%98%AF%E7%94%B1Kryo%E5%BA%8F%E5%88%97%E5%8C%96%E7%9A%84%E3%80%82"><span class="toc-number">0.1.</span> <span class="toc-text">Flink支持所有的Java类和Scala类。不过如果没有按照上面POJO类型的要求来定义，就会被Flink当作泛型类来处理。Flink会把泛型类型当作黑盒，无法获取它们内部的属性；它们也不是由Flink本身序列化的，而是由Kryo序列化的。</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#%E5%9C%A8%E8%BF%99%E4%BA%9B%E7%B1%BB%E5%9E%8B%E4%B8%AD%EF%BC%8C%E5%85%83%E7%BB%84%E7%B1%BB%E5%9E%8B%E5%92%8CPOJO%E7%B1%BB%E5%9E%8B%E6%9C%80%E4%B8%BA%E7%81%B5%E6%B4%BB%EF%BC%8C%E5%9B%A0%E4%B8%BA%E5%AE%83%E4%BB%AC%E6%94%AF%E6%8C%81%E5%88%9B%E5%BB%BA%E5%A4%8D%E6%9D%82%E7%B1%BB%E5%9E%8B%E3%80%82%E8%80%8C%E7%9B%B8%E6%AF%94%E4%B9%8B%E4%B8%8B%EF%BC%8CPOJO%E8%BF%98%E6%94%AF%E6%8C%81%E5%9C%A8%E9%94%AE%EF%BC%88key%EF%BC%89%E7%9A%84%E5%AE%9A%E4%B9%89%E4%B8%AD%E7%9B%B4%E6%8E%A5%E4%BD%BF%E7%94%A8%E5%AD%97%E6%AE%B5%E5%90%8D%EF%BC%8C%E8%BF%99%E4%BC%9A%E8%AE%A9%E6%88%91%E4%BB%AC%E7%9A%84%E4%BB%A3%E7%A0%81%E5%8F%AF%E8%AF%BB%E6%80%A7%E5%A4%A7%E5%A4%A7%E5%A2%9E%E5%8A%A0%E3%80%82%E6%89%80%E4%BB%A5%EF%BC%8C%E5%9C%A8%E9%A1%B9%E7%9B%AE%E5%AE%9E%E8%B7%B5%E4%B8%AD%EF%BC%8C%E5%BE%80%E5%BE%80%E4%BC%9A%E5%B0%86%E6%B5%81%E5%A4%84%E7%90%86%E7%A8%8B%E5%BA%8F%E4%B8%AD%E7%9A%84%E5%85%83%E7%B4%A0%E7%B1%BB%E5%9E%8B%E5%AE%9A%E4%B8%BAFlink%E7%9A%84POJO%E7%B1%BB%E5%9E%8B%E3%80%82"><span class="toc-number">0.2.</span> <span class="toc-text">在这些类型中，元组类型和POJO类型最为灵活，因为它们支持创建复杂类型。而相比之下，POJO还支持在键（key）的定义中直接使用字段名，这会让我们的代码可读性大大增加。所以，在项目实践中，往往会将流处理程序中的元素类型定为Flink的POJO类型。</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#Flink%E5%AF%B9POJO%E7%B1%BB%E5%9E%8B%E7%9A%84%E8%A6%81%E6%B1%82%E5%A6%82%E4%B8%8B%EF%BC%9A"><span class="toc-number">0.3.</span> <span class="toc-text">Flink对POJO类型的要求如下：</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#%E7%B1%BB%E6%98%AF%E5%85%AC%E6%9C%89%EF%BC%88public%EF%BC%89%E7%9A%84"><span class="toc-number">0.4.</span> <span class="toc-text">类是公有（public）的</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#%E6%9C%89%E4%B8%80%E4%B8%AA%E6%97%A0%E5%8F%82%E7%9A%84%E6%9E%84%E9%80%A0%E6%96%B9%E6%B3%95"><span class="toc-number">0.5.</span> <span class="toc-text">有一个无参的构造方法</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#%E6%89%80%E6%9C%89%E5%B1%9E%E6%80%A7%E9%83%BD%E6%98%AF%E5%85%AC%E6%9C%89%EF%BC%88public%EF%BC%89%E7%9A%84"><span class="toc-number">0.6.</span> <span class="toc-text">所有属性都是公有（public）的</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#%E6%89%80%E6%9C%89%E5%B1%9E%E6%80%A7%E7%9A%84%E7%B1%BB%E5%9E%8B%E9%83%BD%E6%98%AF%E5%8F%AF%E4%BB%A5%E5%BA%8F%E5%88%97%E5%8C%96%E7%9A%84"><span class="toc-number">0.7.</span> <span class="toc-text">所有属性的类型都是可以序列化的</span></a></li></ol></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3%EF%BC%89%E7%B1%BB%E5%9E%8B%E6%8F%90%E7%A4%BA%EF%BC%88Type-Hints%EF%BC%89"><span class="toc-number"></span> <span class="toc-text">3）类型提示（Type Hints）</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#Flink%E8%BF%98%E5%85%B7%E6%9C%89%E4%B8%80%E4%B8%AA%E7%B1%BB%E5%9E%8B%E6%8F%90%E5%8F%96%E7%B3%BB%E7%BB%9F%EF%BC%8C%E5%8F%AF%E4%BB%A5%E5%88%86%E6%9E%90%E5%87%BD%E6%95%B0%E7%9A%84%E8%BE%93%E5%85%A5%E5%92%8C%E8%BF%94%E5%9B%9E%E7%B1%BB%E5%9E%8B%EF%BC%8C%E8%87%AA%E5%8A%A8%E8%8E%B7%E5%8F%96%E7%B1%BB%E5%9E%8B%E4%BF%A1%E6%81%AF%EF%BC%8C%E4%BB%8E%E8%80%8C%E8%8E%B7%E5%BE%97%E5%AF%B9%E5%BA%94%E7%9A%84%E5%BA%8F%E5%88%97%E5%8C%96%E5%99%A8%E5%92%8C%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96%E5%99%A8%E3%80%82%E4%BD%86%E6%98%AF%EF%BC%8C%E7%94%B1%E4%BA%8EJava%E4%B8%AD%E6%B3%9B%E5%9E%8B%E6%93%A6%E9%99%A4%E7%9A%84%E5%AD%98%E5%9C%A8%EF%BC%8C%E5%9C%A8%E6%9F%90%E4%BA%9B%E7%89%B9%E6%AE%8A%E6%83%85%E5%86%B5%E4%B8%8B%EF%BC%88%E6%AF%94%E5%A6%82Lambda%E8%A1%A8%E8%BE%BE%E5%BC%8F%E4%B8%AD%EF%BC%89%EF%BC%8C%E8%87%AA%E5%8A%A8%E6%8F%90%E5%8F%96%E7%9A%84%E4%BF%A1%E6%81%AF%E6%98%AF%E4%B8%8D%E5%A4%9F%E7%B2%BE%E7%BB%86%E7%9A%84%E2%80%94%E2%80%94%E5%8F%AA%E5%91%8A%E8%AF%89Flink%E5%BD%93%E5%89%8D%E7%9A%84%E5%85%83%E7%B4%A0%E7%94%B1%E2%80%9C%E8%88%B9%E5%A4%B4%E3%80%81%E8%88%B9%E8%BA%AB%E3%80%81%E8%88%B9%E5%B0%BE%E2%80%9D%E6%9E%84%E6%88%90%EF%BC%8C%E6%A0%B9%E6%9C%AC%E6%97%A0%E6%B3%95%E9%87%8D%E5%BB%BA%E5%87%BA%E2%80%9C%E5%A4%A7%E8%88%B9%E2%80%9D%E7%9A%84%E6%A8%A1%E6%A0%B7%EF%BC%9B%E8%BF%99%E6%97%B6%E5%B0%B1%E9%9C%80%E8%A6%81%E6%98%BE%E5%BC%8F%E5%9C%B0%E6%8F%90%E4%BE%9B%E7%B1%BB%E5%9E%8B%E4%BF%A1%E6%81%AF%EF%BC%8C%E6%89%8D%E8%83%BD%E4%BD%BF%E5%BA%94%E7%94%A8%E7%A8%8B%E5%BA%8F%E6%AD%A3%E5%B8%B8%E5%B7%A5%E4%BD%9C%E6%88%96%E6%8F%90%E9%AB%98%E5%85%B6%E6%80%A7%E8%83%BD%E3%80%82"><span class="toc-number">0.1.</span> <span class="toc-text">Flink还具有一个类型提取系统，可以分析函数的输入和返回类型，自动获取类型信息，从而获得对应的序列化器和反序列化器。但是，由于Java中泛型擦除的存在，在某些特殊情况下（比如Lambda表达式中），自动提取的信息是不够精细的——只告诉Flink当前的元素由“船头、船身、船尾”构成，根本无法重建出“大船”的模样；这时就需要显式地提供类型信息，才能使应用程序正常工作或提高其性能。</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#%E4%B8%BA%E4%BA%86%E8%A7%A3%E5%86%B3%E8%BF%99%E7%B1%BB%E9%97%AE%E9%A2%98%EF%BC%8CJava-API%E6%8F%90%E4%BE%9B%E4%BA%86%E4%B8%93%E9%97%A8%E7%9A%84%E2%80%9C%E7%B1%BB%E5%9E%8B%E6%8F%90%E7%A4%BA%E2%80%9D%EF%BC%88type-hints%EF%BC%89%E3%80%82"><span class="toc-number">0.2.</span> <span class="toc-text">为了解决这类问题，Java API提供了专门的“类型提示”（type hints）。</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#%E5%9B%9E%E5%BF%86%E4%B8%80%E4%B8%8B%E4%B9%8B%E5%89%8D%E7%9A%84word-count%E6%B5%81%E5%A4%84%E7%90%86%E7%A8%8B%E5%BA%8F%EF%BC%8C%E6%88%91%E4%BB%AC%E5%9C%A8%E5%B0%86String%E7%B1%BB%E5%9E%8B%E7%9A%84%E6%AF%8F%E4%B8%AA%E8%AF%8D%E8%BD%AC%E6%8D%A2%E6%88%90%EF%BC%88word%EF%BC%8C-count%EF%BC%89%E4%BA%8C%E5%85%83%E7%BB%84%E5%90%8E%EF%BC%8C%E5%B0%B1%E6%98%8E%E7%A1%AE%E5%9C%B0%E7%94%A8returns%E6%8C%87%E5%AE%9A%E4%BA%86%E8%BF%94%E5%9B%9E%E7%9A%84%E7%B1%BB%E5%9E%8B%E3%80%82%E5%9B%A0%E4%B8%BA%E5%AF%B9%E4%BA%8Emap%E9%87%8C%E4%BC%A0%E5%85%A5%E7%9A%84Lambda%E8%A1%A8%E8%BE%BE%E5%BC%8F%EF%BC%8C%E7%B3%BB%E7%BB%9F%E5%8F%AA%E8%83%BD%E6%8E%A8%E6%96%AD%E5%87%BA%E8%BF%94%E5%9B%9E%E7%9A%84%E6%98%AFTuple2%E7%B1%BB%E5%9E%8B%EF%BC%8C%E8%80%8C%E6%97%A0%E6%B3%95%E5%BE%97%E5%88%B0Tuple2-lt-String-Long-gt-%E3%80%82%E5%8F%AA%E6%9C%89%E6%98%BE%E5%BC%8F%E5%9C%B0%E5%91%8A%E8%AF%89%E7%B3%BB%E7%BB%9F%E5%BD%93%E5%89%8D%E7%9A%84%E8%BF%94%E5%9B%9E%E7%B1%BB%E5%9E%8B%EF%BC%8C%E6%89%8D%E8%83%BD%E6%AD%A3%E7%A1%AE%E5%9C%B0%E8%A7%A3%E6%9E%90%E5%87%BA%E5%AE%8C%E6%95%B4%E6%95%B0%E6%8D%AE%E3%80%82"><span class="toc-number">0.3.</span> <span class="toc-text">回忆一下之前的word count流处理程序，我们在将String类型的每个词转换成（word， count）二元组后，就明确地用returns指定了返回的类型。因为对于map里传入的Lambda表达式，系统只能推断出返回的是Tuple2类型，而无法得到Tuple2&lt;String, Long&gt;。只有显式地告诉系统当前的返回类型，才能正确地解析出完整数据。</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#Flink%E8%BF%98%E4%B8%93%E9%97%A8%E6%8F%90%E4%BE%9B%E4%BA%86TypeHint%E7%B1%BB%EF%BC%8C%E5%AE%83%E5%8F%AF%E4%BB%A5%E6%8D%95%E8%8E%B7%E6%B3%9B%E5%9E%8B%E7%9A%84%E7%B1%BB%E5%9E%8B%E4%BF%A1%E6%81%AF%EF%BC%8C%E5%B9%B6%E4%B8%94%E4%B8%80%E7%9B%B4%E8%AE%B0%E5%BD%95%E4%B8%8B%E6%9D%A5%EF%BC%8C%E4%B8%BA%E8%BF%90%E8%A1%8C%E6%97%B6%E6%8F%90%E4%BE%9B%E8%B6%B3%E5%A4%9F%E7%9A%84%E4%BF%A1%E6%81%AF%E3%80%82%E6%88%91%E4%BB%AC%E5%90%8C%E6%A0%B7%E5%8F%AF%E4%BB%A5%E9%80%9A%E8%BF%87-returns-%E6%96%B9%E6%B3%95%EF%BC%8C%E6%98%8E%E7%A1%AE%E5%9C%B0%E6%8C%87%E5%AE%9A%E8%BD%AC%E6%8D%A2%E4%B9%8B%E5%90%8E%E7%9A%84DataStream%E9%87%8C%E5%85%83%E7%B4%A0%E7%9A%84%E7%B1%BB%E5%9E%8B%E3%80%82"><span class="toc-number">0.4.</span> <span class="toc-text">Flink还专门提供了TypeHint类，它可以捕获泛型的类型信息，并且一直记录下来，为运行时提供足够的信息。我们同样可以通过.returns()方法，明确地指定转换之后的DataStream里元素的类型。</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%BD%AC%E6%8D%A2%E7%AE%97%E5%AD%90%EF%BC%88Transformation%EF%BC%89"><span class="toc-number"></span> <span class="toc-text">转换算子（Transformation）</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E6%BA%90%E8%AF%BB%E5%85%A5%E6%95%B0%E6%8D%AE%E4%B9%8B%E5%90%8E%EF%BC%8C%E6%88%91%E4%BB%AC%E5%B0%B1%E5%8F%AF%E4%BB%A5%E4%BD%BF%E7%94%A8%E5%90%84%E7%A7%8D%E8%BD%AC%E6%8D%A2%E7%AE%97%E5%AD%90%EF%BC%8C%E5%B0%86%E4%B8%80%E4%B8%AA%E6%88%96%E5%A4%9A%E4%B8%AADataStream%E8%BD%AC%E6%8D%A2%E4%B8%BA%E6%96%B0%E7%9A%84DataStream%E3%80%82"><span class="toc-number">1.</span> <span class="toc-text">数据源读入数据之后，我们就可以使用各种转换算子，将一个或多个DataStream转换为新的DataStream。</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E5%9F%BA%E6%9C%AC%E8%BD%AC%E6%8D%A2%E7%AE%97%E5%AD%90%EF%BC%88map-x2F-filter-x2F-flatMap%EF%BC%89"><span class="toc-number"></span> <span class="toc-text">1.基本转换算子（map&#x2F; filter&#x2F; flatMap）</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-1-1%E6%98%A0%E5%B0%84%EF%BC%88map%EF%BC%89"><span class="toc-number"></span> <span class="toc-text">1.1.1映射（map）</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#map%E6%98%AF%E5%A4%A7%E5%AE%B6%E9%9D%9E%E5%B8%B8%E7%86%9F%E6%82%89%E7%9A%84%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%93%8D%E4%BD%9C%E7%AE%97%E5%AD%90%EF%BC%8C%E4%B8%BB%E8%A6%81%E7%94%A8%E4%BA%8E%E5%B0%86%E6%95%B0%E6%8D%AE%E6%B5%81%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE%E8%BF%9B%E8%A1%8C%E8%BD%AC%E6%8D%A2%EF%BC%8C%E5%BD%A2%E6%88%90%E6%96%B0%E7%9A%84%E6%95%B0%E6%8D%AE%E6%B5%81%E3%80%82%E7%AE%80%E5%8D%95%E6%9D%A5%E8%AF%B4%EF%BC%8C%E5%B0%B1%E6%98%AF%E4%B8%80%E4%B8%AA%E2%80%9C%E4%B8%80%E4%B8%80%E6%98%A0%E5%B0%84%E2%80%9D%EF%BC%8C%E6%B6%88%E8%B4%B9%E4%B8%80%E4%B8%AA%E5%85%83%E7%B4%A0%E5%B0%B1%E4%BA%A7%E5%87%BA%E4%B8%80%E4%B8%AA%E5%85%83%E7%B4%A0%E3%80%82"><span class="toc-number">0.1.</span> <span class="toc-text">map是大家非常熟悉的大数据操作算子，主要用于将数据流中的数据进行转换，形成新的数据流。简单来说，就是一个“一一映射”，消费一个元素就产出一个元素。</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#%E6%88%91%E4%BB%AC%E5%8F%AA%E9%9C%80%E8%A6%81%E5%9F%BA%E4%BA%8EDataStream%E8%B0%83%E7%94%A8map-%E6%96%B9%E6%B3%95%E5%B0%B1%E5%8F%AF%E4%BB%A5%E8%BF%9B%E8%A1%8C%E8%BD%AC%E6%8D%A2%E5%A4%84%E7%90%86%E3%80%82%E6%96%B9%E6%B3%95%E9%9C%80%E8%A6%81%E4%BC%A0%E5%85%A5%E7%9A%84%E5%8F%82%E6%95%B0%E6%98%AF%E6%8E%A5%E5%8F%A3MapFunction%E7%9A%84%E5%AE%9E%E7%8E%B0%EF%BC%9B%E8%BF%94%E5%9B%9E%E5%80%BC%E7%B1%BB%E5%9E%8B%E8%BF%98%E6%98%AFDataStream%EF%BC%8C%E4%B8%8D%E8%BF%87%E6%B3%9B%E5%9E%8B%EF%BC%88%E6%B5%81%E4%B8%AD%E7%9A%84%E5%85%83%E7%B4%A0%E7%B1%BB%E5%9E%8B%EF%BC%89%E5%8F%AF%E8%83%BD%E6%94%B9%E5%8F%98%E3%80%82"><span class="toc-number">0.2.</span> <span class="toc-text">我们只需要基于DataStream调用map()方法就可以进行转换处理。方法需要传入的参数是接口MapFunction的实现；返回值类型还是DataStream，不过泛型（流中的元素类型）可能改变。</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#%E4%B8%8B%E9%9D%A2%E7%9A%84%E4%BB%A3%E7%A0%81%E7%94%A8%E4%B8%8D%E5%90%8C%E7%9A%84%E6%96%B9%E5%BC%8F%EF%BC%8C%E5%AE%9E%E7%8E%B0%E4%BA%86%E6%8F%90%E5%8F%96WaterSensor%E4%B8%AD%E7%9A%84id%E5%AD%97%E6%AE%B5%E7%9A%84%E5%8A%9F%E8%83%BD%E3%80%82"><span class="toc-number">0.3.</span> <span class="toc-text">下面的代码用不同的方式，实现了提取WaterSensor中的id字段的功能。</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#%E4%B8%8A%E9%9D%A2%E4%BB%A3%E7%A0%81%E4%B8%AD%EF%BC%8CMapFunction%E5%AE%9E%E7%8E%B0%E7%B1%BB%E7%9A%84%E6%B3%9B%E5%9E%8B%E7%B1%BB%E5%9E%8B%EF%BC%8C%E4%B8%8E%E8%BE%93%E5%85%A5%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%E5%92%8C%E8%BE%93%E5%87%BA%E6%95%B0%E6%8D%AE%E7%9A%84%E7%B1%BB%E5%9E%8B%E6%9C%89%E5%85%B3%E3%80%82%E5%9C%A8%E5%AE%9E%E7%8E%B0MapFunction%E6%8E%A5%E5%8F%A3%E7%9A%84%E6%97%B6%E5%80%99%EF%BC%8C%E9%9C%80%E8%A6%81%E6%8C%87%E5%AE%9A%E4%B8%A4%E4%B8%AA%E6%B3%9B%E5%9E%8B%EF%BC%8C%E5%88%86%E5%88%AB%E6%98%AF%E8%BE%93%E5%85%A5%E4%BA%8B%E4%BB%B6%E5%92%8C%E8%BE%93%E5%87%BA%E4%BA%8B%E4%BB%B6%E7%9A%84%E7%B1%BB%E5%9E%8B%EF%BC%8C%E8%BF%98%E9%9C%80%E8%A6%81%E9%87%8D%E5%86%99%E4%B8%80%E4%B8%AAmap-%E6%96%B9%E6%B3%95%EF%BC%8C%E5%AE%9A%E4%B9%89%E4%BB%8E%E4%B8%80%E4%B8%AA%E8%BE%93%E5%85%A5%E4%BA%8B%E4%BB%B6%E8%BD%AC%E6%8D%A2%E4%B8%BA%E5%8F%A6%E4%B8%80%E4%B8%AA%E8%BE%93%E5%87%BA%E4%BA%8B%E4%BB%B6%E7%9A%84%E5%85%B7%E4%BD%93%E9%80%BB%E8%BE%91%E3%80%82"><span class="toc-number">0.4.</span> <span class="toc-text">上面代码中，MapFunction实现类的泛型类型，与输入数据类型和输出数据的类型有关。在实现MapFunction接口的时候，需要指定两个泛型，分别是输入事件和输出事件的类型，还需要重写一个map()方法，定义从一个输入事件转换为另一个输出事件的具体逻辑。</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-1-2%E8%BF%87%E6%BB%A4%EF%BC%88filter%EF%BC%89"><span class="toc-number"></span> <span class="toc-text">1.1.2过滤（filter）</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#filter%E8%BD%AC%E6%8D%A2%E6%93%8D%E4%BD%9C%EF%BC%8C%E9%A1%BE%E5%90%8D%E6%80%9D%E4%B9%89%E6%98%AF%E5%AF%B9%E6%95%B0%E6%8D%AE%E6%B5%81%E6%89%A7%E8%A1%8C%E4%B8%80%E4%B8%AA%E8%BF%87%E6%BB%A4%EF%BC%8C%E9%80%9A%E8%BF%87%E4%B8%80%E4%B8%AA%E5%B8%83%E5%B0%94%E6%9D%A1%E4%BB%B6%E8%A1%A8%E8%BE%BE%E5%BC%8F%E8%AE%BE%E7%BD%AE%E8%BF%87%E6%BB%A4%E6%9D%A1%E4%BB%B6%EF%BC%8C%E5%AF%B9%E4%BA%8E%E6%AF%8F%E4%B8%80%E4%B8%AA%E6%B5%81%E5%86%85%E5%85%83%E7%B4%A0%E8%BF%9B%E8%A1%8C%E5%88%A4%E6%96%AD%EF%BC%8C%E8%8B%A5%E4%B8%BAtrue%E5%88%99%E5%85%83%E7%B4%A0%E6%AD%A3%E5%B8%B8%E8%BE%93%E5%87%BA%EF%BC%8C%E8%8B%A5%E4%B8%BAfalse%E5%88%99%E5%85%83%E7%B4%A0%E8%A2%AB%E8%BF%87%E6%BB%A4%E6%8E%89%E3%80%82"><span class="toc-number">1.</span> <span class="toc-text">filter转换操作，顾名思义是对数据流执行一个过滤，通过一个布尔条件表达式设置过滤条件，对于每一个流内元素进行判断，若为true则元素正常输出，若为false则元素被过滤掉。</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#%E8%BF%9B%E8%A1%8Cfilter%E8%BD%AC%E6%8D%A2%E4%B9%8B%E5%90%8E%E7%9A%84%E6%96%B0%E6%95%B0%E6%8D%AE%E6%B5%81%E7%9A%84%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%E4%B8%8E%E5%8E%9F%E6%95%B0%E6%8D%AE%E6%B5%81%E6%98%AF%E7%9B%B8%E5%90%8C%E7%9A%84%E3%80%82filter%E8%BD%AC%E6%8D%A2%E9%9C%80%E8%A6%81%E4%BC%A0%E5%85%A5%E7%9A%84%E5%8F%82%E6%95%B0%E9%9C%80%E8%A6%81%E5%AE%9E%E7%8E%B0FilterFunction%E6%8E%A5%E5%8F%A3%EF%BC%8C%E8%80%8CFilterFunction%E5%86%85%E8%A6%81%E5%AE%9E%E7%8E%B0filter-%E6%96%B9%E6%B3%95%EF%BC%8C%E5%B0%B1%E7%9B%B8%E5%BD%93%E4%BA%8E%E4%B8%80%E4%B8%AA%E8%BF%94%E5%9B%9E%E5%B8%83%E5%B0%94%E7%B1%BB%E5%9E%8B%E7%9A%84%E6%9D%A1%E4%BB%B6%E8%A1%A8%E8%BE%BE%E5%BC%8F%E3%80%82"><span class="toc-number">1.1.</span> <span class="toc-text">进行filter转换之后的新数据流的数据类型与原数据流是相同的。filter转换需要传入的参数需要实现FilterFunction接口，而FilterFunction内要实现filter()方法，就相当于一个返回布尔类型的条件表达式。</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#%E6%A1%88%E4%BE%8B%E9%9C%80%E6%B1%82%EF%BC%9A%E4%B8%8B%E9%9D%A2%E7%9A%84%E4%BB%A3%E7%A0%81%E4%BC%9A%E5%B0%86%E6%95%B0%E6%8D%AE%E6%B5%81%E4%B8%AD%E4%BC%A0%E6%84%9F%E5%99%A8id%E4%B8%BAsensor-1%E7%9A%84%E6%95%B0%E6%8D%AE%E8%BF%87%E6%BB%A4%E5%87%BA%E6%9D%A5%E3%80%82"><span class="toc-number">1.2.</span> <span class="toc-text">案例需求：下面的代码会将数据流中传感器id为sensor_1的数据过滤出来。</span></a></li></ol></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-1-3-%E6%89%81%E5%B9%B3%E6%98%A0%E5%B0%84%EF%BC%88flatMap%EF%BC%89"><span class="toc-number"></span> <span class="toc-text">1.1.3 扁平映射（flatMap）</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#flatMap%E6%93%8D%E4%BD%9C%E5%8F%88%E7%A7%B0%E4%B8%BA%E6%89%81%E5%B9%B3%E6%98%A0%E5%B0%84%EF%BC%8C%E4%B8%BB%E8%A6%81%E6%98%AF%E5%B0%86%E6%95%B0%E6%8D%AE%E6%B5%81%E4%B8%AD%E7%9A%84%E6%95%B4%E4%BD%93%EF%BC%88%E4%B8%80%E8%88%AC%E6%98%AF%E9%9B%86%E5%90%88%E7%B1%BB%E5%9E%8B%EF%BC%89%E6%8B%86%E5%88%86%E6%88%90%E4%B8%80%E4%B8%AA%E4%B8%80%E4%B8%AA%E7%9A%84%E4%B8%AA%E4%BD%93%E4%BD%BF%E7%94%A8%E3%80%82%E6%B6%88%E8%B4%B9%E4%B8%80%E4%B8%AA%E5%85%83%E7%B4%A0%EF%BC%8C%E5%8F%AF%E4%BB%A5%E4%BA%A7%E7%94%9F0%E5%88%B0%E5%A4%9A%E4%B8%AA%E5%85%83%E7%B4%A0%E3%80%82flatMap%E5%8F%AF%E4%BB%A5%E8%AE%A4%E4%B8%BA%E6%98%AF%E2%80%9C%E6%89%81%E5%B9%B3%E5%8C%96%E2%80%9D%EF%BC%88flatten%EF%BC%89%E5%92%8C%E2%80%9C%E6%98%A0%E5%B0%84%E2%80%9D%EF%BC%88map%EF%BC%89%E4%B8%A4%E6%AD%A5%E6%93%8D%E4%BD%9C%E7%9A%84%E7%BB%93%E5%90%88%EF%BC%8C%E4%B9%9F%E5%B0%B1%E6%98%AF%E5%85%88%E6%8C%89%E7%85%A7%E6%9F%90%E7%A7%8D%E8%A7%84%E5%88%99%E5%AF%B9%E6%95%B0%E6%8D%AE%E8%BF%9B%E8%A1%8C%E6%89%93%E6%95%A3%E6%8B%86%E5%88%86%EF%BC%8C%E5%86%8D%E5%AF%B9%E6%8B%86%E5%88%86%E5%90%8E%E7%9A%84%E5%85%83%E7%B4%A0%E5%81%9A%E8%BD%AC%E6%8D%A2%E5%A4%84%E7%90%86%E3%80%82"><span class="toc-number">0.1.</span> <span class="toc-text">flatMap操作又称为扁平映射，主要是将数据流中的整体（一般是集合类型）拆分成一个一个的个体使用。消费一个元素，可以产生0到多个元素。flatMap可以认为是“扁平化”（flatten）和“映射”（map）两步操作的结合，也就是先按照某种规则对数据进行打散拆分，再对拆分后的元素做转换处理。</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#%E5%90%8Cmap%E4%B8%80%E6%A0%B7%EF%BC%8CflatMap%E4%B9%9F%E5%8F%AF%E4%BB%A5%E4%BD%BF%E7%94%A8Lambda%E8%A1%A8%E8%BE%BE%E5%BC%8F%E6%88%96%E8%80%85FlatMapFunction%E6%8E%A5%E5%8F%A3%E5%AE%9E%E7%8E%B0%E7%B1%BB%E7%9A%84%E6%96%B9%E5%BC%8F%E6%9D%A5%E8%BF%9B%E8%A1%8C%E4%BC%A0%E5%8F%82%EF%BC%8C%E8%BF%94%E5%9B%9E%E5%80%BC%E7%B1%BB%E5%9E%8B%E5%8F%96%E5%86%B3%E4%BA%8E%E6%89%80%E4%BC%A0%E5%8F%82%E6%95%B0%E7%9A%84%E5%85%B7%E4%BD%93%E9%80%BB%E8%BE%91%EF%BC%8C%E5%8F%AF%E4%BB%A5%E4%B8%8E%E5%8E%9F%E6%95%B0%E6%8D%AE%E6%B5%81%E7%9B%B8%E5%90%8C%EF%BC%8C%E4%B9%9F%E5%8F%AF%E4%BB%A5%E4%B8%8D%E5%90%8C%E3%80%82"><span class="toc-number">0.2.</span> <span class="toc-text">同map一样，flatMap也可以使用Lambda表达式或者FlatMapFunction接口实现类的方式来进行传参，返回值类型取决于所传参数的具体逻辑，可以与原数据流相同，也可以不同。</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#%E6%A1%88%E4%BE%8B%E9%9C%80%E6%B1%82%EF%BC%9A%E5%A6%82%E6%9E%9C%E8%BE%93%E5%85%A5%E7%9A%84%E6%95%B0%E6%8D%AE%E6%98%AFsensor-1%EF%BC%8C%E5%8F%AA%E6%89%93%E5%8D%B0vc%EF%BC%9B%E5%A6%82%E6%9E%9C%E8%BE%93%E5%85%A5%E7%9A%84%E6%95%B0%E6%8D%AE%E6%98%AFsensor-2%EF%BC%8C%E6%97%A2%E6%89%93%E5%8D%B0ts%E5%8F%88%E6%89%93%E5%8D%B0vc%E3%80%82"><span class="toc-number">0.3.</span> <span class="toc-text">案例需求：如果输入的数据是sensor_1，只打印vc；如果输入的数据是sensor_2，既打印ts又打印vc。</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#%E5%AE%9E%E7%8E%B0%E4%BB%A3%E7%A0%81%E5%A6%82%E4%B8%8B%EF%BC%9A"><span class="toc-number">0.4.</span> <span class="toc-text">实现代码如下：</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-2%E8%81%9A%E5%90%88%E7%AE%97%E5%AD%90%EF%BC%88Aggregation%EF%BC%89"><span class="toc-number"></span> <span class="toc-text">1.2聚合算子（Aggregation）</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E8%AE%A1%E7%AE%97%E7%9A%84%E7%BB%93%E6%9E%9C%E4%B8%8D%E4%BB%85%E4%BE%9D%E8%B5%96%E5%BD%93%E5%89%8D%E6%95%B0%E6%8D%AE%EF%BC%8C%E8%BF%98%E8%B7%9F%E4%B9%8B%E5%89%8D%E7%9A%84%E6%95%B0%E6%8D%AE%E6%9C%89%E5%85%B3%EF%BC%8C%E7%9B%B8%E5%BD%93%E4%BA%8E%E8%A6%81%E6%8A%8A%E6%89%80%E6%9C%89%E6%95%B0%E6%8D%AE%E8%81%9A%E5%9C%A8%E4%B8%80%E8%B5%B7%E8%BF%9B%E8%A1%8C%E6%B1%87%E6%80%BB%E5%90%88%E5%B9%B6%E2%80%94%E2%80%94%E8%BF%99%E5%B0%B1%E6%98%AF%E6%89%80%E8%B0%93%E7%9A%84%E2%80%9C%E8%81%9A%E5%90%88%E2%80%9D%EF%BC%88Aggregation%EF%BC%89%EF%BC%8C%E7%B1%BB%E4%BC%BC%E4%BA%8EMapReduce%E4%B8%AD%E7%9A%84reduce%E6%93%8D%E4%BD%9C%E3%80%82"><span class="toc-number">1.</span> <span class="toc-text">计算的结果不仅依赖当前数据，还跟之前的数据有关，相当于要把所有数据聚在一起进行汇总合并——这就是所谓的“聚合”（Aggregation），类似于MapReduce中的reduce操作。</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-2-1-%E6%8C%89%E9%94%AE%E5%88%86%E5%8C%BA%EF%BC%88keyBy%EF%BC%89"><span class="toc-number"></span> <span class="toc-text">1.2.1 按键分区（keyBy）</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#%E5%AF%B9%E4%BA%8EFlink%E8%80%8C%E8%A8%80%EF%BC%8CDataStream%E6%98%AF%E6%B2%A1%E6%9C%89%E7%9B%B4%E6%8E%A5%E8%BF%9B%E8%A1%8C%E8%81%9A%E5%90%88%E7%9A%84API%E7%9A%84%E3%80%82%E5%9B%A0%E4%B8%BA%E6%88%91%E4%BB%AC%E5%AF%B9%E6%B5%B7%E9%87%8F%E6%95%B0%E6%8D%AE%E5%81%9A%E8%81%9A%E5%90%88%E8%82%AF%E5%AE%9A%E8%A6%81%E8%BF%9B%E8%A1%8C%E5%88%86%E5%8C%BA%E5%B9%B6%E8%A1%8C%E5%A4%84%E7%90%86%EF%BC%8C%E8%BF%99%E6%A0%B7%E6%89%8D%E8%83%BD%E6%8F%90%E9%AB%98%E6%95%88%E7%8E%87%E3%80%82%E6%89%80%E4%BB%A5%E5%9C%A8Flink%E4%B8%AD%EF%BC%8C%E8%A6%81%E5%81%9A%E8%81%9A%E5%90%88%EF%BC%8C%E9%9C%80%E8%A6%81%E5%85%88%E8%BF%9B%E8%A1%8C%E5%88%86%E5%8C%BA%EF%BC%9B%E8%BF%99%E4%B8%AA%E6%93%8D%E4%BD%9C%E5%B0%B1%E6%98%AF%E9%80%9A%E8%BF%87keyBy%E6%9D%A5%E5%AE%8C%E6%88%90%E7%9A%84%E3%80%82"><span class="toc-number">0.1.</span> <span class="toc-text">对于Flink而言，DataStream是没有直接进行聚合的API的。因为我们对海量数据做聚合肯定要进行分区并行处理，这样才能提高效率。所以在Flink中，要做聚合，需要先进行分区；这个操作就是通过keyBy来完成的。</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#keyBy%E6%98%AF%E8%81%9A%E5%90%88%E5%89%8D%E5%BF%85%E9%A1%BB%E8%A6%81%E7%94%A8%E5%88%B0%E7%9A%84%E4%B8%80%E4%B8%AA%E7%AE%97%E5%AD%90%E3%80%82keyBy%E9%80%9A%E8%BF%87%E6%8C%87%E5%AE%9A%E9%94%AE%EF%BC%88key%EF%BC%89%EF%BC%8C%E5%8F%AF%E4%BB%A5%E5%B0%86%E4%B8%80%E6%9D%A1%E6%B5%81%E4%BB%8E%E9%80%BB%E8%BE%91%E4%B8%8A%E5%88%92%E5%88%86%E6%88%90%E4%B8%8D%E5%90%8C%E7%9A%84%E5%88%86%E5%8C%BA%EF%BC%88partitions%EF%BC%89%E3%80%82%E8%BF%99%E9%87%8C%E6%89%80%E8%AF%B4%E7%9A%84%E5%88%86%E5%8C%BA%EF%BC%8C%E5%85%B6%E5%AE%9E%E5%B0%B1%E6%98%AF%E5%B9%B6%E8%A1%8C%E5%A4%84%E7%90%86%E7%9A%84%E5%AD%90%E4%BB%BB%E5%8A%A1%E3%80%82"><span class="toc-number">0.2.</span> <span class="toc-text">keyBy是聚合前必须要用到的一个算子。keyBy通过指定键（key），可以将一条流从逻辑上划分成不同的分区（partitions）。这里所说的分区，其实就是并行处理的子任务。</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E%E4%B8%8D%E5%90%8C%E7%9A%84key%EF%BC%8C%E6%B5%81%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE%E5%B0%86%E8%A2%AB%E5%88%86%E9%85%8D%E5%88%B0%E4%B8%8D%E5%90%8C%E7%9A%84%E5%88%86%E5%8C%BA%E4%B8%AD%E5%8E%BB%EF%BC%9B%E8%BF%99%E6%A0%B7%E4%B8%80%E6%9D%A5%EF%BC%8C%E6%89%80%E6%9C%89%E5%85%B7%E6%9C%89%E7%9B%B8%E5%90%8C%E7%9A%84key%E7%9A%84%E6%95%B0%E6%8D%AE%EF%BC%8C%E9%83%BD%E5%B0%86%E8%A2%AB%E5%8F%91%E5%BE%80%E5%90%8C%E4%B8%80%E4%B8%AA%E5%88%86%E5%8C%BA%E3%80%82"><span class="toc-number">0.3.</span> <span class="toc-text">基于不同的key，流中的数据将被分配到不同的分区中去；这样一来，所有具有相同的key的数据，都将被发往同一个分区。</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#%E5%9C%A8%E5%86%85%E9%83%A8%EF%BC%8C%E6%98%AF%E9%80%9A%E8%BF%87%E8%AE%A1%E7%AE%97key%E7%9A%84%E5%93%88%E5%B8%8C%E5%80%BC%EF%BC%88hash-code%EF%BC%89%EF%BC%8C%E5%AF%B9%E5%88%86%E5%8C%BA%E6%95%B0%E8%BF%9B%E8%A1%8C%E5%8F%96%E6%A8%A1%E8%BF%90%E7%AE%97%E6%9D%A5%E5%AE%9E%E7%8E%B0%E7%9A%84%E3%80%82%E6%89%80%E4%BB%A5%E8%BF%99%E9%87%8Ckey%E5%A6%82%E6%9E%9C%E6%98%AFPOJO%E7%9A%84%E8%AF%9D%EF%BC%8C%E5%BF%85%E9%A1%BB%E8%A6%81%E9%87%8D%E5%86%99hashCode-%E6%96%B9%E6%B3%95%E3%80%82"><span class="toc-number">0.4.</span> <span class="toc-text">在内部，是通过计算key的哈希值（hash code），对分区数进行取模运算来实现的。所以这里key如果是POJO的话，必须要重写hashCode()方法。</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#keyBy-%E6%96%B9%E6%B3%95%E9%9C%80%E8%A6%81%E4%BC%A0%E5%85%A5%E4%B8%80%E4%B8%AA%E5%8F%82%E6%95%B0%EF%BC%8C%E8%BF%99%E4%B8%AA%E5%8F%82%E6%95%B0%E6%8C%87%E5%AE%9A%E4%BA%86%E4%B8%80%E4%B8%AA%E6%88%96%E4%B8%80%E7%BB%84key%E3%80%82%E6%9C%89%E5%BE%88%E5%A4%9A%E4%B8%8D%E5%90%8C%E7%9A%84%E6%96%B9%E6%B3%95%E6%9D%A5%E6%8C%87%E5%AE%9Akey%EF%BC%9A%E6%AF%94%E5%A6%82%E5%AF%B9%E4%BA%8ETuple%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%EF%BC%8C%E5%8F%AF%E4%BB%A5%E6%8C%87%E5%AE%9A%E5%AD%97%E6%AE%B5%E7%9A%84%E4%BD%8D%E7%BD%AE%E6%88%96%E8%80%85%E5%A4%9A%E4%B8%AA%E4%BD%8D%E7%BD%AE%E7%9A%84%E7%BB%84%E5%90%88%EF%BC%9B%E5%AF%B9%E4%BA%8EPOJO%E7%B1%BB%E5%9E%8B%EF%BC%8C%E5%8F%AF%E4%BB%A5%E6%8C%87%E5%AE%9A%E5%AD%97%E6%AE%B5%E7%9A%84%E5%90%8D%E7%A7%B0%EF%BC%88String%EF%BC%89%EF%BC%9B%E5%8F%A6%E5%A4%96%EF%BC%8C%E8%BF%98%E5%8F%AF%E4%BB%A5%E4%BC%A0%E5%85%A5Lambda%E8%A1%A8%E8%BE%BE%E5%BC%8F%E6%88%96%E8%80%85%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E9%94%AE%E9%80%89%E6%8B%A9%E5%99%A8%EF%BC%88KeySelector%EF%BC%89%EF%BC%8C%E7%94%A8%E4%BA%8E%E8%AF%B4%E6%98%8E%E4%BB%8E%E6%95%B0%E6%8D%AE%E4%B8%AD%E6%8F%90%E5%8F%96key%E7%9A%84%E9%80%BB%E8%BE%91%E3%80%82"><span class="toc-number">0.5.</span> <span class="toc-text">keyBy()方法需要传入一个参数，这个参数指定了一个或一组key。有很多不同的方法来指定key：比如对于Tuple数据类型，可以指定字段的位置或者多个位置的组合；对于POJO类型，可以指定字段的名称（String）；另外，还可以传入Lambda表达式或者实现一个键选择器（KeySelector），用于说明从数据中提取key的逻辑。</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#%E6%88%91%E4%BB%AC%E5%8F%AF%E4%BB%A5%E4%BB%A5id%E4%BD%9C%E4%B8%BAkey%E5%81%9A%E4%B8%80%E4%B8%AA%E5%88%86%E5%8C%BA%E6%93%8D%E4%BD%9C%EF%BC%8C%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0%E5%A6%82%E4%B8%8B%EF%BC%9A"><span class="toc-number">0.6.</span> <span class="toc-text">我们可以以id作为key做一个分区操作，代码实现如下：</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#%E9%9C%80%E8%A6%81%E6%B3%A8%E6%84%8F%E7%9A%84%E6%98%AF%EF%BC%8CkeyBy%E5%BE%97%E5%88%B0%E7%9A%84%E7%BB%93%E6%9E%9C%E5%B0%86%E4%B8%8D%E5%86%8D%E6%98%AFDataStream%EF%BC%8C%E8%80%8C%E6%98%AF%E4%BC%9A%E5%B0%86DataStream%E8%BD%AC%E6%8D%A2%E4%B8%BAKeyedStream%E3%80%82KeyedStream%E5%8F%AF%E4%BB%A5%E8%AE%A4%E4%B8%BA%E6%98%AF%E2%80%9C%E5%88%86%E5%8C%BA%E6%B5%81%E2%80%9D%E6%88%96%E8%80%85%E2%80%9C%E9%94%AE%E6%8E%A7%E6%B5%81%E2%80%9D%EF%BC%8C%E5%AE%83%E6%98%AF%E5%AF%B9DataStream%E6%8C%89%E7%85%A7key%E7%9A%84%E4%B8%80%E4%B8%AA%E9%80%BB%E8%BE%91%E5%88%86%E5%8C%BA%EF%BC%8C%E6%89%80%E4%BB%A5%E6%B3%9B%E5%9E%8B%E6%9C%89%E4%B8%A4%E4%B8%AA%E7%B1%BB%E5%9E%8B%EF%BC%9A%E9%99%A4%E5%8E%BB%E5%BD%93%E5%89%8D%E6%B5%81%E4%B8%AD%E7%9A%84%E5%85%83%E7%B4%A0%E7%B1%BB%E5%9E%8B%E5%A4%96%EF%BC%8C%E8%BF%98%E9%9C%80%E8%A6%81%E6%8C%87%E5%AE%9Akey%E7%9A%84%E7%B1%BB%E5%9E%8B%E3%80%82"><span class="toc-number">0.7.</span> <span class="toc-text">需要注意的是，keyBy得到的结果将不再是DataStream，而是会将DataStream转换为KeyedStream。KeyedStream可以认为是“分区流”或者“键控流”，它是对DataStream按照key的一个逻辑分区，所以泛型有两个类型：除去当前流中的元素类型外，还需要指定key的类型。</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#KeyedStream%E4%B9%9F%E7%BB%A7%E6%89%BF%E8%87%AADataStream%EF%BC%8C%E6%89%80%E4%BB%A5%E5%9F%BA%E4%BA%8E%E5%AE%83%E7%9A%84%E6%93%8D%E4%BD%9C%E4%B9%9F%E9%83%BD%E5%BD%92%E5%B1%9E%E4%BA%8EDataStream-API%E3%80%82%E4%BD%86%E5%AE%83%E8%B7%9F%E4%B9%8B%E5%89%8D%E7%9A%84%E8%BD%AC%E6%8D%A2%E6%93%8D%E4%BD%9C%E5%BE%97%E5%88%B0%E7%9A%84SingleOutputStreamOperator%E4%B8%8D%E5%90%8C%EF%BC%8C%E5%8F%AA%E6%98%AF%E4%B8%80%E4%B8%AA%E6%B5%81%E7%9A%84%E5%88%86%E5%8C%BA%E6%93%8D%E4%BD%9C%EF%BC%8C%E5%B9%B6%E4%B8%8D%E6%98%AF%E4%B8%80%E4%B8%AA%E8%BD%AC%E6%8D%A2%E7%AE%97%E5%AD%90%E3%80%82KeyedStream%E6%98%AF%E4%B8%80%E4%B8%AA%E9%9D%9E%E5%B8%B8%E9%87%8D%E8%A6%81%E7%9A%84%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%EF%BC%8C%E5%8F%AA%E6%9C%89%E5%9F%BA%E4%BA%8E%E5%AE%83%E6%89%8D%E5%8F%AF%E4%BB%A5%E5%81%9A%E5%90%8E%E7%BB%AD%E7%9A%84%E8%81%9A%E5%90%88%E6%93%8D%E4%BD%9C%EF%BC%88%E6%AF%94%E5%A6%82sum%EF%BC%8Creduce%EF%BC%89%E3%80%82"><span class="toc-number">0.8.</span> <span class="toc-text">KeyedStream也继承自DataStream，所以基于它的操作也都归属于DataStream API。但它跟之前的转换操作得到的SingleOutputStreamOperator不同，只是一个流的分区操作，并不是一个转换算子。KeyedStream是一个非常重要的数据结构，只有基于它才可以做后续的聚合操作（比如sum，reduce）。</span></a></li></ol></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-2-2-%E7%AE%80%E5%8D%95%E8%81%9A%E5%90%88%EF%BC%88sum-x2F-min-x2F-max-x2F-minBy-x2F-maxBy%EF%BC%89"><span class="toc-number"></span> <span class="toc-text">1.2.2 简单聚合（sum&#x2F;min&#x2F;max&#x2F;minBy&#x2F;maxBy）</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#%E6%9C%89%E4%BA%86%E6%8C%89%E9%94%AE%E5%88%86%E5%8C%BA%E7%9A%84%E6%95%B0%E6%8D%AE%E6%B5%81KeyedStream%EF%BC%8C%E6%88%91%E4%BB%AC%E5%B0%B1%E5%8F%AF%E4%BB%A5%E5%9F%BA%E4%BA%8E%E5%AE%83%E8%BF%9B%E8%A1%8C%E8%81%9A%E5%90%88%E6%93%8D%E4%BD%9C%E4%BA%86%E3%80%82Flink%E4%B8%BA%E6%88%91%E4%BB%AC%E5%86%85%E7%BD%AE%E5%AE%9E%E7%8E%B0%E4%BA%86%E4%B8%80%E4%BA%9B%E6%9C%80%E5%9F%BA%E6%9C%AC%E3%80%81%E6%9C%80%E7%AE%80%E5%8D%95%E7%9A%84%E8%81%9A%E5%90%88API%EF%BC%8C%E4%B8%BB%E8%A6%81%E6%9C%89%E4%BB%A5%E4%B8%8B%E5%87%A0%E7%A7%8D%EF%BC%9A"><span class="toc-number">0.1.</span> <span class="toc-text">有了按键分区的数据流KeyedStream，我们就可以基于它进行聚合操作了。Flink为我们内置实现了一些最基本、最简单的聚合API，主要有以下几种：</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#sum-%EF%BC%9A%E5%9C%A8%E8%BE%93%E5%85%A5%E6%B5%81%E4%B8%8A%EF%BC%8C%E5%AF%B9%E6%8C%87%E5%AE%9A%E7%9A%84%E5%AD%97%E6%AE%B5%E5%81%9A%E5%8F%A0%E5%8A%A0%E6%B1%82%E5%92%8C%E7%9A%84%E6%93%8D%E4%BD%9C%E3%80%82"><span class="toc-number">0.2.</span> <span class="toc-text">sum()：在输入流上，对指定的字段做叠加求和的操作。</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#min-%EF%BC%9A%E5%9C%A8%E8%BE%93%E5%85%A5%E6%B5%81%E4%B8%8A%EF%BC%8C%E5%AF%B9%E6%8C%87%E5%AE%9A%E7%9A%84%E5%AD%97%E6%AE%B5%E6%B1%82%E6%9C%80%E5%B0%8F%E5%80%BC%E3%80%82"><span class="toc-number">0.3.</span> <span class="toc-text">min()：在输入流上，对指定的字段求最小值。</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#max-%EF%BC%9A%E5%9C%A8%E8%BE%93%E5%85%A5%E6%B5%81%E4%B8%8A%EF%BC%8C%E5%AF%B9%E6%8C%87%E5%AE%9A%E7%9A%84%E5%AD%97%E6%AE%B5%E6%B1%82%E6%9C%80%E5%A4%A7%E5%80%BC%E3%80%82"><span class="toc-number">0.4.</span> <span class="toc-text">max()：在输入流上，对指定的字段求最大值。</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#minBy-%EF%BC%9A%E4%B8%8Emin-%E7%B1%BB%E4%BC%BC%EF%BC%8C%E5%9C%A8%E8%BE%93%E5%85%A5%E6%B5%81%E4%B8%8A%E9%92%88%E5%AF%B9%E6%8C%87%E5%AE%9A%E5%AD%97%E6%AE%B5%E6%B1%82%E6%9C%80%E5%B0%8F%E5%80%BC%E3%80%82%E4%B8%8D%E5%90%8C%E7%9A%84%E6%98%AF%EF%BC%8Cmin-%E5%8F%AA%E8%AE%A1%E7%AE%97%E6%8C%87%E5%AE%9A%E5%AD%97%E6%AE%B5%E7%9A%84%E6%9C%80%E5%B0%8F%E5%80%BC%EF%BC%8C%E5%85%B6%E4%BB%96%E5%AD%97%E6%AE%B5%E4%BC%9A%E4%BF%9D%E7%95%99%E6%9C%80%E5%88%9D%E7%AC%AC%E4%B8%80%E4%B8%AA%E6%95%B0%E6%8D%AE%E7%9A%84%E5%80%BC%EF%BC%9B%E8%80%8CminBy-%E5%88%99%E4%BC%9A%E8%BF%94%E5%9B%9E%E5%8C%85%E5%90%AB%E5%AD%97%E6%AE%B5%E6%9C%80%E5%B0%8F%E5%80%BC%E7%9A%84%E6%95%B4%E6%9D%A1%E6%95%B0%E6%8D%AE%E3%80%82"><span class="toc-number">0.5.</span> <span class="toc-text">minBy()：与min()类似，在输入流上针对指定字段求最小值。不同的是，min()只计算指定字段的最小值，其他字段会保留最初第一个数据的值；而minBy()则会返回包含字段最小值的整条数据。</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#maxBy-%EF%BC%9A%E4%B8%8Emax-%E7%B1%BB%E4%BC%BC%EF%BC%8C%E5%9C%A8%E8%BE%93%E5%85%A5%E6%B5%81%E4%B8%8A%E9%92%88%E5%AF%B9%E6%8C%87%E5%AE%9A%E5%AD%97%E6%AE%B5%E6%B1%82%E6%9C%80%E5%A4%A7%E5%80%BC%E3%80%82%E4%B8%A4%E8%80%85%E5%8C%BA%E5%88%AB%E4%B8%8Emin-x2F-minBy-%E5%AE%8C%E5%85%A8%E4%B8%80%E8%87%B4%E3%80%82"><span class="toc-number">0.6.</span> <span class="toc-text">maxBy()：与max()类似，在输入流上针对指定字段求最大值。两者区别与min()&#x2F;minBy()完全一致。</span></a></li></ol></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E7%AE%80%E5%8D%95%E8%81%9A%E5%90%88%E7%AE%97%E5%AD%90%E4%BD%BF%E7%94%A8%E9%9D%9E%E5%B8%B8%E6%96%B9%E4%BE%BF%EF%BC%8C%E8%AF%AD%E4%B9%89%E4%B9%9F%E9%9D%9E%E5%B8%B8%E6%98%8E%E7%A1%AE%E3%80%82%E8%BF%99%E4%BA%9B%E8%81%9A%E5%90%88%E6%96%B9%E6%B3%95%E8%B0%83%E7%94%A8%E6%97%B6%EF%BC%8C%E4%B9%9F%E9%9C%80%E8%A6%81%E4%BC%A0%E5%85%A5%E5%8F%82%E6%95%B0%EF%BC%9B%E4%BD%86%E5%B9%B6%E4%B8%8D%E5%83%8F%E5%9F%BA%E6%9C%AC%E8%BD%AC%E6%8D%A2%E7%AE%97%E5%AD%90%E9%82%A3%E6%A0%B7%E9%9C%80%E8%A6%81%E5%AE%9E%E7%8E%B0%E8%87%AA%E5%AE%9A%E4%B9%89%E5%87%BD%E6%95%B0%EF%BC%8C%E5%8F%AA%E8%A6%81%E8%AF%B4%E6%98%8E%E8%81%9A%E5%90%88%E6%8C%87%E5%AE%9A%E7%9A%84%E5%AD%97%E6%AE%B5%E5%B0%B1%E5%8F%AF%E4%BB%A5%E4%BA%86%E3%80%82%E6%8C%87%E5%AE%9A%E5%AD%97%E6%AE%B5%E7%9A%84%E6%96%B9%E5%BC%8F%E6%9C%89%E4%B8%A4%E7%A7%8D%EF%BC%9A%E6%8C%87%E5%AE%9A%E4%BD%8D%E7%BD%AE%EF%BC%8C%E5%92%8C%E6%8C%87%E5%AE%9A%E5%90%8D%E7%A7%B0%E3%80%82"><span class="toc-number">1.</span> <span class="toc-text">简单聚合算子使用非常方便，语义也非常明确。这些聚合方法调用时，也需要传入参数；但并不像基本转换算子那样需要实现自定义函数，只要说明聚合指定的字段就可以了。指定字段的方式有两种：指定位置，和指定名称。</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#%E5%AF%B9%E4%BA%8E%E5%85%83%E7%BB%84%E7%B1%BB%E5%9E%8B%E7%9A%84%E6%95%B0%E6%8D%AE%EF%BC%8C%E5%8F%AF%E4%BB%A5%E4%BD%BF%E7%94%A8%E8%BF%99%E4%B8%A4%E7%A7%8D%E6%96%B9%E5%BC%8F%E6%9D%A5%E6%8C%87%E5%AE%9A%E5%AD%97%E6%AE%B5%E3%80%82%E9%9C%80%E8%A6%81%E6%B3%A8%E6%84%8F%E7%9A%84%E6%98%AF%EF%BC%8C%E5%85%83%E7%BB%84%E4%B8%AD%E5%AD%97%E6%AE%B5%E7%9A%84%E5%90%8D%E7%A7%B0%EF%BC%8C%E6%98%AF%E4%BB%A5f0%E3%80%81f1%E3%80%81f2%E3%80%81%E2%80%A6%E6%9D%A5%E5%91%BD%E5%90%8D%E7%9A%84%E3%80%82"><span class="toc-number">1.1.</span> <span class="toc-text">对于元组类型的数据，可以使用这两种方式来指定字段。需要注意的是，元组中字段的名称，是以f0、f1、f2、…来命名的。</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#%E5%A6%82%E6%9E%9C%E6%95%B0%E6%8D%AE%E6%B5%81%E7%9A%84%E7%B1%BB%E5%9E%8B%E6%98%AFPOJO%E7%B1%BB%EF%BC%8C%E9%82%A3%E4%B9%88%E5%B0%B1%E5%8F%AA%E8%83%BD%E9%80%9A%E8%BF%87%E5%AD%97%E6%AE%B5%E5%90%8D%E7%A7%B0%E6%9D%A5%E6%8C%87%E5%AE%9A%EF%BC%8C%E4%B8%8D%E8%83%BD%E9%80%9A%E8%BF%87%E4%BD%8D%E7%BD%AE%E6%9D%A5%E6%8C%87%E5%AE%9A%E4%BA%86%E3%80%82"><span class="toc-number">1.2.</span> <span class="toc-text">如果数据流的类型是POJO类，那么就只能通过字段名称来指定，不能通过位置来指定了。</span></a></li></ol></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E7%AE%80%E5%8D%95%E8%81%9A%E5%90%88%E7%AE%97%E5%AD%90%E8%BF%94%E5%9B%9E%E7%9A%84%EF%BC%8C%E5%90%8C%E6%A0%B7%E6%98%AF%E4%B8%80%E4%B8%AASingleOutputStreamOperator%EF%BC%8C%E4%B9%9F%E5%B0%B1%E6%98%AF%E4%BB%8EKeyedStream%E5%8F%88%E8%BD%AC%E6%8D%A2%E6%88%90%E4%BA%86%E5%B8%B8%E8%A7%84%E7%9A%84DataStream%E3%80%82%E6%89%80%E4%BB%A5%E5%8F%AF%E4%BB%A5%E8%BF%99%E6%A0%B7%E7%90%86%E8%A7%A3%EF%BC%9AkeyBy%E5%92%8C%E8%81%9A%E5%90%88%E6%98%AF%E6%88%90%E5%AF%B9%E5%87%BA%E7%8E%B0%E7%9A%84%EF%BC%8C%E5%85%88%E5%88%86%E5%8C%BA%E3%80%81%E5%90%8E%E8%81%9A%E5%90%88%EF%BC%8C%E5%BE%97%E5%88%B0%E7%9A%84%E4%BE%9D%E7%84%B6%E6%98%AF%E4%B8%80%E4%B8%AADataStream%E3%80%82%E8%80%8C%E4%B8%94%E7%BB%8F%E8%BF%87%E7%AE%80%E5%8D%95%E8%81%9A%E5%90%88%E4%B9%8B%E5%90%8E%E7%9A%84%E6%95%B0%E6%8D%AE%E6%B5%81%EF%BC%8C%E5%85%83%E7%B4%A0%E7%9A%84%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%E4%BF%9D%E6%8C%81%E4%B8%8D%E5%8F%98%E3%80%82"><span class="toc-number">2.</span> <span class="toc-text">简单聚合算子返回的，同样是一个SingleOutputStreamOperator，也就是从KeyedStream又转换成了常规的DataStream。所以可以这样理解：keyBy和聚合是成对出现的，先分区、后聚合，得到的依然是一个DataStream。而且经过简单聚合之后的数据流，元素的数据类型保持不变。</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E4%B8%80%E4%B8%AA%E8%81%9A%E5%90%88%E7%AE%97%E5%AD%90%EF%BC%8C%E4%BC%9A%E4%B8%BA%E6%AF%8F%E4%B8%80%E4%B8%AAkey%E4%BF%9D%E5%AD%98%E4%B8%80%E4%B8%AA%E8%81%9A%E5%90%88%E7%9A%84%E5%80%BC%EF%BC%8C%E5%9C%A8Flink%E4%B8%AD%E6%88%91%E4%BB%AC%E6%8A%8A%E5%AE%83%E5%8F%AB%E4%BD%9C%E2%80%9C%E7%8A%B6%E6%80%81%E2%80%9D%EF%BC%88state%EF%BC%89%E3%80%82%E6%89%80%E4%BB%A5%E6%AF%8F%E5%BD%93%E6%9C%89%E4%B8%80%E4%B8%AA%E6%96%B0%E7%9A%84%E6%95%B0%E6%8D%AE%E8%BE%93%E5%85%A5%EF%BC%8C%E7%AE%97%E5%AD%90%E5%B0%B1%E4%BC%9A%E6%9B%B4%E6%96%B0%E4%BF%9D%E5%AD%98%E7%9A%84%E8%81%9A%E5%90%88%E7%BB%93%E6%9E%9C%EF%BC%8C%E5%B9%B6%E5%8F%91%E9%80%81%E4%B8%80%E4%B8%AA%E5%B8%A6%E6%9C%89%E6%9B%B4%E6%96%B0%E5%90%8E%E8%81%9A%E5%90%88%E5%80%BC%E7%9A%84%E4%BA%8B%E4%BB%B6%E5%88%B0%E4%B8%8B%E6%B8%B8%E7%AE%97%E5%AD%90%E3%80%82%E5%AF%B9%E4%BA%8E%E6%97%A0%E7%95%8C%E6%B5%81%E6%9D%A5%E8%AF%B4%EF%BC%8C%E8%BF%99%E4%BA%9B%E7%8A%B6%E6%80%81%E6%98%AF%E6%B0%B8%E8%BF%9C%E4%B8%8D%E4%BC%9A%E8%A2%AB%E6%B8%85%E9%99%A4%E7%9A%84%EF%BC%8C%E6%89%80%E4%BB%A5%E6%88%91%E4%BB%AC%E4%BD%BF%E7%94%A8%E8%81%9A%E5%90%88%E7%AE%97%E5%AD%90%EF%BC%8C%E5%BA%94%E8%AF%A5%E5%8F%AA%E7%94%A8%E5%9C%A8%E5%90%AB%E6%9C%89%E6%9C%89%E9%99%90%E4%B8%AAkey%E7%9A%84%E6%95%B0%E6%8D%AE%E6%B5%81%E4%B8%8A%E3%80%82"><span class="toc-number">3.</span> <span class="toc-text">一个聚合算子，会为每一个key保存一个聚合的值，在Flink中我们把它叫作“状态”（state）。所以每当有一个新的数据输入，算子就会更新保存的聚合结果，并发送一个带有更新后聚合值的事件到下游算子。对于无界流来说，这些状态是永远不会被清除的，所以我们使用聚合算子，应该只用在含有有限个key的数据流上。</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-2-3-%E5%BD%92%E7%BA%A6%E8%81%9A%E5%90%88%EF%BC%88reduce%EF%BC%89"><span class="toc-number"></span> <span class="toc-text">1.2.3 归约聚合（reduce）</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#reduce%E5%8F%AF%E4%BB%A5%E5%AF%B9%E5%B7%B2%E6%9C%89%E7%9A%84%E6%95%B0%E6%8D%AE%E8%BF%9B%E8%A1%8C%E5%BD%92%E7%BA%A6%E5%A4%84%E7%90%86%EF%BC%8C%E6%8A%8A%E6%AF%8F%E4%B8%80%E4%B8%AA%E6%96%B0%E8%BE%93%E5%85%A5%E7%9A%84%E6%95%B0%E6%8D%AE%E5%92%8C%E5%BD%93%E5%89%8D%E5%B7%B2%E7%BB%8F%E5%BD%92%E7%BA%A6%E5%87%BA%E6%9D%A5%E7%9A%84%E5%80%BC%EF%BC%8C%E5%86%8D%E5%81%9A%E4%B8%80%E4%B8%AA%E8%81%9A%E5%90%88%E8%AE%A1%E7%AE%97%E3%80%82"><span class="toc-number">1.</span> <span class="toc-text">reduce可以对已有的数据进行归约处理，把每一个新输入的数据和当前已经归约出来的值，再做一个聚合计算。</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#reduce%E6%93%8D%E4%BD%9C%E4%B9%9F%E4%BC%9A%E5%B0%86KeyedStream%E8%BD%AC%E6%8D%A2%E4%B8%BADataStream%E3%80%82%E5%AE%83%E4%B8%8D%E4%BC%9A%E6%94%B9%E5%8F%98%E6%B5%81%E7%9A%84%E5%85%83%E7%B4%A0%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%EF%BC%8C%E6%89%80%E4%BB%A5%E8%BE%93%E5%87%BA%E7%B1%BB%E5%9E%8B%E5%92%8C%E8%BE%93%E5%85%A5%E7%B1%BB%E5%9E%8B%E6%98%AF%E4%B8%80%E6%A0%B7%E7%9A%84%E3%80%82"><span class="toc-number">2.</span> <span class="toc-text">reduce操作也会将KeyedStream转换为DataStream。它不会改变流的元素数据类型，所以输出类型和输入类型是一样的。</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E8%B0%83%E7%94%A8KeyedStream%E7%9A%84reduce%E6%96%B9%E6%B3%95%E6%97%B6%EF%BC%8C%E9%9C%80%E8%A6%81%E4%BC%A0%E5%85%A5%E4%B8%80%E4%B8%AA%E5%8F%82%E6%95%B0%EF%BC%8C%E5%AE%9E%E7%8E%B0ReduceFunction%E6%8E%A5%E5%8F%A3%E3%80%82%E6%8E%A5%E5%8F%A3%E5%9C%A8%E6%BA%90%E7%A0%81%E4%B8%AD%E7%9A%84%E5%AE%9A%E4%B9%89%E5%A6%82%E4%B8%8B%EF%BC%9A"><span class="toc-number">3.</span> <span class="toc-text">调用KeyedStream的reduce方法时，需要传入一个参数，实现ReduceFunction接口。接口在源码中的定义如下：</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#ReduceFunction%E6%8E%A5%E5%8F%A3%E9%87%8C%E9%9C%80%E8%A6%81%E5%AE%9E%E7%8E%B0reduce-%E6%96%B9%E6%B3%95%EF%BC%8C%E8%BF%99%E4%B8%AA%E6%96%B9%E6%B3%95%E6%8E%A5%E6%94%B6%E4%B8%A4%E4%B8%AA%E8%BE%93%E5%85%A5%E4%BA%8B%E4%BB%B6%EF%BC%8C%E7%BB%8F%E8%BF%87%E8%BD%AC%E6%8D%A2%E5%A4%84%E7%90%86%E4%B9%8B%E5%90%8E%E8%BE%93%E5%87%BA%E4%B8%80%E4%B8%AA%E7%9B%B8%E5%90%8C%E7%B1%BB%E5%9E%8B%E7%9A%84%E4%BA%8B%E4%BB%B6%E3%80%82%E5%9C%A8%E6%B5%81%E5%A4%84%E7%90%86%E7%9A%84%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E8%BF%87%E7%A8%8B%E4%B8%AD%EF%BC%8C%E5%AE%9E%E9%99%85%E4%B8%8A%E6%98%AF%E5%B0%86%E4%B8%AD%E9%97%B4%E2%80%9C%E5%90%88%E5%B9%B6%E7%9A%84%E7%BB%93%E6%9E%9C%E2%80%9D%E4%BD%9C%E4%B8%BA%E4%BB%BB%E5%8A%A1%E7%9A%84%E4%B8%80%E4%B8%AA%E7%8A%B6%E6%80%81%E4%BF%9D%E5%AD%98%E8%B5%B7%E6%9D%A5%E7%9A%84%EF%BC%9B%E4%B9%8B%E5%90%8E%E6%AF%8F%E6%9D%A5%E4%B8%80%E4%B8%AA%E6%96%B0%E7%9A%84%E6%95%B0%E6%8D%AE%EF%BC%8C%E5%B0%B1%E5%92%8C%E4%B9%8B%E5%89%8D%E7%9A%84%E8%81%9A%E5%90%88%E7%8A%B6%E6%80%81%E8%BF%9B%E4%B8%80%E6%AD%A5%E5%81%9A%E5%BD%92%E7%BA%A6%E3%80%82"><span class="toc-number">4.</span> <span class="toc-text">ReduceFunction接口里需要实现reduce()方法，这个方法接收两个输入事件，经过转换处理之后输出一个相同类型的事件。在流处理的底层实现过程中，实际上是将中间“合并的结果”作为任务的一个状态保存起来的；之后每来一个新的数据，就和之前的聚合状态进一步做归约。</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%88%91%E4%BB%AC%E5%8F%AF%E4%BB%A5%E5%8D%95%E7%8B%AC%E5%AE%9A%E4%B9%89%E4%B8%80%E4%B8%AA%E5%87%BD%E6%95%B0%E7%B1%BB%E5%AE%9E%E7%8E%B0ReduceFunction%E6%8E%A5%E5%8F%A3%EF%BC%8C%E4%B9%9F%E5%8F%AF%E4%BB%A5%E7%9B%B4%E6%8E%A5%E4%BC%A0%E5%85%A5%E4%B8%80%E4%B8%AA%E5%8C%BF%E5%90%8D%E7%B1%BB%E3%80%82%E5%BD%93%E7%84%B6%EF%BC%8C%E5%90%8C%E6%A0%B7%E4%B9%9F%E5%8F%AF%E4%BB%A5%E9%80%9A%E8%BF%87%E4%BC%A0%E5%85%A5Lambda%E8%A1%A8%E8%BE%BE%E5%BC%8F%E5%AE%9E%E7%8E%B0%E7%B1%BB%E4%BC%BC%E7%9A%84%E5%8A%9F%E8%83%BD%E3%80%82"><span class="toc-number">5.</span> <span class="toc-text">我们可以单独定义一个函数类实现ReduceFunction接口，也可以直接传入一个匿名类。当然，同样也可以通过传入Lambda表达式实现类似的功能。</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E4%B8%BA%E4%BA%86%E6%96%B9%E4%BE%BF%E5%90%8E%E7%BB%AD%E4%BD%BF%E7%94%A8%EF%BC%8C%E5%AE%9A%E4%B9%89%E4%B8%80%E4%B8%AAWaterSensorMapFunction%EF%BC%9A"><span class="toc-number">6.</span> <span class="toc-text">为了方便后续使用，定义一个WaterSensorMapFunction：</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%A1%88%E4%BE%8B%EF%BC%9A%E4%BD%BF%E7%94%A8reduce%E5%AE%9E%E7%8E%B0max%E5%92%8CmaxBy%E7%9A%84%E5%8A%9F%E8%83%BD%E3%80%82"><span class="toc-number">7.</span> <span class="toc-text">案例：使用reduce实现max和maxBy的功能。</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#reduce%E5%90%8C%E7%AE%80%E5%8D%95%E8%81%9A%E5%90%88%E7%AE%97%E5%AD%90%E4%B8%80%E6%A0%B7%EF%BC%8C%E4%B9%9F%E8%A6%81%E9%92%88%E5%AF%B9%E6%AF%8F%E4%B8%80%E4%B8%AAkey%E4%BF%9D%E5%AD%98%E7%8A%B6%E6%80%81%E3%80%82%E5%9B%A0%E4%B8%BA%E7%8A%B6%E6%80%81%E4%B8%8D%E4%BC%9A%E6%B8%85%E7%A9%BA%EF%BC%8C%E6%89%80%E4%BB%A5%E6%88%91%E4%BB%AC%E9%9C%80%E8%A6%81%E5%B0%86reduce%E7%AE%97%E5%AD%90%E4%BD%9C%E7%94%A8%E5%9C%A8%E4%B8%80%E4%B8%AA%E6%9C%89%E9%99%90key%E7%9A%84%E6%B5%81%E4%B8%8A%E3%80%82"><span class="toc-number">8.</span> <span class="toc-text">reduce同简单聚合算子一样，也要针对每一个key保存状态。因为状态不会清空，所以我们需要将reduce算子作用在一个有限key的流上。</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-3-3-%E7%94%A8%E6%88%B7%E8%87%AA%E5%AE%9A%E4%B9%89%E5%87%BD%E6%95%B0%EF%BC%88UDF%EF%BC%89"><span class="toc-number"></span> <span class="toc-text">1.3.3 用户自定义函数（UDF）</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E7%94%A8%E6%88%B7%E8%87%AA%E5%AE%9A%E4%B9%89%E5%87%BD%E6%95%B0%EF%BC%88user-defined-function%EF%BC%8CUDF%EF%BC%89%EF%BC%8C%E5%8D%B3%E7%94%A8%E6%88%B7%E5%8F%AF%E4%BB%A5%E6%A0%B9%E6%8D%AE%E8%87%AA%E8%BA%AB%E9%9C%80%E6%B1%82%EF%BC%8C%E9%87%8D%E6%96%B0%E5%AE%9E%E7%8E%B0%E7%AE%97%E5%AD%90%E7%9A%84%E9%80%BB%E8%BE%91%E3%80%82"><span class="toc-number">1.</span> <span class="toc-text">用户自定义函数（user-defined function，UDF），即用户可以根据自身需求，重新实现算子的逻辑。</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E7%94%A8%E6%88%B7%E8%87%AA%E5%AE%9A%E4%B9%89%E5%87%BD%E6%95%B0%E5%88%86%E4%B8%BA%EF%BC%9A%E5%87%BD%E6%95%B0%E7%B1%BB%E3%80%81%E5%8C%BF%E5%90%8D%E5%87%BD%E6%95%B0%E3%80%81%E5%AF%8C%E5%87%BD%E6%95%B0%E7%B1%BB%E3%80%82"><span class="toc-number">2.</span> <span class="toc-text">用户自定义函数分为：函数类、匿名函数、富函数类。</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%9C%80%E6%B1%82%EF%BC%9A%E7%94%A8%E6%9D%A5%E4%BB%8E%E7%94%A8%E6%88%B7%E7%9A%84%E7%82%B9%E5%87%BB%E6%95%B0%E6%8D%AE%E4%B8%AD%E7%AD%9B%E9%80%89%E5%8C%85%E5%90%AB%E2%80%9Csensor-1%E2%80%9D%E7%9A%84%E5%86%85%E5%AE%B9%EF%BC%9A"><span class="toc-number"></span> <span class="toc-text">需求：用来从用户的点击数据中筛选包含“sensor_1”的内容：</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%96%B9%E5%BC%8F%E4%B8%80%EF%BC%9A%E5%AE%9E%E7%8E%B0FilterFunction%E6%8E%A5%E5%8F%A3"><span class="toc-number"></span> <span class="toc-text">方式一：实现FilterFunction接口</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%96%B9%E5%BC%8F%E4%BA%8C%EF%BC%9A%E9%80%9A%E8%BF%87%E5%8C%BF%E5%90%8D%E7%B1%BB%E6%9D%A5%E5%AE%9E%E7%8E%B0FilterFunction%E6%8E%A5%E5%8F%A3%EF%BC%9A"><span class="toc-number"></span> <span class="toc-text">方式二：通过匿名类来实现FilterFunction接口：</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%96%B9%E5%BC%8F%E4%BA%8C%E7%9A%84%E4%BC%98%E5%8C%96%EF%BC%9A%E4%B8%BA%E4%BA%86%E7%B1%BB%E5%8F%AF%E4%BB%A5%E6%9B%B4%E5%8A%A0%E9%80%9A%E7%94%A8%EF%BC%8C%E6%88%91%E4%BB%AC%E8%BF%98%E5%8F%AF%E4%BB%A5%E5%B0%86%E7%94%A8%E4%BA%8E%E8%BF%87%E6%BB%A4%E7%9A%84%E5%85%B3%E9%94%AE%E5%AD%97%E2%80%9Dhome%E2%80%9D%E6%8A%BD%E8%B1%A1%E5%87%BA%E6%9D%A5%E4%BD%9C%E4%B8%BA%E7%B1%BB%E7%9A%84%E5%B1%9E%E6%80%A7%EF%BC%8C%E8%B0%83%E7%94%A8%E6%9E%84%E9%80%A0%E6%96%B9%E6%B3%95%E6%97%B6%E4%BC%A0%E8%BF%9B%E5%8E%BB%E3%80%82"><span class="toc-number">1.</span> <span class="toc-text">方式二的优化：为了类可以更加通用，我们还可以将用于过滤的关键字”home”抽象出来作为类的属性，调用构造方法时传进去。</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%96%B9%E5%BC%8F%E4%B8%89%EF%BC%9A%E9%87%87%E7%94%A8%E5%8C%BF%E5%90%8D%E5%87%BD%E6%95%B0%EF%BC%88Lambda%EF%BC%89"><span class="toc-number">2.</span> <span class="toc-text">方式三：采用匿名函数（Lambda）</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-3-2-%E5%AF%8C%E5%87%BD%E6%95%B0%E7%B1%BB%EF%BC%88Rich-Function-Classes%EF%BC%89"><span class="toc-number"></span> <span class="toc-text">1.3.2 富函数类（Rich Function Classes）</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#%E2%80%9C%E5%AF%8C%E5%87%BD%E6%95%B0%E7%B1%BB%E2%80%9D%E4%B9%9F%E6%98%AFDataStream-API%E6%8F%90%E4%BE%9B%E7%9A%84%E4%B8%80%E4%B8%AA%E5%87%BD%E6%95%B0%E7%B1%BB%E7%9A%84%E6%8E%A5%E5%8F%A3%EF%BC%8C%E6%89%80%E6%9C%89%E7%9A%84Flink%E5%87%BD%E6%95%B0%E7%B1%BB%E9%83%BD%E6%9C%89%E5%85%B6Rich%E7%89%88%E6%9C%AC%E3%80%82%E5%AF%8C%E5%87%BD%E6%95%B0%E7%B1%BB%E4%B8%80%E8%88%AC%E6%98%AF%E4%BB%A5%E6%8A%BD%E8%B1%A1%E7%B1%BB%E7%9A%84%E5%BD%A2%E5%BC%8F%E5%87%BA%E7%8E%B0%E7%9A%84%E3%80%82%E4%BE%8B%E5%A6%82%EF%BC%9ARichMapFunction%E3%80%81RichFilterFunction%E3%80%81RichReduceFunction%E7%AD%89%E3%80%82"><span class="toc-number">0.1.</span> <span class="toc-text">“富函数类”也是DataStream API提供的一个函数类的接口，所有的Flink函数类都有其Rich版本。富函数类一般是以抽象类的形式出现的。例如：RichMapFunction、RichFilterFunction、RichReduceFunction等。</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#%E4%B8%8E%E5%B8%B8%E8%A7%84%E5%87%BD%E6%95%B0%E7%B1%BB%E7%9A%84%E4%B8%8D%E5%90%8C%E4%B8%BB%E8%A6%81%E5%9C%A8%E4%BA%8E%EF%BC%8C%E5%AF%8C%E5%87%BD%E6%95%B0%E7%B1%BB%E5%8F%AF%E4%BB%A5%E8%8E%B7%E5%8F%96%E8%BF%90%E8%A1%8C%E7%8E%AF%E5%A2%83%E7%9A%84%E4%B8%8A%E4%B8%8B%E6%96%87%EF%BC%8C%E5%B9%B6%E6%8B%A5%E6%9C%89%E4%B8%80%E4%BA%9B%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F%E6%96%B9%E6%B3%95%EF%BC%8C%E6%89%80%E4%BB%A5%E5%8F%AF%E4%BB%A5%E5%AE%9E%E7%8E%B0%E6%9B%B4%E5%A4%8D%E6%9D%82%E7%9A%84%E5%8A%9F%E8%83%BD%E3%80%82"><span class="toc-number">0.2.</span> <span class="toc-text">与常规函数类的不同主要在于，富函数类可以获取运行环境的上下文，并拥有一些生命周期方法，所以可以实现更复杂的功能。</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#Rich-Function%E6%9C%89%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F%E7%9A%84%E6%A6%82%E5%BF%B5%E3%80%82%E5%85%B8%E5%9E%8B%E7%9A%84%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F%E6%96%B9%E6%B3%95%E6%9C%89%EF%BC%9A"><span class="toc-number">0.3.</span> <span class="toc-text">Rich Function有生命周期的概念。典型的生命周期方法有：</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#open-%E6%96%B9%E6%B3%95%EF%BC%8C%E6%98%AFRich-Function%E7%9A%84%E5%88%9D%E5%A7%8B%E5%8C%96%E6%96%B9%E6%B3%95%EF%BC%8C%E4%B9%9F%E5%B0%B1%E6%98%AF%E4%BC%9A%E5%BC%80%E5%90%AF%E4%B8%80%E4%B8%AA%E7%AE%97%E5%AD%90%E7%9A%84%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F%E3%80%82%E5%BD%93%E4%B8%80%E4%B8%AA%E7%AE%97%E5%AD%90%E7%9A%84%E5%AE%9E%E9%99%85%E5%B7%A5%E4%BD%9C%E6%96%B9%E6%B3%95%E4%BE%8B%E5%A6%82map-%E6%88%96%E8%80%85filter-%E6%96%B9%E6%B3%95%E8%A2%AB%E8%B0%83%E7%94%A8%E4%B9%8B%E5%89%8D%EF%BC%8Copen-%E4%BC%9A%E9%A6%96%E5%85%88%E8%A2%AB%E8%B0%83%E7%94%A8%E3%80%82"><span class="toc-number">0.4.</span> <span class="toc-text">open()方法，是Rich Function的初始化方法，也就是会开启一个算子的生命周期。当一个算子的实际工作方法例如map()或者filter()方法被调用之前，open()会首先被调用。</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#close-%E6%96%B9%E6%B3%95%EF%BC%8C%E6%98%AF%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F%E4%B8%AD%E7%9A%84%E6%9C%80%E5%90%8E%E4%B8%80%E4%B8%AA%E8%B0%83%E7%94%A8%E7%9A%84%E6%96%B9%E6%B3%95%EF%BC%8C%E7%B1%BB%E4%BC%BC%E4%BA%8E%E7%BB%93%E6%9D%9F%E6%96%B9%E6%B3%95%E3%80%82%E4%B8%80%E8%88%AC%E7%94%A8%E6%9D%A5%E5%81%9A%E4%B8%80%E4%BA%9B%E6%B8%85%E7%90%86%E5%B7%A5%E4%BD%9C%E3%80%82"><span class="toc-number">0.5.</span> <span class="toc-text">close()方法，是生命周期中的最后一个调用的方法，类似于结束方法。一般用来做一些清理工作。</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#%E9%9C%80%E8%A6%81%E6%B3%A8%E6%84%8F%E7%9A%84%E6%98%AF%EF%BC%8C%E8%BF%99%E9%87%8C%E7%9A%84%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F%E6%96%B9%E6%B3%95%EF%BC%8C%E5%AF%B9%E4%BA%8E%E4%B8%80%E4%B8%AA%E5%B9%B6%E8%A1%8C%E5%AD%90%E4%BB%BB%E5%8A%A1%E6%9D%A5%E8%AF%B4%E5%8F%AA%E4%BC%9A%E8%B0%83%E7%94%A8%E4%B8%80%E6%AC%A1%EF%BC%9B%E8%80%8C%E5%AF%B9%E5%BA%94%E7%9A%84%EF%BC%8C%E5%AE%9E%E9%99%85%E5%B7%A5%E4%BD%9C%E6%96%B9%E6%B3%95%EF%BC%8C%E4%BE%8B%E5%A6%82RichMapFunction%E4%B8%AD%E7%9A%84map-%EF%BC%8C%E5%9C%A8%E6%AF%8F%E6%9D%A1%E6%95%B0%E6%8D%AE%E5%88%B0%E6%9D%A5%E5%90%8E%E9%83%BD%E4%BC%9A%E8%A7%A6%E5%8F%91%E4%B8%80%E6%AC%A1%E8%B0%83%E7%94%A8%E3%80%82"><span class="toc-number">0.6.</span> <span class="toc-text">需要注意的是，这里的生命周期方法，对于一个并行子任务来说只会调用一次；而对应的，实际工作方法，例如RichMapFunction中的map()，在每条数据到来后都会触发一次调用。</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#%E6%9D%A5%E7%9C%8B%E4%B8%80%E4%B8%AA%E4%BE%8B%E5%AD%90%E8%AF%B4%E6%98%8E%EF%BC%9A"><span class="toc-number">0.7.</span> <span class="toc-text">来看一个例子说明：</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-3-4-%E7%89%A9%E7%90%86%E5%88%86%E5%8C%BA%E7%AE%97%E5%AD%90%EF%BC%88Physical-Partitioning%EF%BC%89"><span class="toc-number"></span> <span class="toc-text">5.3.4 物理分区算子（Physical Partitioning）</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%B8%B8%E8%A7%81%E7%9A%84%E7%89%A9%E7%90%86%E5%88%86%E5%8C%BA%E7%AD%96%E7%95%A5%E6%9C%89%EF%BC%9A%E9%9A%8F%E6%9C%BA%E5%88%86%E9%85%8D%EF%BC%88Random%EF%BC%89%E3%80%81%E8%BD%AE%E8%AF%A2%E5%88%86%E9%85%8D%EF%BC%88Round-Robin%EF%BC%89%E3%80%81%E9%87%8D%E7%BC%A9%E6%94%BE%EF%BC%88Rescale%EF%BC%89%E5%92%8C%E5%B9%BF%E6%92%AD%EF%BC%88Broadcast%EF%BC%89%E3%80%82"><span class="toc-number">1.</span> <span class="toc-text">常见的物理分区策略有：随机分配（Random）、轮询分配（Round-Robin）、重缩放（Rescale）和广播（Broadcast）。</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-4-1-%E9%9A%8F%E6%9C%BA%E5%88%86%E5%8C%BA%EF%BC%88shuffle%EF%BC%89"><span class="toc-number"></span> <span class="toc-text">1.4.1 随机分区（shuffle）</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%9C%80%E7%AE%80%E5%8D%95%E7%9A%84%E9%87%8D%E5%88%86%E5%8C%BA%E6%96%B9%E5%BC%8F%E5%B0%B1%E6%98%AF%E7%9B%B4%E6%8E%A5%E2%80%9C%E6%B4%97%E7%89%8C%E2%80%9D%E3%80%82%E9%80%9A%E8%BF%87%E8%B0%83%E7%94%A8DataStream%E7%9A%84-shuffle-%E6%96%B9%E6%B3%95%EF%BC%8C%E5%B0%86%E6%95%B0%E6%8D%AE%E9%9A%8F%E6%9C%BA%E5%9C%B0%E5%88%86%E9%85%8D%E5%88%B0%E4%B8%8B%E6%B8%B8%E7%AE%97%E5%AD%90%E7%9A%84%E5%B9%B6%E8%A1%8C%E4%BB%BB%E5%8A%A1%E4%B8%AD%E5%8E%BB%E3%80%82"><span class="toc-number">1.</span> <span class="toc-text">最简单的重分区方式就是直接“洗牌”。通过调用DataStream的.shuffle()方法，将数据随机地分配到下游算子的并行任务中去。</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E9%9A%8F%E6%9C%BA%E5%88%86%E5%8C%BA%E6%9C%8D%E4%BB%8E%E5%9D%87%E5%8C%80%E5%88%86%E5%B8%83%EF%BC%88uniform-distribution%EF%BC%89%EF%BC%8C%E6%89%80%E4%BB%A5%E5%8F%AF%E4%BB%A5%E6%8A%8A%E6%B5%81%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE%E9%9A%8F%E6%9C%BA%E6%89%93%E4%B9%B1%EF%BC%8C%E5%9D%87%E5%8C%80%E5%9C%B0%E4%BC%A0%E9%80%92%E5%88%B0%E4%B8%8B%E6%B8%B8%E4%BB%BB%E5%8A%A1%E5%88%86%E5%8C%BA%E3%80%82%E5%9B%A0%E4%B8%BA%E6%98%AF%E5%AE%8C%E5%85%A8%E9%9A%8F%E6%9C%BA%E7%9A%84%EF%BC%8C%E6%89%80%E4%BB%A5%E5%AF%B9%E4%BA%8E%E5%90%8C%E6%A0%B7%E7%9A%84%E8%BE%93%E5%85%A5%E6%95%B0%E6%8D%AE-%E6%AF%8F%E6%AC%A1%E6%89%A7%E8%A1%8C%E5%BE%97%E5%88%B0%E7%9A%84%E7%BB%93%E6%9E%9C%E4%B9%9F%E4%B8%8D%E4%BC%9A%E7%9B%B8%E5%90%8C%E3%80%82"><span class="toc-number">2.</span> <span class="toc-text">随机分区服从均匀分布（uniform distribution），所以可以把流中的数据随机打乱，均匀地传递到下游任务分区。因为是完全随机的，所以对于同样的输入数据, 每次执行得到的结果也不会相同。</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E7%BB%8F%E8%BF%87%E9%9A%8F%E6%9C%BA%E5%88%86%E5%8C%BA%E4%B9%8B%E5%90%8E%EF%BC%8C%E5%BE%97%E5%88%B0%E7%9A%84%E4%BE%9D%E7%84%B6%E6%98%AF%E4%B8%80%E4%B8%AADataStream%E3%80%82"><span class="toc-number">3.</span> <span class="toc-text">经过随机分区之后，得到的依然是一个DataStream。</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%88%91%E4%BB%AC%E5%8F%AF%E4%BB%A5%E5%81%9A%E4%B8%AA%E7%AE%80%E5%8D%95%E6%B5%8B%E8%AF%95%EF%BC%9A%E5%B0%86%E6%95%B0%E6%8D%AE%E8%AF%BB%E5%85%A5%E4%B9%8B%E5%90%8E%E7%9B%B4%E6%8E%A5%E6%89%93%E5%8D%B0%E5%88%B0%E6%8E%A7%E5%88%B6%E5%8F%B0%EF%BC%8C%E5%B0%86%E8%BE%93%E5%87%BA%E7%9A%84%E5%B9%B6%E8%A1%8C%E5%BA%A6%E8%AE%BE%E7%BD%AE%E4%B8%BA2%EF%BC%8C%E4%B8%AD%E9%97%B4%E7%BB%8F%E5%8E%86%E4%B8%80%E6%AC%A1shuffle%E3%80%82%E6%89%A7%E8%A1%8C%E5%A4%9A%E6%AC%A1%EF%BC%8C%E8%A7%82%E5%AF%9F%E7%BB%93%E6%9E%9C%E6%98%AF%E5%90%A6%E7%9B%B8%E5%90%8C%E3%80%82"><span class="toc-number">4.</span> <span class="toc-text">我们可以做个简单测试：将数据读入之后直接打印到控制台，将输出的并行度设置为2，中间经历一次shuffle。执行多次，观察结果是否相同。</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-4-2-%E8%BD%AE%E8%AF%A2%E5%88%86%E5%8C%BA%EF%BC%88Round-Robin%EF%BC%89"><span class="toc-number"></span> <span class="toc-text">1.4.2 轮询分区（Round-Robin）</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E8%BD%AE%E8%AF%A2%EF%BC%8C%E7%AE%80%E5%8D%95%E6%9D%A5%E8%AF%B4%E5%B0%B1%E6%98%AF%E2%80%9C%E5%8F%91%E7%89%8C%E2%80%9D%EF%BC%8C%E6%8C%89%E7%85%A7%E5%85%88%E5%90%8E%E9%A1%BA%E5%BA%8F%E5%B0%86%E6%95%B0%E6%8D%AE%E5%81%9A%E4%BE%9D%E6%AC%A1%E5%88%86%E5%8F%91%E3%80%82%E9%80%9A%E8%BF%87%E8%B0%83%E7%94%A8DataStream%E7%9A%84-rebalance-%E6%96%B9%E6%B3%95%EF%BC%8C%E5%B0%B1%E5%8F%AF%E4%BB%A5%E5%AE%9E%E7%8E%B0%E8%BD%AE%E8%AF%A2%E9%87%8D%E5%88%86%E5%8C%BA%E3%80%82rebalance%E4%BD%BF%E7%94%A8%E7%9A%84%E6%98%AFRound-Robin%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E7%AE%97%E6%B3%95%EF%BC%8C%E5%8F%AF%E4%BB%A5%E5%B0%86%E8%BE%93%E5%85%A5%E6%B5%81%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%9D%87%E5%88%86%E9%85%8D%E5%88%B0%E4%B8%8B%E6%B8%B8%E7%9A%84%E5%B9%B6%E8%A1%8C%E4%BB%BB%E5%8A%A1%E4%B8%AD%E5%8E%BB%E3%80%82"><span class="toc-number">1.</span> <span class="toc-text">轮询，简单来说就是“发牌”，按照先后顺序将数据做依次分发。通过调用DataStream的.rebalance()方法，就可以实现轮询重分区。rebalance使用的是Round-Robin负载均衡算法，可以将输入流数据平均分配到下游的并行任务中去。</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-4-3-%E9%87%8D%E7%BC%A9%E6%94%BE%E5%88%86%E5%8C%BA%EF%BC%88rescale%EF%BC%89"><span class="toc-number"></span> <span class="toc-text">1.4.3 重缩放分区（rescale）</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E9%87%8D%E7%BC%A9%E6%94%BE%E5%88%86%E5%8C%BA%E5%92%8C%E8%BD%AE%E8%AF%A2%E5%88%86%E5%8C%BA%E9%9D%9E%E5%B8%B8%E7%9B%B8%E4%BC%BC%E3%80%82%E5%BD%93%E8%B0%83%E7%94%A8rescale-%E6%96%B9%E6%B3%95%E6%97%B6%EF%BC%8C%E5%85%B6%E5%AE%9E%E5%BA%95%E5%B1%82%E4%B9%9F%E6%98%AF%E4%BD%BF%E7%94%A8Round-Robin%E7%AE%97%E6%B3%95%E8%BF%9B%E8%A1%8C%E8%BD%AE%E8%AF%A2%EF%BC%8C%E4%BD%86%E6%98%AF%E5%8F%AA%E4%BC%9A%E5%B0%86%E6%95%B0%E6%8D%AE%E8%BD%AE%E8%AF%A2%E5%8F%91%E9%80%81%E5%88%B0%E4%B8%8B%E6%B8%B8%E5%B9%B6%E8%A1%8C%E4%BB%BB%E5%8A%A1%E7%9A%84%E4%B8%80%E9%83%A8%E5%88%86%E4%B8%AD%E3%80%82rescale%E7%9A%84%E5%81%9A%E6%B3%95%E6%98%AF%E5%88%86%E6%88%90%E5%B0%8F%E5%9B%A2%E4%BD%93%EF%BC%8C%E5%8F%91%E7%89%8C%E4%BA%BA%E5%8F%AA%E7%BB%99%E8%87%AA%E5%B7%B1%E5%9B%A2%E4%BD%93%E5%86%85%E7%9A%84%E6%89%80%E6%9C%89%E4%BA%BA%E8%BD%AE%E6%B5%81%E5%8F%91%E7%89%8C%E3%80%82"><span class="toc-number">1.</span> <span class="toc-text">重缩放分区和轮询分区非常相似。当调用rescale()方法时，其实底层也是使用Round-Robin算法进行轮询，但是只会将数据轮询发送到下游并行任务的一部分中。rescale的做法是分成小团体，发牌人只给自己团体内的所有人轮流发牌。</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-4-4-%E5%B9%BF%E6%92%AD%EF%BC%88broadcast%EF%BC%89"><span class="toc-number"></span> <span class="toc-text">1.4.4 广播（broadcast）</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E8%BF%99%E7%A7%8D%E6%96%B9%E5%BC%8F%E5%85%B6%E5%AE%9E%E4%B8%8D%E5%BA%94%E8%AF%A5%E5%8F%AB%E5%81%9A%E2%80%9C%E9%87%8D%E5%88%86%E5%8C%BA%E2%80%9D%EF%BC%8C%E5%9B%A0%E4%B8%BA%E7%BB%8F%E8%BF%87%E5%B9%BF%E6%92%AD%E4%B9%8B%E5%90%8E%EF%BC%8C%E6%95%B0%E6%8D%AE%E4%BC%9A%E5%9C%A8%E4%B8%8D%E5%90%8C%E7%9A%84%E5%88%86%E5%8C%BA%E9%83%BD%E4%BF%9D%E7%95%99%E4%B8%80%E4%BB%BD%EF%BC%8C%E5%8F%AF%E8%83%BD%E8%BF%9B%E8%A1%8C%E9%87%8D%E5%A4%8D%E5%A4%84%E7%90%86%E3%80%82%E5%8F%AF%E4%BB%A5%E9%80%9A%E8%BF%87%E8%B0%83%E7%94%A8DataStream%E7%9A%84broadcast-%E6%96%B9%E6%B3%95%EF%BC%8C%E5%B0%86%E8%BE%93%E5%85%A5%E6%95%B0%E6%8D%AE%E5%A4%8D%E5%88%B6%E5%B9%B6%E5%8F%91%E9%80%81%E5%88%B0%E4%B8%8B%E6%B8%B8%E7%AE%97%E5%AD%90%E7%9A%84%E6%89%80%E6%9C%89%E5%B9%B6%E8%A1%8C%E4%BB%BB%E5%8A%A1%E4%B8%AD%E5%8E%BB%E3%80%82"><span class="toc-number">1.</span> <span class="toc-text">这种方式其实不应该叫做“重分区”，因为经过广播之后，数据会在不同的分区都保留一份，可能进行重复处理。可以通过调用DataStream的broadcast()方法，将输入数据复制并发送到下游算子的所有并行任务中去。</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-4-5-%E5%85%A8%E5%B1%80%E5%88%86%E5%8C%BA%EF%BC%88global%EF%BC%89"><span class="toc-number"></span> <span class="toc-text">1.4.5 全局分区（global）</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%85%A8%E5%B1%80%E5%88%86%E5%8C%BA%E4%B9%9F%E6%98%AF%E4%B8%80%E7%A7%8D%E7%89%B9%E6%AE%8A%E7%9A%84%E5%88%86%E5%8C%BA%E6%96%B9%E5%BC%8F%E3%80%82%E8%BF%99%E7%A7%8D%E5%81%9A%E6%B3%95%E9%9D%9E%E5%B8%B8%E6%9E%81%E7%AB%AF%EF%BC%8C%E9%80%9A%E8%BF%87%E8%B0%83%E7%94%A8-global-%E6%96%B9%E6%B3%95%EF%BC%8C%E4%BC%9A%E5%B0%86%E6%89%80%E6%9C%89%E7%9A%84%E8%BE%93%E5%85%A5%E6%B5%81%E6%95%B0%E6%8D%AE%E9%83%BD%E5%8F%91%E9%80%81%E5%88%B0%E4%B8%8B%E6%B8%B8%E7%AE%97%E5%AD%90%E7%9A%84%E7%AC%AC%E4%B8%80%E4%B8%AA%E5%B9%B6%E8%A1%8C%E5%AD%90%E4%BB%BB%E5%8A%A1%E4%B8%AD%E5%8E%BB%E3%80%82%E8%BF%99%E5%B0%B1%E7%9B%B8%E5%BD%93%E4%BA%8E%E5%BC%BA%E8%A1%8C%E8%AE%A9%E4%B8%8B%E6%B8%B8%E4%BB%BB%E5%8A%A1%E5%B9%B6%E8%A1%8C%E5%BA%A6%E5%8F%98%E6%88%90%E4%BA%861%EF%BC%8C%E6%89%80%E4%BB%A5%E4%BD%BF%E7%94%A8%E8%BF%99%E4%B8%AA%E6%93%8D%E4%BD%9C%E9%9C%80%E8%A6%81%E9%9D%9E%E5%B8%B8%E8%B0%A8%E6%85%8E%EF%BC%8C%E5%8F%AF%E8%83%BD%E5%AF%B9%E7%A8%8B%E5%BA%8F%E9%80%A0%E6%88%90%E5%BE%88%E5%A4%A7%E7%9A%84%E5%8E%8B%E5%8A%9B%E3%80%82"><span class="toc-number">1.</span> <span class="toc-text">全局分区也是一种特殊的分区方式。这种做法非常极端，通过调用.global()方法，会将所有的输入流数据都发送到下游算子的第一个并行子任务中去。这就相当于强行让下游任务并行度变成了1，所以使用这个操作需要非常谨慎，可能对程序造成很大的压力。</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-4-6-%E8%87%AA%E5%AE%9A%E4%B9%89%E5%88%86%E5%8C%BA%EF%BC%88Custom%EF%BC%89"><span class="toc-number"></span> <span class="toc-text">1.4.6 自定义分区（Custom）</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%BD%93Flink%E6%8F%90%E4%BE%9B%E7%9A%84%E6%89%80%E6%9C%89%E5%88%86%E5%8C%BA%E7%AD%96%E7%95%A5%E9%83%BD%E4%B8%8D%E8%83%BD%E6%BB%A1%E8%B6%B3%E7%94%A8%E6%88%B7%E7%9A%84%E9%9C%80%E6%B1%82%E6%97%B6%EF%BC%8C%E6%88%91%E4%BB%AC%E5%8F%AF%E4%BB%A5%E9%80%9A%E8%BF%87%E4%BD%BF%E7%94%A8partitionCustom-%E6%96%B9%E6%B3%95%E6%9D%A5%E8%87%AA%E5%AE%9A%E4%B9%89%E5%88%86%E5%8C%BA%E7%AD%96%E7%95%A5%E3%80%82"><span class="toc-number">1.</span> <span class="toc-text">当Flink提供的所有分区策略都不能满足用户的需求时，我们可以通过使用partitionCustom()方法来自定义分区策略。</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-%E8%87%AA%E5%AE%9A%E4%B9%89%E5%88%86%E5%8C%BA%E5%99%A8"><span class="toc-number"></span> <span class="toc-text">1)自定义分区器</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#2%EF%BC%89%E4%BD%BF%E7%94%A8%E8%87%AA%E5%AE%9A%E4%B9%89%E5%88%86%E5%8C%BA%E5%99%A8"><span class="toc-number">1.</span> <span class="toc-text">2）使用自定义分区器</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-3-5%E5%88%86%E6%B5%81"><span class="toc-number"></span> <span class="toc-text">1.3.5分流</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%89%80%E8%B0%93%E2%80%9C%E5%88%86%E6%B5%81%E2%80%9D%EF%BC%8C%E5%B0%B1%E6%98%AF%E5%B0%86%E4%B8%80%E6%9D%A1%E6%95%B0%E6%8D%AE%E6%B5%81%E6%8B%86%E5%88%86%E6%88%90%E5%AE%8C%E5%85%A8%E7%8B%AC%E7%AB%8B%E7%9A%84%E4%B8%A4%E6%9D%A1%E3%80%81%E7%94%9A%E8%87%B3%E5%A4%9A%E6%9D%A1%E6%B5%81%E3%80%82%E4%B9%9F%E5%B0%B1%E6%98%AF%E5%9F%BA%E4%BA%8E%E4%B8%80%E4%B8%AADataStream%EF%BC%8C%E5%AE%9A%E4%B9%89%E4%B8%80%E4%BA%9B%E7%AD%9B%E9%80%89%E6%9D%A1%E4%BB%B6%EF%BC%8C%E5%B0%86%E7%AC%A6%E5%90%88%E6%9D%A1%E4%BB%B6%E7%9A%84%E6%95%B0%E6%8D%AE%E6%8B%A3%E9%80%89%E5%87%BA%E6%9D%A5%E6%94%BE%E5%88%B0%E5%AF%B9%E5%BA%94%E7%9A%84%E6%B5%81%E9%87%8C%E3%80%82"><span class="toc-number"></span> <span class="toc-text">所谓“分流”，就是将一条数据流拆分成完全独立的两条、甚至多条流。也就是基于一个DataStream，定义一些筛选条件，将符合条件的数据拣选出来放到对应的流里。</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-3-5-1-%E7%AE%80%E5%8D%95%E5%AE%9E%E7%8E%B0"><span class="toc-number"></span> <span class="toc-text">1.3.5.1 简单实现</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E8%BF%99%E7%A7%8D%E5%AE%9E%E7%8E%B0%E9%9D%9E%E5%B8%B8%E7%AE%80%E5%8D%95%EF%BC%8C%E4%BD%86%E4%BB%A3%E7%A0%81%E6%98%BE%E5%BE%97%E6%9C%89%E4%BA%9B%E5%86%97%E4%BD%99%E2%80%94%E2%80%94%E6%88%91%E4%BB%AC%E7%9A%84%E5%A4%84%E7%90%86%E9%80%BB%E8%BE%91%E5%AF%B9%E6%8B%86%E5%88%86%E5%87%BA%E7%9A%84%E4%B8%89%E6%9D%A1%E6%B5%81%E5%85%B6%E5%AE%9E%E6%98%AF%E4%B8%80%E6%A0%B7%E7%9A%84%EF%BC%8C%E5%8D%B4%E9%87%8D%E5%A4%8D%E5%86%99%E4%BA%86%E4%B8%89%E6%AC%A1%E3%80%82%E8%80%8C%E4%B8%94%E8%BF%99%E6%AE%B5%E4%BB%A3%E7%A0%81%E8%83%8C%E5%90%8E%E7%9A%84%E5%90%AB%E4%B9%89%EF%BC%8C%E6%98%AF%E5%B0%86%E5%8E%9F%E5%A7%8B%E6%95%B0%E6%8D%AE%E6%B5%81stream%E5%A4%8D%E5%88%B6%E4%B8%89%E4%BB%BD%EF%BC%8C%E7%84%B6%E5%90%8E%E5%AF%B9%E6%AF%8F%E4%B8%80%E4%BB%BD%E5%88%86%E5%88%AB%E5%81%9A%E7%AD%9B%E9%80%89%EF%BC%9B%E8%BF%99%E6%98%8E%E6%98%BE%E6%98%AF%E4%B8%8D%E5%A4%9F%E9%AB%98%E6%95%88%E7%9A%84%E3%80%82%E6%88%91%E4%BB%AC%E8%87%AA%E7%84%B6%E6%83%B3%E5%88%B0%EF%BC%8C%E8%83%BD%E4%B8%8D%E8%83%BD%E4%B8%8D%E7%94%A8%E5%A4%8D%E5%88%B6%E6%B5%81%EF%BC%8C%E7%9B%B4%E6%8E%A5%E7%94%A8%E4%B8%80%E4%B8%AA%E7%AE%97%E5%AD%90%E5%B0%B1%E6%8A%8A%E5%AE%83%E4%BB%AC%E9%83%BD%E6%8B%86%E5%88%86%E5%BC%80%E5%91%A2%EF%BC%9F"><span class="toc-number">1.</span> <span class="toc-text">这种实现非常简单，但代码显得有些冗余——我们的处理逻辑对拆分出的三条流其实是一样的，却重复写了三次。而且这段代码背后的含义，是将原始数据流stream复制三份，然后对每一份分别做筛选；这明显是不够高效的。我们自然想到，能不能不用复制流，直接用一个算子就把它们都拆分开呢？</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-3-5-2-%E4%BD%BF%E7%94%A8%E4%BE%A7%E8%BE%93%E5%87%BA%E6%B5%81"><span class="toc-number"></span> <span class="toc-text">1.3.5.2 使用侧输出流</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-3-6-%E5%9F%BA%E6%9C%AC%E5%90%88%E6%B5%81%E6%93%8D%E4%BD%9C"><span class="toc-number"></span> <span class="toc-text">1.3.6 基本合流操作</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%9C%A8%E5%AE%9E%E9%99%85%E5%BA%94%E7%94%A8%E4%B8%AD%EF%BC%8C%E6%88%91%E4%BB%AC%E7%BB%8F%E5%B8%B8%E4%BC%9A%E9%81%87%E5%88%B0%E6%9D%A5%E6%BA%90%E4%B8%8D%E5%90%8C%E7%9A%84%E5%A4%9A%E6%9D%A1%E6%B5%81%EF%BC%8C%E9%9C%80%E8%A6%81%E5%B0%86%E5%AE%83%E4%BB%AC%E7%9A%84%E6%95%B0%E6%8D%AE%E8%BF%9B%E8%A1%8C%E8%81%94%E5%90%88%E5%A4%84%E7%90%86%E3%80%82%E6%89%80%E4%BB%A5Flink%E4%B8%AD%E5%90%88%E6%B5%81%E7%9A%84%E6%93%8D%E4%BD%9C%E4%BC%9A%E6%9B%B4%E5%8A%A0%E6%99%AE%E9%81%8D%EF%BC%8C%E5%AF%B9%E5%BA%94%E7%9A%84API%E4%B9%9F%E6%9B%B4%E5%8A%A0%E4%B8%B0%E5%AF%8C%E3%80%82"><span class="toc-number">1.</span> <span class="toc-text">在实际应用中，我们经常会遇到来源不同的多条流，需要将它们的数据进行联合处理。所以Flink中合流的操作会更加普遍，对应的API也更加丰富。</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-3-6-1"><span class="toc-number"></span> <span class="toc-text">1.3.6.1</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%9C%80%E7%AE%80%E5%8D%95%E7%9A%84%E5%90%88%E6%B5%81%E6%93%8D%E4%BD%9C%EF%BC%8C%E5%B0%B1%E6%98%AF%E7%9B%B4%E6%8E%A5%E5%B0%86%E5%A4%9A%E6%9D%A1%E6%B5%81%E5%90%88%E5%9C%A8%E4%B8%80%E8%B5%B7%EF%BC%8C%E5%8F%AB%E4%BD%9C%E6%B5%81%E7%9A%84%E2%80%9C%E8%81%94%E5%90%88%E2%80%9D%EF%BC%88union%EF%BC%89%E3%80%82%E8%81%94%E5%90%88%E6%93%8D%E4%BD%9C%E8%A6%81%E6%B1%82%E5%BF%85%E9%A1%BB%E6%B5%81%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%E5%BF%85%E9%A1%BB%E7%9B%B8%E5%90%8C%EF%BC%8C%E5%90%88%E5%B9%B6%E4%B9%8B%E5%90%8E%E7%9A%84%E6%96%B0%E6%B5%81%E4%BC%9A%E5%8C%85%E6%8B%AC%E6%89%80%E6%9C%89%E6%B5%81%E4%B8%AD%E7%9A%84%E5%85%83%E7%B4%A0%EF%BC%8C%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%E4%B8%8D%E5%8F%98%E3%80%82"><span class="toc-number"></span> <span class="toc-text">最简单的合流操作，就是直接将多条流合在一起，叫作流的“联合”（union）。联合操作要求必须流中的数据类型必须相同，合并之后的新流会包括所有流中的元素，数据类型不变。</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%9C%A8%E4%BB%A3%E7%A0%81%E4%B8%AD%EF%BC%8C%E6%88%91%E4%BB%AC%E5%8F%AA%E8%A6%81%E5%9F%BA%E4%BA%8EDataStream%E7%9B%B4%E6%8E%A5%E8%B0%83%E7%94%A8-union-%E6%96%B9%E6%B3%95%EF%BC%8C%E4%BC%A0%E5%85%A5%E5%85%B6%E4%BB%96DataStream%E4%BD%9C%E4%B8%BA%E5%8F%82%E6%95%B0%EF%BC%8C%E5%B0%B1%E5%8F%AF%E4%BB%A5%E5%AE%9E%E7%8E%B0%E6%B5%81%E7%9A%84%E8%81%94%E5%90%88%E4%BA%86%EF%BC%9B%E5%BE%97%E5%88%B0%E7%9A%84%E4%BE%9D%E7%84%B6%E6%98%AF%E4%B8%80%E4%B8%AADataStream%EF%BC%9A"><span class="toc-number">1.</span> <span class="toc-text">在代码中，我们只要基于DataStream直接调用.union()方法，传入其他DataStream作为参数，就可以实现流的联合了；得到的依然是一个DataStream：</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%B3%A8%E6%84%8F%EF%BC%9Aunion-%E7%9A%84%E5%8F%82%E6%95%B0%E5%8F%AF%E4%BB%A5%E6%98%AF%E5%A4%9A%E4%B8%AADataStream%EF%BC%8C%E6%89%80%E4%BB%A5%E8%81%94%E5%90%88%E6%93%8D%E4%BD%9C%E5%8F%AF%E4%BB%A5%E5%AE%9E%E7%8E%B0%E5%A4%9A%E6%9D%A1%E6%B5%81%E7%9A%84%E5%90%88%E5%B9%B6%E3%80%82"><span class="toc-number"></span> <span class="toc-text">注意：union()的参数可以是多个DataStream，所以联合操作可以实现多条流的合并。</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-3-6-2-%E8%BF%9E%E6%8E%A5%EF%BC%88Connect%EF%BC%89"><span class="toc-number"></span> <span class="toc-text">1.3.6.2 连接（Connect）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%B5%81%E7%9A%84%E8%81%94%E5%90%88%E8%99%BD%E7%84%B6%E7%AE%80%E5%8D%95%EF%BC%8C%E4%B8%8D%E8%BF%87%E5%8F%97%E9%99%90%E4%BA%8E%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%E4%B8%8D%E8%83%BD%E6%94%B9%E5%8F%98%EF%BC%8C%E7%81%B5%E6%B4%BB%E6%80%A7%E5%A4%A7%E6%89%93%E6%8A%98%E6%89%A3%EF%BC%8C%E6%89%80%E4%BB%A5%E5%AE%9E%E9%99%85%E5%BA%94%E7%94%A8%E8%BE%83%E5%B0%91%E5%87%BA%E7%8E%B0%E3%80%82%E9%99%A4%E4%BA%86%E8%81%94%E5%90%88%EF%BC%88union%EF%BC%89%EF%BC%8CFlink%E8%BF%98%E6%8F%90%E4%BE%9B%E4%BA%86%E5%8F%A6%E5%A4%96%E4%B8%80%E7%A7%8D%E6%96%B9%E4%BE%BF%E7%9A%84%E5%90%88%E6%B5%81%E6%93%8D%E4%BD%9C%E2%80%94%E2%80%94%E8%BF%9E%E6%8E%A5%EF%BC%88connect%EF%BC%89%E3%80%82"><span class="toc-number"></span> <span class="toc-text">流的联合虽然简单，不过受限于数据类型不能改变，灵活性大打折扣，所以实际应用较少出现。除了联合（union），Flink还提供了另外一种方便的合流操作——连接（connect）。</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#1%EF%BC%89%E8%BF%9E%E6%8E%A5%E6%B5%81%EF%BC%88ConnectedStreams%EF%BC%89"><span class="toc-number">1.</span> <span class="toc-text">1）连接流（ConnectedStreams）</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-4%E8%BE%93%E5%87%BA%E7%AE%97%E5%AD%90"><span class="toc-number"></span> <span class="toc-text">1.4输出算子</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Flink%E4%BD%9C%E4%B8%BA%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%A1%86%E6%9E%B6%EF%BC%8C%E6%9C%80%E7%BB%88%E8%BF%98%E6%98%AF%E8%A6%81%E6%8A%8A%E8%AE%A1%E7%AE%97%E5%A4%84%E7%90%86%E7%9A%84%E7%BB%93%E6%9E%9C%E5%86%99%E5%85%A5%E5%A4%96%E9%83%A8%E5%AD%98%E5%82%A8%EF%BC%8C%E4%B8%BA%E5%A4%96%E9%83%A8%E5%BA%94%E7%94%A8%E6%8F%90%E4%BE%9B%E6%94%AF%E6%8C%81%E3%80%82"><span class="toc-number"></span> <span class="toc-text">Flink作为数据处理框架，最终还是要把计算处理的结果写入外部存储，为外部应用提供支持。</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-4-1-%E8%BF%9E%E6%8E%A5%E5%88%B0%E5%A4%96%E9%83%A8%E7%B3%BB%E7%BB%9F"><span class="toc-number"></span> <span class="toc-text">1.4.1 连接到外部系统</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Flink%E7%9A%84DataStream-API%E4%B8%93%E9%97%A8%E6%8F%90%E4%BE%9B%E4%BA%86%E5%90%91%E5%A4%96%E9%83%A8%E5%86%99%E5%85%A5%E6%95%B0%E6%8D%AE%E7%9A%84%E6%96%B9%E6%B3%95%EF%BC%9AaddSink%E3%80%82%E4%B8%8EaddSource%E7%B1%BB%E4%BC%BC%EF%BC%8CaddSink%E6%96%B9%E6%B3%95%E5%AF%B9%E5%BA%94%E7%9D%80%E4%B8%80%E4%B8%AA%E2%80%9CSink%E2%80%9D%E7%AE%97%E5%AD%90%EF%BC%8C%E4%B8%BB%E8%A6%81%E5%B0%B1%E6%98%AF%E7%94%A8%E6%9D%A5%E5%AE%9E%E7%8E%B0%E4%B8%8E%E5%A4%96%E9%83%A8%E7%B3%BB%E7%BB%9F%E8%BF%9E%E6%8E%A5%E3%80%81%E5%B9%B6%E5%B0%86%E6%95%B0%E6%8D%AE%E6%8F%90%E4%BA%A4%E5%86%99%E5%85%A5%E7%9A%84%EF%BC%9BFlink%E7%A8%8B%E5%BA%8F%E4%B8%AD%E6%89%80%E6%9C%89%E5%AF%B9%E5%A4%96%E7%9A%84%E8%BE%93%E5%87%BA%E6%93%8D%E4%BD%9C%EF%BC%8C%E4%B8%80%E8%88%AC%E9%83%BD%E6%98%AF%E5%88%A9%E7%94%A8Sink%E7%AE%97%E5%AD%90%E5%AE%8C%E6%88%90%E7%9A%84%E3%80%82"><span class="toc-number"></span> <span class="toc-text">Flink的DataStream API专门提供了向外部写入数据的方法：addSink。与addSource类似，addSink方法对应着一个“Sink”算子，主要就是用来实现与外部系统连接、并将数据提交写入的；Flink程序中所有对外的输出操作，一般都是利用Sink算子完成的。</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#Flink1-12%E4%BB%A5%E5%89%8D%EF%BC%8CSink%E7%AE%97%E5%AD%90%E7%9A%84%E5%88%9B%E5%BB%BA%E6%98%AF%E9%80%9A%E8%BF%87%E8%B0%83%E7%94%A8DataStream%E7%9A%84-addSink-%E6%96%B9%E6%B3%95%E5%AE%9E%E7%8E%B0%E7%9A%84%E3%80%82"><span class="toc-number">1.</span> <span class="toc-text">Flink1.12以前，Sink算子的创建是通过调用DataStream的.addSink()方法实现的。</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#stream-addSink-new-SinkFunction-%E2%80%A6"><span class="toc-number">2.</span> <span class="toc-text">stream.addSink(new SinkFunction(…));</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#addSink%E6%96%B9%E6%B3%95%E5%90%8C%E6%A0%B7%E9%9C%80%E8%A6%81%E4%BC%A0%E5%85%A5%E4%B8%80%E4%B8%AA%E5%8F%82%E6%95%B0%EF%BC%8C%E5%AE%9E%E7%8E%B0%E7%9A%84%E6%98%AFSinkFunction%E6%8E%A5%E5%8F%A3%E3%80%82%E5%9C%A8%E8%BF%99%E4%B8%AA%E6%8E%A5%E5%8F%A3%E4%B8%AD%E5%8F%AA%E9%9C%80%E8%A6%81%E9%87%8D%E5%86%99%E4%B8%80%E4%B8%AA%E6%96%B9%E6%B3%95invoke-%EF%BC%8C%E7%94%A8%E6%9D%A5%E5%B0%86%E6%8C%87%E5%AE%9A%E7%9A%84%E5%80%BC%E5%86%99%E5%85%A5%E5%88%B0%E5%A4%96%E9%83%A8%E7%B3%BB%E7%BB%9F%E4%B8%AD%E3%80%82%E8%BF%99%E4%B8%AA%E6%96%B9%E6%B3%95%E5%9C%A8%E6%AF%8F%E6%9D%A1%E6%95%B0%E6%8D%AE%E8%AE%B0%E5%BD%95%E5%88%B0%E6%9D%A5%E6%97%B6%E9%83%BD%E4%BC%9A%E8%B0%83%E7%94%A8%E3%80%82"><span class="toc-number">3.</span> <span class="toc-text">addSink方法同样需要传入一个参数，实现的是SinkFunction接口。在这个接口中只需要重写一个方法invoke()，用来将指定的值写入到外部系统中。这个方法在每条数据记录到来时都会调用。</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Flink1-12%E5%BC%80%E5%A7%8B%EF%BC%8C%E5%90%8C%E6%A0%B7%E9%87%8D%E6%9E%84%E4%BA%86Sink%E6%9E%B6%E6%9E%84%EF%BC%8C"><span class="toc-number">4.</span> <span class="toc-text">Flink1.12开始，同样重构了Sink架构，</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%BD%93%E7%84%B6%EF%BC%8CSink%E5%A4%9A%E6%95%B0%E6%83%85%E5%86%B5%E4%B8%8B%E5%90%8C%E6%A0%B7%E5%B9%B6%E4%B8%8D%E9%9C%80%E8%A6%81%E6%88%91%E4%BB%AC%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E3%80%82%E4%B9%8B%E5%89%8D%E6%88%91%E4%BB%AC%E4%B8%80%E7%9B%B4%E5%9C%A8%E4%BD%BF%E7%94%A8%E7%9A%84print%E6%96%B9%E6%B3%95%E5%85%B6%E5%AE%9E%E5%B0%B1%E6%98%AF%E4%B8%80%E7%A7%8DSink%EF%BC%8C%E5%AE%83%E8%A1%A8%E7%A4%BA%E5%B0%86%E6%95%B0%E6%8D%AE%E6%B5%81%E5%86%99%E5%85%A5%E6%A0%87%E5%87%86%E6%8E%A7%E5%88%B6%E5%8F%B0%E6%89%93%E5%8D%B0%E8%BE%93%E5%87%BA%E3%80%82Flink%E5%AE%98%E6%96%B9%E4%B8%BA%E6%88%91%E4%BB%AC%E6%8F%90%E4%BE%9B%E4%BA%86%E4%B8%80%E9%83%A8%E5%88%86%E7%9A%84%E6%A1%86%E6%9E%B6%E7%9A%84Sink%E8%BF%9E%E6%8E%A5%E5%99%A8%E3%80%82%E5%A6%82%E4%B8%8B%E5%9B%BE%E6%89%80%E7%A4%BA%EF%BC%8C%E5%88%97%E5%87%BA%E4%BA%86Flink%E5%AE%98%E6%96%B9%E7%9B%AE%E5%89%8D%E6%94%AF%E6%8C%81%E7%9A%84%E7%AC%AC%E4%B8%89%E6%96%B9%E7%B3%BB%E7%BB%9F%E8%BF%9E%E6%8E%A5%E5%99%A8%EF%BC%9A"><span class="toc-number"></span> <span class="toc-text">当然，Sink多数情况下同样并不需要我们自己实现。之前我们一直在使用的print方法其实就是一种Sink，它表示将数据流写入标准控制台打印输出。Flink官方为我们提供了一部分的框架的Sink连接器。如下图所示，列出了Flink官方目前支持的第三方系统连接器：</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%88%91%E4%BB%AC%E5%8F%AF%E4%BB%A5%E7%9C%8B%E5%88%B0%EF%BC%8C%E5%83%8FKafka%E4%B9%8B%E7%B1%BB%E6%B5%81%E5%BC%8F%E7%B3%BB%E7%BB%9F%EF%BC%8CFlink%E6%8F%90%E4%BE%9B%E4%BA%86%E5%AE%8C%E7%BE%8E%E5%AF%B9%E6%8E%A5%EF%BC%8Csource-x2F-sink%E4%B8%A4%E7%AB%AF%E9%83%BD%E8%83%BD%E8%BF%9E%E6%8E%A5%EF%BC%8C%E5%8F%AF%E8%AF%BB%E5%8F%AF%E5%86%99%EF%BC%9B%E8%80%8C%E5%AF%B9%E4%BA%8EElasticsearch%E3%80%81JDBC%E7%AD%89%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8%E7%B3%BB%E7%BB%9F%EF%BC%8C%E5%88%99%E5%8F%AA%E6%8F%90%E4%BE%9B%E4%BA%86%E8%BE%93%E5%87%BA%E5%86%99%E5%85%A5%E7%9A%84sink%E8%BF%9E%E6%8E%A5%E5%99%A8%E3%80%82"><span class="toc-number"></span> <span class="toc-text">我们可以看到，像Kafka之类流式系统，Flink提供了完美对接，source&#x2F;sink两端都能连接，可读可写；而对于Elasticsearch、JDBC等数据存储系统，则只提供了输出写入的sink连接器。</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%99%A4Flink%E5%AE%98%E6%96%B9%E4%B9%8B%E5%A4%96%EF%BC%8CApache-Bahir%E6%A1%86%E6%9E%B6%EF%BC%8C%E4%B9%9F%E5%AE%9E%E7%8E%B0%E4%BA%86%E4%B8%80%E4%BA%9B%E5%85%B6%E4%BB%96%E7%AC%AC%E4%B8%89%E6%96%B9%E7%B3%BB%E7%BB%9F%E4%B8%8EFlink%E7%9A%84%E8%BF%9E%E6%8E%A5%E5%99%A8%E3%80%82"><span class="toc-number"></span> <span class="toc-text">除Flink官方之外，Apache Bahir框架，也实现了一些其他第三方系统与Flink的连接器。</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%99%A4%E6%AD%A4%E4%BB%A5%E5%A4%96%EF%BC%8C%E5%B0%B1%E9%9C%80%E8%A6%81%E7%94%A8%E6%88%B7%E8%87%AA%E5%AE%9A%E4%B9%89%E5%AE%9E%E7%8E%B0sink%E8%BF%9E%E6%8E%A5%E5%99%A8%E4%BA%86%E3%80%82"><span class="toc-number"></span> <span class="toc-text">除此以外，就需要用户自定义实现sink连接器了。</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-4-2-%E8%BE%93%E5%87%BA%E5%88%B0%E6%96%87%E4%BB%B6"><span class="toc-number"></span> <span class="toc-text">5.4.2 输出到文件</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Flink%E4%B8%93%E9%97%A8%E6%8F%90%E4%BE%9B%E4%BA%86%E4%B8%80%E4%B8%AA%E6%B5%81%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%9A%84%E8%BF%9E%E6%8E%A5%E5%99%A8%EF%BC%9AFileSink%EF%BC%8C%E4%B8%BA%E6%89%B9%E5%A4%84%E7%90%86%E5%92%8C%E6%B5%81%E5%A4%84%E7%90%86%E6%8F%90%E4%BE%9B%E4%BA%86%E4%B8%80%E4%B8%AA%E7%BB%9F%E4%B8%80%E7%9A%84Sink%EF%BC%8C%E5%AE%83%E5%8F%AF%E4%BB%A5%E5%B0%86%E5%88%86%E5%8C%BA%E6%96%87%E4%BB%B6%E5%86%99%E5%85%A5Flink%E6%94%AF%E6%8C%81%E7%9A%84%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E3%80%82"><span class="toc-number"></span> <span class="toc-text">Flink专门提供了一个流式文件系统的连接器：FileSink，为批处理和流处理提供了一个统一的Sink，它可以将分区文件写入Flink支持的文件系统。</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#FileSink%E6%94%AF%E6%8C%81%E8%A1%8C%E7%BC%96%E7%A0%81%EF%BC%88Row-encoded%EF%BC%89%E5%92%8C%E6%89%B9%E9%87%8F%E7%BC%96%E7%A0%81%EF%BC%88Bulk-encoded%EF%BC%89%E6%A0%BC%E5%BC%8F%E3%80%82%E8%BF%99%E4%B8%A4%E7%A7%8D%E4%B8%8D%E5%90%8C%E7%9A%84%E6%96%B9%E5%BC%8F%E9%83%BD%E6%9C%89%E5%90%84%E8%87%AA%E7%9A%84%E6%9E%84%E5%BB%BA%E5%99%A8%EF%BC%88builder%EF%BC%89%EF%BC%8C%E5%8F%AF%E4%BB%A5%E7%9B%B4%E6%8E%A5%E8%B0%83%E7%94%A8FileSink%E7%9A%84%E9%9D%99%E6%80%81%E6%96%B9%E6%B3%95%EF%BC%9A"><span class="toc-number"></span> <span class="toc-text">FileSink支持行编码（Row-encoded）和批量编码（Bulk-encoded）格式。这两种不同的方式都有各自的构建器（builder），可以直接调用FileSink的静态方法：</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AE%9E%E4%BE%8B%EF%BC%9A"><span class="toc-number"></span> <span class="toc-text">实例：</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-4-3-%E8%BE%93%E5%87%BA%E5%88%B0Kafka"><span class="toc-number"></span> <span class="toc-text">1.4.3 输出到Kafka</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%EF%BC%881%EF%BC%89%E6%B7%BB%E5%8A%A0Kafka-%E8%BF%9E%E6%8E%A5%E5%99%A8%E4%BE%9D%E8%B5%96"><span class="toc-number"></span> <span class="toc-text">（1）添加Kafka 连接器依赖</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%94%B1%E4%BA%8E%E6%88%91%E4%BB%AC%E5%B7%B2%E7%BB%8F%E6%B5%8B%E8%AF%95%E8%BF%87%E4%BB%8EKafka%E6%95%B0%E6%8D%AE%E6%BA%90%E8%AF%BB%E5%8F%96%E6%95%B0%E6%8D%AE%EF%BC%8C%E8%BF%9E%E6%8E%A5%E5%99%A8%E7%9B%B8%E5%85%B3%E4%BE%9D%E8%B5%96%E5%B7%B2%E7%BB%8F%E5%BC%95%E5%85%A5%EF%BC%8C%E8%BF%99%E9%87%8C%E5%B0%B1%E4%B8%8D%E9%87%8D%E5%A4%8D%E4%BB%8B%E7%BB%8D%E4%BA%86%E3%80%82"><span class="toc-number"></span> <span class="toc-text">由于我们已经测试过从Kafka数据源读取数据，连接器相关依赖已经引入，这里就不重复介绍了。</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%EF%BC%882%EF%BC%89%E5%90%AF%E5%8A%A8Kafka%E9%9B%86%E7%BE%A4"><span class="toc-number"></span> <span class="toc-text">（2）启动Kafka集群</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%EF%BC%883%EF%BC%89%E7%BC%96%E5%86%99%E8%BE%93%E5%87%BA%E5%88%B0Kafka%E7%9A%84%E7%A4%BA%E4%BE%8B%E4%BB%A3%E7%A0%81"><span class="toc-number"></span> <span class="toc-text">（3）编写输出到Kafka的示例代码</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%BE%93%E5%87%BA%E6%97%A0key%E7%9A%84record"><span class="toc-number"></span> <span class="toc-text">输出无key的record:</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%84%B6%E5%90%8E%E5%BC%80%E4%B8%80%E4%B8%AA%E6%B6%88%E8%B4%B9%E8%80%85%E6%9F%A5%E7%9C%8B%E6%98%AF%E5%90%A6%E5%88%B0%E6%95%B0%E6%8D%AE"><span class="toc-number"></span> <span class="toc-text">然后开一个消费者查看是否到数据</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-4-4-%E8%BE%93%E5%87%BA%E5%88%B0MySQL%EF%BC%88JDBC%EF%BC%89"><span class="toc-number"></span> <span class="toc-text">1.4.4 输出到MySQL（JDBC）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%86%99%E5%85%A5%E6%95%B0%E6%8D%AE%E7%9A%84MySQL%E7%9A%84%E6%B5%8B%E8%AF%95%E6%AD%A5%E9%AA%A4%E5%A6%82%E4%B8%8B%E3%80%82"><span class="toc-number"></span> <span class="toc-text">写入数据的MySQL的测试步骤如下。</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%EF%BC%881%EF%BC%89%E6%B7%BB%E5%8A%A0%E4%BE%9D%E8%B5%96"><span class="toc-number"></span> <span class="toc-text">（1）添加依赖</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B7%BB%E5%8A%A0MySQL%E9%A9%B1%E5%8A%A8%EF%BC%9A"><span class="toc-number"></span> <span class="toc-text">添加MySQL驱动：</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AE%98%E6%96%B9%E8%BF%98%E6%9C%AA%E6%8F%90%E4%BE%9Bflink-connector-jdbc%E7%9A%841-17-0%E7%9A%84%E6%AD%A3%E5%BC%8F%E4%BE%9D%E8%B5%96%EF%BC%8C%E6%9A%82%E6%97%B6%E4%BB%8Eapache-snapshot%E4%BB%93%E5%BA%93%E4%B8%8B%E8%BD%BD%EF%BC%8Cpom%E6%96%87%E4%BB%B6%E4%B8%AD%E6%8C%87%E5%AE%9A%E4%BB%93%E5%BA%93%E8%B7%AF%E5%BE%84%EF%BC%9A"><span class="toc-number"></span> <span class="toc-text">官方还未提供flink-connector-jdbc的1.17.0的正式依赖，暂时从apache snapshot仓库下载，pom文件中指定仓库路径：</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%B7%BB%E5%8A%A0%E4%BE%9D%E8%B5%96%EF%BC%9A"><span class="toc-number"></span> <span class="toc-text">添加依赖：</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%A6%82%E6%9E%9C%E4%B8%8D%E7%94%9F%E6%95%88%EF%BC%8C%E8%BF%98%E9%9C%80%E8%A6%81%E4%BF%AE%E6%94%B9%E6%9C%AC%E5%9C%B0maven%E7%9A%84%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%EF%BC%8CmirrorOf%E4%B8%AD%E6%B7%BB%E5%8A%A0%E5%A6%82%E4%B8%8B%E6%A0%87%E7%BA%A2%E5%86%85%E5%AE%B9%EF%BC%9A"><span class="toc-number"></span> <span class="toc-text">如果不生效，还需要修改本地maven的配置文件，mirrorOf中添加如下标红内容：</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%EF%BC%882%EF%BC%89%E5%90%AF%E5%8A%A8MySQL%EF%BC%8C%E5%9C%A8test%E5%BA%93%E4%B8%8B%E5%BB%BA%E8%A1%A8ws"><span class="toc-number"></span> <span class="toc-text">（2）启动MySQL，在test库下建表ws</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%EF%BC%883%EF%BC%89%E7%BC%96%E5%86%99%E8%BE%93%E5%87%BA%E5%88%B0MySQL%E7%9A%84%E7%A4%BA%E4%BE%8B%E4%BB%A3%E7%A0%81"><span class="toc-number"></span> <span class="toc-text">（3）编写输出到MySQL的示例代码</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%EF%BC%884%EF%BC%89%E8%BF%90%E8%A1%8C%E4%BB%A3%E7%A0%81%EF%BC%8C%E7%94%A8%E5%AE%A2%E6%88%B7%E7%AB%AF%E8%BF%9E%E6%8E%A5MySQL%EF%BC%8C%E6%9F%A5%E7%9C%8B%E6%98%AF%E5%90%A6%E6%88%90%E5%8A%9F%E5%86%99%E5%85%A5%E6%95%B0%E6%8D%AE%E3%80%82"><span class="toc-number"></span> <span class="toc-text">（4）运行代码，用客户端连接MySQL，查看是否成功写入数据。</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-4-5-%E8%87%AA%E5%AE%9A%E4%B9%89Sink%E8%BE%93%E5%87%BA"><span class="toc-number"></span> <span class="toc-text">1.4.5 自定义Sink输出</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%A6%82%E6%9E%9C%E6%88%91%E4%BB%AC%E6%83%B3%E5%B0%86%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8%E5%88%B0%E6%88%91%E4%BB%AC%E8%87%AA%E5%B7%B1%E7%9A%84%E5%AD%98%E5%82%A8%E8%AE%BE%E5%A4%87%E4%B8%AD%EF%BC%8C%E8%80%8CFlink%E5%B9%B6%E6%B2%A1%E6%9C%89%E6%8F%90%E4%BE%9B%E5%8F%AF%E4%BB%A5%E7%9B%B4%E6%8E%A5%E4%BD%BF%E7%94%A8%E7%9A%84%E8%BF%9E%E6%8E%A5%E5%99%A8%EF%BC%8C%E5%B0%B1%E5%8F%AA%E8%83%BD%E8%87%AA%E5%AE%9A%E4%B9%89Sink%E8%BF%9B%E8%A1%8C%E8%BE%93%E5%87%BA%E4%BA%86%E3%80%82%E4%B8%8ESource%E7%B1%BB%E4%BC%BC%EF%BC%8CFlink%E4%B8%BA%E6%88%91%E4%BB%AC%E6%8F%90%E4%BE%9B%E4%BA%86%E9%80%9A%E7%94%A8%E7%9A%84SinkFunction%E6%8E%A5%E5%8F%A3%E5%92%8C%E5%AF%B9%E5%BA%94%E7%9A%84RichSinkDunction%E6%8A%BD%E8%B1%A1%E7%B1%BB%EF%BC%8C%E5%8F%AA%E8%A6%81%E5%AE%9E%E7%8E%B0%E5%AE%83%EF%BC%8C%E9%80%9A%E8%BF%87%E7%AE%80%E5%8D%95%E5%9C%B0%E8%B0%83%E7%94%A8DataStream%E7%9A%84-addSink-%E6%96%B9%E6%B3%95%E5%B0%B1%E5%8F%AF%E4%BB%A5%E8%87%AA%E5%AE%9A%E4%B9%89%E5%86%99%E5%85%A5%E4%BB%BB%E4%BD%95%E5%A4%96%E9%83%A8%E5%AD%98%E5%82%A8%E3%80%82"><span class="toc-number"></span> <span class="toc-text">如果我们想将数据存储到我们自己的存储设备中，而Flink并没有提供可以直接使用的连接器，就只能自定义Sink进行输出了。与Source类似，Flink为我们提供了通用的SinkFunction接口和对应的RichSinkDunction抽象类，只要实现它，通过简单地调用DataStream的.addSink()方法就可以自定义写入任何外部存储。</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9C%A8%E5%AE%9E%E7%8E%B0SinkFunction%E7%9A%84%E6%97%B6%E5%80%99%EF%BC%8C%E9%9C%80%E8%A6%81%E9%87%8D%E5%86%99%E7%9A%84%E4%B8%80%E4%B8%AA%E5%85%B3%E9%94%AE%E6%96%B9%E6%B3%95invoke-%EF%BC%8C%E5%9C%A8%E8%BF%99%E4%B8%AA%E6%96%B9%E6%B3%95%E4%B8%AD%E6%88%91%E4%BB%AC%E5%B0%B1%E5%8F%AF%E4%BB%A5%E5%AE%9E%E7%8E%B0%E5%B0%86%E6%B5%81%E9%87%8C%E7%9A%84%E6%95%B0%E6%8D%AE%E5%8F%91%E9%80%81%E5%87%BA%E5%8E%BB%E7%9A%84%E9%80%BB%E8%BE%91%E3%80%82"><span class="toc-number"></span> <span class="toc-text">在实现SinkFunction的时候，需要重写的一个关键方法invoke()，在这个方法中我们就可以实现将流里的数据发送出去的逻辑。</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%BF%99%E7%A7%8D%E6%96%B9%E5%BC%8F%E6%AF%94%E8%BE%83%E9%80%9A%E7%94%A8%EF%BC%8C%E5%AF%B9%E4%BA%8E%E4%BB%BB%E4%BD%95%E5%A4%96%E9%83%A8%E5%AD%98%E5%82%A8%E7%B3%BB%E7%BB%9F%E9%83%BD%E6%9C%89%E6%95%88%EF%BC%9B%E4%B8%8D%E8%BF%87%E8%87%AA%E5%AE%9A%E4%B9%89Sink%E6%83%B3%E8%A6%81%E5%AE%9E%E7%8E%B0%E7%8A%B6%E6%80%81%E4%B8%80%E8%87%B4%E6%80%A7%E5%B9%B6%E4%B8%8D%E5%AE%B9%E6%98%93%EF%BC%8C%E6%89%80%E4%BB%A5%E4%B8%80%E8%88%AC%E5%8F%AA%E5%9C%A8%E6%B2%A1%E6%9C%89%E5%85%B6%E5%AE%83%E9%80%89%E6%8B%A9%E6%97%B6%E4%BD%BF%E7%94%A8%E3%80%82%E5%AE%9E%E9%99%85%E9%A1%B9%E7%9B%AE%E4%B8%AD%E7%94%A8%E5%88%B0%E7%9A%84%E5%A4%96%E9%83%A8%E8%BF%9E%E6%8E%A5%E5%99%A8Flink%E5%AE%98%E6%96%B9%E5%9F%BA%E6%9C%AC%E9%83%BD%E5%B7%B2%E5%AE%9E%E7%8E%B0%EF%BC%8C%E8%80%8C%E4%B8%94%E5%9C%A8%E4%B8%8D%E6%96%AD%E5%9C%B0%E6%89%A9%E5%85%85%EF%BC%8C%E5%9B%A0%E6%AD%A4%E8%87%AA%E5%AE%9A%E4%B9%89%E7%9A%84%E5%9C%BA%E6%99%AF%E5%B9%B6%E4%B8%8D%E5%B8%B8%E8%A7%81%E3%80%82"><span class="toc-number"></span> <span class="toc-text">这种方式比较通用，对于任何外部存储系统都有效；不过自定义Sink想要实现状态一致性并不容易，所以一般只在没有其它选择时使用。实际项目中用到的外部连接器Flink官方基本都已实现，而且在不断地扩充，因此自定义的场景并不常见。</span></a></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="anzhiyufont anzhiyu-icon-history"></i><span>最近发布</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/posts/git001.html" title="git学习"><img src= "/imgs/loading/loading.gif" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://pic1.imgdb.cn/item/6784bd24d0e0a243d4f3d4a3.png?_r_=587f5087-8fbf-9eed-bdbb-47994d663c44" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="git学习"/></a><div class="content"><a class="title" href="/posts/git001.html" title="git学习">git学习</a><time datetime="2025-05-23T07:17:58.000Z" title="发表于 2025-05-23 15:17:58">2025-05-23</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/mysql1.html" title="mysql搭建使用"><img src= "/imgs/loading/loading.gif" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://pic1.imgdb.cn/item/6784bd24d0e0a243d4f3d4a3.png?_r_=d78b3699-fc14-5be6-2e6d-a56c9a65bc28" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="mysql搭建使用"/></a><div class="content"><a class="title" href="/posts/mysql1.html" title="mysql搭建使用">mysql搭建使用</a><time datetime="2025-04-17T01:18:18.000Z" title="发表于 2025-04-17 09:18:18">2025-04-17</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/a403.html" title="mysql运维"><img src= "/imgs/loading/loading.gif" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://pic1.imgdb.cn/item/6784bd24d0e0a243d4f3d4a3.png?_r_=36e48ea1-47aa-6757-6366-a220ab2c5a0f" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="mysql运维"/></a><div class="content"><a class="title" href="/posts/a403.html" title="mysql运维">mysql运维</a><time datetime="2025-02-17T06:59:37.000Z" title="发表于 2025-02-17 14:59:37">2025-02-17</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/a298.html" title="省赛样题1"><img src= "/imgs/loading/loading.gif" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://pic1.imgdb.cn/item/6784be46d0e0a243d4f3d508.jpg?_r_=d3807f01-f96e-3518-f185-0ad9b0ced9fd" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="省赛样题1"/></a><div class="content"><a class="title" href="/posts/a298.html" title="省赛样题1">省赛样题1</a><time datetime="2025-02-17T06:59:37.000Z" title="发表于 2025-02-17 14:59:37">2025-02-17</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/a398.html" title="省赛样题1解析"><img src= "/imgs/loading/loading.gif" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://pic1.imgdb.cn/item/6784bd24d0e0a243d4f3d4a3.png?_r_=a7dafa4d-7303-db0a-fa89-cbcc8e41c8af" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="省赛样题1解析"/></a><div class="content"><a class="title" href="/posts/a398.html" title="省赛样题1解析">省赛样题1解析</a><time datetime="2025-02-17T06:59:37.000Z" title="发表于 2025-02-17 14:59:37">2025-02-17</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/a299.html" title="省赛样题2"><img src= "/imgs/loading/loading.gif" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://pic1.imgdb.cn/item/6784be5fd0e0a243d4f3d513.png?_r_=56bd173d-4de1-6da8-237a-520d3641d852" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="省赛样题2"/></a><div class="content"><a class="title" href="/posts/a299.html" title="省赛样题2">省赛样题2</a><time datetime="2025-02-17T06:59:37.000Z" title="发表于 2025-02-17 14:59:37">2025-02-17</time></div></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div id="footer_deal"><a class="deal_link" target="_blank" rel="noopener" href="https://blogyx.top/" title="主页"><i class="anzhiyufont anzhiyufont anzhiyu-icon-paper-plane"></i></a><a class="deal_link" target="_blank" rel="noopener" href="https://blogyx.top/" title="email"><i class="anzhiyufont anzhiyufont anzhiyu-icon-envelope"></i></a><a class="deal_link" target="_blank" rel="noopener" href="https://blogyx.top/" title="微博"><i class="anzhiyufont anzhiyufont anzhiyu-icon-weibo"></i></a><img class="footer_mini_logo" title="返回顶部" alt="返回顶部" onclick="anzhiyu.scrollToDest(0, 500)" src= "/imgs/loading/loading.gif" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/imgs/gif/ghost.gif" size="50px"/><a class="deal_link" target="_blank" rel="noopener" href="https://blogyx.top/" title="Github"><i class="anzhiyufont anzhiyufont anzhiyu-icon-github"></i></a><a class="deal_link" target="_blank" rel="noopener" href="https://space.bilibili.com/" title="Bilibili"><i class="anzhiyufont anzhiyufont anzhiyu-icon-bilibili"></i></a><a class="deal_link" target="_blank" rel="noopener" href="https://www.douyin.com/" title="抖音"><i class="anzhiyufont anzhiyufont anzhiyu-icon-tiktok"></i></a></div><div id="workboard"><img class="workSituationImg boardsign" src= "/imgs/loading/loading.gif" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/imgs/gif/cat.gif" alt="但行好事，莫问前程" title="但行好事，莫问前程"/><div id="runtimeTextTip"></div></div><div id="anzhiyu-footer"><div class="footer-group"><div class="footer-title">服务</div><div class="footer-links"><a class="footer-item" title="51la统计" target="_blank" rel="noopener" href="https://v6.51.la/">51la统计</a><a class="footer-item" title="十年之约" target="_blank" rel="noopener" href="https://www.foreverblog.cn/">十年之约</a><a class="footer-item" title="开往" target="_blank" rel="noopener" href="https://blogyx.top//travellings-link/travellings">开往</a></div></div><div class="footer-group"><div class="footer-title">导航</div><div class="footer-links"><a class="footer-item" title="个人主页" target="_blank" rel="noopener" href="https://blogyx.top/">个人主页</a><a class="footer-item" title="ChatGPT" target="_blank" rel="noopener" href="https://blogyx.top/">ChatGPT</a><a class="footer-item" title="站点监测" target="_blank" rel="noopener" href="https://blogyx.top/">站点监测</a></div></div><div class="footer-group"><div class="footer-title">主题</div><div class="footer-links"><a class="footer-item" title="模板仓库" target="_blank" rel="noopener" href="https://blogyx.top//gavinblog/blog-anzhiyu">模板仓库</a><a class="footer-item" title="主题文档" target="_blank" rel="noopener" href="https://gavinblog.github.io/anzhiyu-docs/">主题文档</a><a class="footer-item" title="更新日志" target="_blank" rel="noopener" href="https://blogyx.top//anzhiyu-c/hexo-theme-anzhiyu/releases">更新日志</a></div></div><div class="footer-group"><div class="footer-title-group"><div class="footer-title">友链</div><a class="random-friends-btn" id="footer-random-friends-btn" href="javascript:addFriendLinksInFooter();" title="换一批友情链接"><i class="anzhiyufont anzhiyu-icon-arrow-rotate-right"></i></a></div><div class="footer-links" id="friend-links-in-footer"></div></div></div><p id="ghbdages"><a class="github-badge" target="_blank" href="https://blogyx.top//gavinblog/blog-anzhiyu" style="margin-inline:5px" data-title="本站项目由Github托管" title="本站项目由Github托管"><img src= "/imgs/loading/loading.gif" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://npm.elemecdn.com/anzhiyu-blog@2.1.5/img/badge/Source-Github.svg" alt="本站项目由Github托管"/></a><a class="github-badge" target="_blank" href="https://hexo.io/" style="margin-inline:5px" data-title="博客框架为Hexo_v5.4.0" title="博客框架为Hexo_v5.4.0"><img src= "/imgs/loading/loading.gif" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://npm.elemecdn.com/anzhiyu-blog@2.1.5/img/badge/Frame-Hexo.svg" alt="博客框架为Hexo_v5.4.0"/></a><a class="github-badge" target="_blank" href="https://blogyx.top//anzhiyu-c/hexo-theme-anzhiyu.git" style="margin-inline:5px" data-title="本站使用AnZhiYu主题" title="本站使用AnZhiYu主题"><img src= "/imgs/loading/loading.gif" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://img.shields.io/badge/Hexo--Theme-Anzhiyu-green" alt="本站使用AnZhiYu主题"/></a></p></div><div id="footer-bar"><div class="footer-bar-links"><div class="footer-bar-left"><div id="footer-bar-tips"><div class="copyright">&copy;2006 - 2025 By <a class="footer-bar-link" href="/" title="曦" target="_blank">曦</a></div></div><div id="footer-type-tips"></div><div class="js-pjax"><script>function subtitleType () {
  if (true) { 
    window.typed = new Typed("#footer-type-tips", {
      strings: ["晨曦洒在窗沿，点亮了新的一天。","Talk Is Cheap, Show Me the Code."],
      startDelay: 300,
      typeSpeed: 150,
      loop: true,
      backSpeed: 50
    })
  } else {
    document.getElementById("footer-type-tips").innerHTML = '晨曦洒在窗沿，点亮了新的一天。'
  }
}

if (true) {
  if (typeof Typed === 'function') {
    subtitleType()
  } else {
    getScript('https://unpkg.com/typed.js@2.1.0/dist/typed.umd.js').then(subtitleType)
  }
} else {
  subtitleType()
}</script></div></div><div class="footer-bar-right"><a class="footer-bar-link" target="_blank" rel="noopener" href="https://blogyx.top/" title="主页">主页</a><a class="footer-bar-link" target="_blank" rel="noopener" href="https://blogyx.top/" title="导航">导航</a><a class="footer-bar-link" target="_blank" rel="noopener" href="https://blogyx.top//YXlhx/blog" title="源码">源码</a><a class="footer-bar-link" target="_blank" rel="noopener" href="https://blogyx.top/" title="文档">文档</a><a class="footer-bar-link" target="_blank" rel="noopener" href="https://blogyx.top/" title="访客">访客</a><a class="footer-bar-link cc" href="/about" title="cc协议"><i class="anzhiyufont anzhiyu-icon-copyright-line"></i><i class="anzhiyufont anzhiyu-icon-creative-commons-by-line"></i><i class="anzhiyufont anzhiyu-icon-creative-commons-nc-line"></i><i class="anzhiyufont anzhiyu-icon-creative-commons-nd-line"></i></a></div></div></div></footer></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="sidebar-site-data site-data is-center"><a href="/archives/" title="archive"><div class="headline">文章</div><div class="length-num">91</div></a><a href="/tags/" title="tag"><div class="headline">标签</div><div class="length-num">14</div></a><a href="/categories/" title="category"><div class="headline">分类</div><div class="length-num">15</div></a></div><span class="sidebar-menu-item-title">功能</span><div class="sidebar-menu-item"><a class="darkmode_switchbutton menu-child" href="javascript:void(0);" title="显示模式"><i class="anzhiyufont anzhiyu-icon-circle-half-stroke"></i><span>显示模式</span></a></div><div class="back-menu-list-groups"><div class="back-menu-list-group"><div class="back-menu-list-title">站点</div><div class="back-menu-list"><a class="back-menu-item" target="_blank" rel="noopener" href="https://blogyx.top/" title="个人主页"><img class="back-menu-item-icon" src= "/imgs/loading/loading.gif" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/imgs/avatar.webp" alt="个人主页"/><span class="back-menu-item-text">个人主页</span></a><a class="back-menu-item" target="_blank" rel="noopener" href="https://blogyx.top/" title="个人导航"><img class="back-menu-item-icon" src= "/imgs/loading/loading.gif" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/imgs/avatar.webp" alt="个人导航"/><span class="back-menu-item-text">个人导航</span></a><a class="back-menu-item" target="_blank" rel="noopener" href="https://blogyx.top/" title="博客-Hugo"><img class="back-menu-item-icon" src= "/imgs/loading/loading.gif" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/imgs/avatar.webp" alt="博客-Hugo"/><span class="back-menu-item-text">博客-Hugo</span></a><a class="back-menu-item" target="_blank" rel="noopener" href="https://blogyx.top/" title="博客-Hexo"><img class="back-menu-item-icon" src= "/imgs/loading/loading.gif" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/imgs/avatar.webp" alt="博客-Hexo"/><span class="back-menu-item-text">博客-Hexo</span></a></div></div><div class="back-menu-list-group"><div class="back-menu-list-title">常用网址</div><div class="back-menu-list"><a class="back-menu-item" target="_blank" rel="noopener" href="https://tool.lu/" title="在线工具"><img class="back-menu-item-icon" src= "/imgs/loading/loading.gif" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/imgs/avatar.webp" alt="在线工具"/><span class="back-menu-item-text">在线工具</span></a><a class="back-menu-item" target="_blank" rel="noopener" href="https://gavinblog.github.io/picx/#/upload" title="免费图床-Picx"><img class="back-menu-item-icon" src= "/imgs/loading/loading.gif" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/imgs/avatar.webp" alt="免费图床-Picx"/><span class="back-menu-item-text">免费图床-Picx</span></a></div></div><div class="back-menu-list-group"><div class="back-menu-list-title">AI大模型</div><div class="back-menu-list"><a class="back-menu-item" target="_blank" rel="noopener" href="https://chat.openai.com/" title="ChatGPT"><img class="back-menu-item-icon" src= "/imgs/loading/loading.gif" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/imgs/avatar.webp" alt="ChatGPT"/><span class="back-menu-item-text">ChatGPT</span></a><a class="back-menu-item" target="_blank" rel="noopener" href="https://blogyx.top//7flash/AutoChatGPT" title="AutoChatGPT"><img class="back-menu-item-icon" src= "/imgs/loading/loading.gif" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/imgs/avatar.webp" alt="AutoChatGPT"/><span class="back-menu-item-text">AutoChatGPT</span></a><a class="back-menu-item" target="_blank" rel="noopener" href="https://bing.com/create" title="Bing-图像创建者"><img class="back-menu-item-icon" src= "/imgs/loading/loading.gif" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/imgs/avatar.webp" alt="Bing-图像创建者"/><span class="back-menu-item-text">Bing-图像创建者</span></a><a class="back-menu-item" target="_blank" rel="noopener" href="https://stablediffusionweb.com/" title="Stable Diffusion Online"><img class="back-menu-item-icon" src= "/imgs/loading/loading.gif" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/imgs/avatar.webp" alt="Stable Diffusion Online"/><span class="back-menu-item-text">Stable Diffusion Online</span></a><a class="back-menu-item" target="_blank" rel="noopener" href="https://yiyan.baidu.com/" title="文心一言"><img class="back-menu-item-icon" src= "/imgs/loading/loading.gif" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/imgs/avatar.webp" alt="文心一言"/><span class="back-menu-item-text">文心一言</span></a><a class="back-menu-item" target="_blank" rel="noopener" href="https://yige.baidu.com/" title="文心一格"><img class="back-menu-item-icon" src= "/imgs/loading/loading.gif" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/imgs/avatar.webp" alt="文心一格"/><span class="back-menu-item-text">文心一格</span></a><a class="back-menu-item" target="_blank" rel="noopener" href="https://xinghuo.xfyun.cn/" title="讯飞星火"><img class="back-menu-item-icon" src= "/imgs/loading/loading.gif" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/imgs/avatar.webp" alt="讯飞星火"/><span class="back-menu-item-text">讯飞星火</span></a></div></div></div><div class="menus_items"><div class="menus_item"><a class="site-page faa-parent animated-hover" target="_blank" rel="noopener" href="https://blogyx.top/"><span> 🏠</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><span> 博客</span></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/archives/"><i class="anzhiyufont anzhiyu-icon-box-archive faa-tada" style="font-size: 0.9em;"></i><span> 文章</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/categories/"><i class="anzhiyufont anzhiyu-icon-shapes faa-tada" style="font-size: 0.9em;"></i><span> 分类</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/tags/"><i class="anzhiyufont anzhiyu-icon-tags faa-tada" style="font-size: 0.9em;"></i><span> 标签</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/charts/"><i class="fa-solid fa-chart-pie fa-spin faa-tada"></i><span> 统计</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/anzhiyu-docs/"><i class="anzhiyufont anzhiyu-icon-book faa-tada" style="font-size: 0.9em;"></i><span> 文档</span></a></li><li><a class="site-page child faa-parent animated-hover" target="_blank" rel="noopener" href="https://blogyx.top/"><i class="anzhiyufont anzhiyu-icon-link faa-tada" style="font-size: 0.9em;"></i><span> 博客-Hugo</span></a></li><li><a class="site-page child faa-parent animated-hover" target="_blank" rel="noopener" href="https://blogyx.top/"><i class="anzhiyufont anzhiyu-icon-link faa-tada" style="font-size: 0.9em;"></i><span> 博客-Hexo</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><span> 我的</span></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/link/"><i class="anzhiyufont anzhiyu-icon-link faa-tada" style="font-size: 0.9em;"></i><span> 友人帐</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/fcircle/"><i class="anzhiyufont anzhiyu-icon-artstation faa-tada" style="font-size: 0.9em;"></i><span> 朋友圈</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/guestbook/"><i class="anzhiyufont anzhiyu-icon-envelope faa-tada" style="font-size: 0.9em;"></i><span> 留言板</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/essay/"><i class="anzhiyufont anzhiyu-icon-lightbulb faa-tada" style="font-size: 0.9em;"></i><span> 说说</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/album/"><i class="anzhiyufont anzhiyu-icon-images faa-tada" style="font-size: 0.9em;"></i><span> 相册集</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/air-condition/"><i class="anzhiyufont anzhiyu-icon-fan faa-tada" style="font-size: 0.9em;"></i><span> 小空调</span></a></li></ul></div><div class="menus_item"><a class="site-page faa-parent animated-hover" href="/music/?id=8138088068&amp;server=tencent"><span> 音乐</span></a></div><div class="menus_item"><a class="site-page faa-parent animated-hover" href="/sites/all-sites"><span> 🌐</span></a></div><div class="menus_item"><a class="site-page faa-parent animated-hover" href="/about/"><span> 🧑‍💻</span></a></div></div><span class="sidebar-menu-item-title">标签</span><div class="card-tags"><div class="item-headline"></div><div class="card-tag-cloud"><a href="/tags/Azkaban/" style="font-size: 0.88rem; color: rgb(188, 126, 199);">Azkaban<sup>8</sup></a><a href="/tags/Flink/" style="font-size: 0.88rem; color: rgb(41, 140, 145);">Flink<sup>5</sup></a><a href="/tags/Flume/" style="font-size: 0.88rem; color: rgb(110, 133, 100);">Flume<sup>19</sup></a><a href="/tags/Hadoop/" style="font-size: 0.88rem; color: rgb(171, 4, 81);">Hadoop<sup>1</sup></a><a href="/tags/Redis/" style="font-size: 0.88rem; color: rgb(17, 112, 47);">Redis<sup>4</sup></a><a href="/tags/Spark/" style="font-size: 0.88rem; color: rgb(100, 81, 159);">Spark<sup>3</sup></a><a href="/tags/Sqoop/" style="font-size: 0.88rem; color: rgb(198, 150, 0);">Sqoop<sup>10</sup></a><a href="/tags/demo/" style="font-size: 0.88rem; color: rgb(198, 111, 51);">demo<sup>16</sup></a><a href="/tags/mysql/" style="font-size: 0.88rem; color: rgb(38, 73, 4);">mysql<sup>1</sup></a><a href="/tags/scala/" style="font-size: 0.88rem; color: rgb(82, 86, 140);">scala<sup>9</sup></a><a href="/tags/yum%E9%85%8D%E7%BD%AE/" style="font-size: 0.88rem; color: rgb(145, 161, 128);">yum配置<sup>1</sup></a><a href="/tags/%E5%AD%A6%E4%B9%A0%E8%B7%AF%E7%BA%BF/" style="font-size: 0.88rem; color: rgb(120, 58, 15);">学习路线<sup>3</sup></a><a href="/tags/%E7%9C%81%E8%B5%9B%E6%A0%B7%E9%A2%98/" style="font-size: 0.88rem; color: rgb(74, 80, 29);">省赛样题<sup>11</sup></a><a href="/tags/%E7%A4%BA%E4%BE%8B/" style="font-size: 0.88rem; color: rgb(46, 188, 39);">示例<sup>88</sup></a></div></div><hr/></div></div><div id="keyboard-tips"><div class="keyboardTitle">博客快捷键</div><div class="keybordList"><div class="keybordItem"><div class="keyGroup"><div class="key">shift K</div></div><div class="keyContent"><div class="content">关闭快捷键功能</div></div></div><div class="keybordItem"><div class="keyGroup"><div class="key">shift A</div></div><div class="keyContent"><div class="content">打开/关闭中控台</div></div></div><div class="keybordItem"><div class="keyGroup"><div class="key">shift M</div></div><div class="keyContent"><div class="content">播放/暂停音乐</div></div></div><div class="keybordItem"><div class="keyGroup"><div class="key">shift D</div></div><div class="keyContent"><div class="content">深色/浅色显示模式</div></div></div><div class="keybordItem"><div class="keyGroup"><div class="key">shift S</div></div><div class="keyContent"><div class="content">站内搜索</div></div></div><div class="keybordItem"><div class="keyGroup"><div class="key">shift R</div></div><div class="keyContent"><div class="content">随机访问</div></div></div><div class="keybordItem"><div class="keyGroup"><div class="key">shift H</div></div><div class="keyContent"><div class="content">返回首页</div></div></div><div class="keybordItem"><div class="keyGroup"><div class="key">shift F</div></div><div class="keyContent"><div class="content">友链鱼塘</div></div></div><div class="keybordItem"><div class="keyGroup"><div class="key">shift L</div></div><div class="keyContent"><div class="content">友链页面</div></div></div><div class="keybordItem"><div class="keyGroup"><div class="key">shift P</div></div><div class="keyContent"><div class="content">关于本站</div></div></div><div class="keybordItem"><div class="keyGroup"><div class="key">shift I</div></div><div class="keyContent"><div class="content">原版/本站右键菜单</div></div></div></div></div><div id="rightside"><div id="rightside-config-hide"><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="anzhiyufont anzhiyu-icon-list-ul"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="anzhiyufont anzhiyu-icon-circle-half-stroke"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="anzhiyufont anzhiyu-icon-arrows-left-right"></i></button><button id="readmode" type="button" title="阅读模式"><i class="anzhiyufont anzhiyu-icon-book-open"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="anzhiyufont anzhiyu-icon-gear"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="anzhiyufont anzhiyu-icon-comments"></i></a><a id="switch-commentBarrage" href="javascript:anzhiyu.switchCommentBarrage();" title="开关弹幕"><i class="anzhiyufont anzhiyu-icon-danmu"></i></a><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="anzhiyufont anzhiyu-icon-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="anzhiyufont anzhiyu-icon-arrow-up"></i></button></div></div><div id="nav-music"><a id="nav-music-hoverTips" onclick="anzhiyu.musicToggle()" accesskey="m">播放音乐</a><div id="console-music-bg"></div><meting-js id="8138088068" server="tencent" type="playlist" mutex="true" preload="none" theme="var(--anzhiyu-main)" data-lrctype="0" order="random" volume="0.7"></meting-js></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="anzhiyufont anzhiyu-icon-xmark"></i></button></nav><div class="is-center" id="loading-database"><i class="anzhiyufont anzhiyu-icon-spinner anzhiyu-pulse-icon"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div></div></div><div id="search-mask"></div></div><div id="rightMenu"><div class="rightMenu-group rightMenu-small"><div class="rightMenu-item" id="menu-backward"><i class="anzhiyufont anzhiyu-icon-arrow-left"></i></div><div class="rightMenu-item" id="menu-forward"><i class="anzhiyufont anzhiyu-icon-arrow-right"></i></div><div class="rightMenu-item" id="menu-refresh"><i class="anzhiyufont anzhiyu-icon-arrow-rotate-right" style="font-size: 1rem;"></i></div><div class="rightMenu-item" id="menu-top"><i class="anzhiyufont anzhiyu-icon-arrow-up"></i></div></div><div class="rightMenu-group rightMenu-line rightMenuPlugin"><div class="rightMenu-item" id="menu-copytext"><i class="anzhiyufont anzhiyu-icon-copy"></i><span>复制选中文本</span></div><div class="rightMenu-item" id="menu-pastetext"><i class="anzhiyufont anzhiyu-icon-paste"></i><span>粘贴文本</span></div><a class="rightMenu-item" id="menu-commenttext"><i class="anzhiyufont anzhiyu-icon-comment-medical"></i><span>引用到评论</span></a><div class="rightMenu-item" id="menu-newwindow"><i class="anzhiyufont anzhiyu-icon-window-restore"></i><span>新窗口打开</span></div><div class="rightMenu-item" id="menu-copylink"><i class="anzhiyufont anzhiyu-icon-link"></i><span>复制链接地址</span></div><div class="rightMenu-item" id="menu-copyimg"><i class="anzhiyufont anzhiyu-icon-images"></i><span>复制此图片</span></div><div class="rightMenu-item" id="menu-downloadimg"><i class="anzhiyufont anzhiyu-icon-download"></i><span>下载此图片</span></div><div class="rightMenu-item" id="menu-newwindowimg"><i class="anzhiyufont anzhiyu-icon-window-restore"></i><span>新窗口打开图片</span></div><div class="rightMenu-item" id="menu-search"><i class="anzhiyufont anzhiyu-icon-magnifying-glass"></i><span>站内搜索</span></div><div class="rightMenu-item" id="menu-searchBaidu"><i class="anzhiyufont anzhiyu-icon-magnifying-glass"></i><span>百度搜索</span></div><div class="rightMenu-item" id="menu-music-toggle"><i class="anzhiyufont anzhiyu-icon-play"></i><span>播放音乐</span></div><div class="rightMenu-item" id="menu-music-back"><i class="anzhiyufont anzhiyu-icon-backward"></i><span>切换到上一首</span></div><div class="rightMenu-item" id="menu-music-forward"><i class="anzhiyufont anzhiyu-icon-forward"></i><span>切换到下一首</span></div><div class="rightMenu-item" id="menu-music-playlist" onclick="window.open(&quot;https://y.qq.com/n/ryqq/playlist/8138088068&quot;, &quot;_blank&quot;);" style="display: none;"><i class="anzhiyufont anzhiyu-icon-radio"></i><span>查看所有歌曲</span></div><div class="rightMenu-item" id="menu-music-copyMusicName"><i class="anzhiyufont anzhiyu-icon-copy"></i><span>复制歌名</span></div></div><div class="rightMenu-group rightMenu-line rightMenuOther"><a class="rightMenu-item menu-link" id="menu-randomPost"><i class="anzhiyufont anzhiyu-icon-shuffle"></i><span>随便逛逛</span></a><a class="rightMenu-item menu-link" href="/categories/"><i class="anzhiyufont anzhiyu-icon-cube"></i><span>博客分类</span></a><a class="rightMenu-item menu-link" href="/tags/"><i class="anzhiyufont anzhiyu-icon-tags"></i><span>文章标签</span></a></div><div class="rightMenu-group rightMenu-line rightMenuOther"><a class="rightMenu-item" id="menu-copy" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-copy"></i><span>复制地址</span></a><a class="rightMenu-item" id="menu-commentBarrage" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-message"></i><span class="menu-commentBarrage-text">关闭热评</span></a><a class="rightMenu-item" id="menu-darkmode" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-circle-half-stroke"></i><span class="menu-darkmode-text">深色模式</span></a><a class="rightMenu-item" id="menu-translate" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-language"></i><span>轉為繁體</span></a></div></div><div id="rightmenu-mask"></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://unpkg.com/medium-zoom@1.1.0/dist/medium-zoom.min.js"></script><script src="https://unpkg.com/instant.page@5.2.0/instantpage.js" type="module"></script><script src="https://unpkg.com/vanilla-lazyload@17.8.5/dist/lazyload.iife.min.js"></script><script src="https://unpkg.com/node-snackbar@0.1.16/dist/snackbar.min.js"></script><script>var meting_api = "https://api.injahow.cn/meting/?server=:server&type=:type&id=:id&auth=:auth&r=:r";
</script><canvas id="universe"></canvas><script async src="https://npm.elemecdn.com/anzhiyu-theme-static@1.0.0/dark/dark.js"></script><script>// 消除控制台打印
var HoldLog = console.log;
console.log = function () {};
let now1 = new Date();
queueMicrotask(() => {
  const Log = function () {
    HoldLog.apply(console, arguments);
  }; //在恢复前输出日志
  const grt = new Date("01/01/2025 15:04:05"); //此处修改你的建站时间或者网站上线时间
  now1.setTime(now1.getTime() + 250);
  const days = (now1 - grt) / 1000 / 60 / 60 / 24;
  const dnum = Math.floor(days);
  const ascll = [
    `欢迎使用安知鱼!`,
    `生活明朗, 万物可爱`,
    `
        
       █████╗ ███╗   ██╗███████╗██╗  ██╗██╗██╗   ██╗██╗   ██╗
      ██╔══██╗████╗  ██║╚══███╔╝██║  ██║██║╚██╗ ██╔╝██║   ██║
      ███████║██╔██╗ ██║  ███╔╝ ███████║██║ ╚████╔╝ ██║   ██║
      ██╔══██║██║╚██╗██║ ███╔╝  ██╔══██║██║  ╚██╔╝  ██║   ██║
      ██║  ██║██║ ╚████║███████╗██║  ██║██║   ██║   ╚██████╔╝
      ╚═╝  ╚═╝╚═╝  ╚═══╝╚══════╝╚═╝  ╚═╝╚═╝   ╚═╝    ╚═════╝
        
        `,
    "已上线",
    dnum,
    "天",
    "©2006 By 安知鱼 V1.6.14",
  ];
  const ascll2 = [`NCC2-036`, `调用前置摄像头拍照成功，识别为【小笨蛋】.`, `Photo captured: `, `🤪`];

  setTimeout(
    Log.bind(
      console,
      `\n%c${ascll[0]} %c ${ascll[1]} %c ${ascll[2]} %c${ascll[3]}%c ${ascll[4]}%c ${ascll[5]}\n\n%c ${ascll[6]}\n`,
      "color:#425AEF",
      "",
      "color:#425AEF",
      "color:#425AEF",
      "",
      "color:#425AEF",
      ""
    )
  );
  setTimeout(
    Log.bind(
      console,
      `%c ${ascll2[0]} %c ${ascll2[1]} %c \n${ascll2[2]} %c\n${ascll2[3]}\n`,
      "color:white; background-color:#4fd953",
      "",
      "",
      'background:url("https://npm.elemecdn.com/anzhiyu-blog@1.1.6/img/post/common/tinggge.gif") no-repeat;font-size:450%'
    )
  );

  setTimeout(Log.bind(console, "%c WELCOME %c 你好，小笨蛋.", "color:white; background-color:#4f90d9", ""));

  setTimeout(
    console.warn.bind(
      console,
      "%c ⚡ Powered by 安知鱼 %c 你正在访问 曦 的博客.",
      "color:white; background-color:#f0ad4e",
      ""
    )
  );

  setTimeout(Log.bind(console, "%c W23-12 %c 你已打开控制台.", "color:white; background-color:#4f90d9", ""));

  setTimeout(
    console.warn.bind(console, "%c S013-782 %c 你现在正处于监控中.", "color:white; background-color:#d9534f", "")
  );
});</script><script async src="/anzhiyu/random.js"></script><script async="async">(function () {
  var grt = new Date("01/01/2025 15:04:05"); //设置网站上线时间
  var now = new Date();
  var dnum;
  var hnum;
  var mnum;
  var snum;
  var nowHour;

  // 计算并更新天数、小时数、分钟数和秒数
  function updateTime() {
    now = new Date(); // 更新 now 的值
    nowHour = now.getHours(); // 更新 nowHour 的值
    var days = (now - grt) / 1000 / 60 / 60 / 24;
    dnum = Math.floor(days);
    var hours = (now - grt) / 1000 / 60 / 60 - 24 * dnum;
    hnum = Math.floor(hours);
    if (String(hnum).length == 1) {
      hnum = "0" + hnum;
    }
    var minutes = (now - grt) / 1000 / 60 - 24 * 60 * dnum - 60 * hnum;
    mnum = Math.floor(minutes);
    if (String(mnum).length == 1) {
      mnum = "0" + mnum;
    }
    var seconds = (now - grt) / 1000 - 24 * 60 * 60 * dnum - 60 * 60 * hnum - 60 * mnum;
    snum = Math.round(seconds);
    if (String(snum).length == 1) {
      snum = "0" + snum;
    }
  }

  // 更新网页中显示的网站运行时间
  function updateHtml() {
    const footer = document.getElementById("footer");
    if (!footer) return
    let currentTimeHtml = "";
    if (nowHour < 18 && nowHour >= 9) {
      // 如果是上班时间，默认就是"安知鱼-上班摸鱼中.svg"图片，不需要更改
      currentTimeHtml = `本站居然运行了 ${dnum} 天<span id='runtime'> ${hnum} 小时 ${mnum} 分 ${snum} 秒 </span><i class='anzhiyufont anzhiyu-icon-heartbeat' style='color:red'></i>`;
    } else {
      // 如果是下班时间，插入"安知鱼-下班啦.svg"图片
      let img = document.querySelector("#workboard .workSituationImg");
      if (img != null) {
        img.src = "/imgs/gif/tree.gif";
        img.title = "天高任鸟飞，海阔凭鱼跃";
        img.alt = "天高任鸟飞，海阔凭鱼跃";
      }

      currentTimeHtml = `本站居然运行了 ${dnum} 天<span id='runtime'> ${hnum} 小时 ${mnum} 分 ${snum} 秒 </span><i class='anzhiyufont anzhiyu-icon-heartbeat' style='color:red'></i>`;
    }

    if (document.getElementById("runtimeTextTip")) {
      document.getElementById("runtimeTextTip").innerHTML = currentTimeHtml;
    }
  }

  setInterval(() => {
    updateTime();
    updateHtml();
  }, 1000);
})();</script><script src="/js/search/local-search.js"></script><div class="js-pjax"><script>(() => {
  const init = () => {
    twikoo.init(Object.assign({
      el: '#twikoo-wrap',
      envId: 'https://hkjcpdd.xiaozhou.cloud/',
      region: '',
      onCommentLoaded: () => {
        anzhiyu.loadLightbox(document.querySelectorAll('#twikoo .tk-content img:not(.tk-owo-emotion)'))
      }
    }, null))
  }

  const loadTwikoo = () => {
    if (typeof twikoo === 'object') setTimeout(runFn,0)
    else getScript('https://unpkg.com/twikoo@1.6.39/dist/twikoo.all.min.js').then(runFn)
  }

  const getCount = () => {
    const countELement = document.getElementById('twikoo-count')
    if(!countELement) return
    twikoo.getCommentsCount({
      envId: 'https://hkjcpdd.xiaozhou.cloud/',
      region: '',
      urls: [window.location.pathname],
      includeReply: false
    }).then(res => {
      countELement.textContent = res[0].count
    }).catch(err => {
      console.error(err)
    })
  }

  const runFn = () => {
    init();
    GLOBAL_CONFIG_SITE.isPost && getCount()
  }

  if ('Twikoo' === 'Twikoo' || !false) {
    if (false) anzhiyu.loadComment(document.getElementById('twikoo-wrap'), loadTwikoo)
    else {
      loadTwikoo()
    }
  } else {
    window.loadOtherComment = loadTwikoo
  }
})()</script><input type="hidden" name="page-type" id="page-type" value="post"><script async src="/js/anzhiyu/comment_barrage.js"></script></div><script>window.addEventListener('load', () => {
  const changeContent = (content) => {
    if (content === '') return content

    content = content.replace(/<img.*?src="(.*?)"?[^\>]+>/ig, '[图片]') // replace image link
    content = content.replace(/<a[^>]+?href=["']?([^"']+)["']?[^>]*>([^<]+)<\/a>/gi, '[链接]') // replace url
    content = content.replace(/<pre><code>.*?<\/pre>/gi, '[代码]') // replace code
    content = content.replace(/<[^>]+>/g,"") // remove html tag

    if (content.length > 150) {
      content = content.substring(0,150) + '...'
    }
    return content
  }

  const getComment = () => {
    const runTwikoo = () => {
      twikoo.getRecentComments({
        envId: 'https://hkjcpdd.xiaozhou.cloud/',
        region: '',
        pageSize: 6,
        includeReply: true
      }).then(function (res) {
        const twikooArray = res.map(e => {
          return {
            'content': changeContent(e.comment),
            'avatar': e.avatar,
            'nick': e.nick,
            'url': e.url + '#' + e.id,
            'date': new Date(e.created).toISOString()
          }
        })

        saveToLocal.set('twikoo-newest-comments', JSON.stringify(twikooArray), 10/(60*24))
        generateHtml(twikooArray)
      }).catch(function (err) {
        const $dom = document.querySelector('#card-newest-comments .aside-list')
        $dom.textContent= "无法获取评论，请确认相关配置是否正确"
      })
    }

    if (typeof twikoo === 'object') {
      runTwikoo()
    } else {
      getScript('https://unpkg.com/twikoo@1.6.39/dist/twikoo.all.min.js').then(runTwikoo)
    }
  }

  const generateHtml = array => {
    let result = ''

    if (array.length) {
      for (let i = 0; i < array.length; i++) {
        result += '<div class=\'aside-list-item\'>'

        if (true) {
          const name = 'data-lazy-src'
          result += `<a href='${array[i].url}' class='thumbnail'><img ${name}='${array[i].avatar}' alt='${array[i].nick}'><div class='name'><span>${array[i].nick} </span></div></a>`
        }
        
        result += `<div class='content'>
        <a class='comment' href='${array[i].url}' title='${array[i].content}'>${array[i].content}</a>
        <time datetime="${array[i].date}">${anzhiyu.diffDate(array[i].date, true)}</time></div>
        </div>`
      }
    } else {
      result += '没有评论'
    }

    let $dom = document.querySelector('#card-newest-comments .aside-list')
    $dom && ($dom.innerHTML= result)
    window.lazyLoadInstance && window.lazyLoadInstance.update()
    window.pjax && window.pjax.refresh($dom)
  }

  const newestCommentInit = () => {
    if (document.querySelector('#card-newest-comments .aside-list')) {
      const data = saveToLocal.get('twikoo-newest-comments')
      if (data) {
        generateHtml(JSON.parse(data))
      } else {
        getComment()
      }
    }
  }

  newestCommentInit()
  document.addEventListener('pjax:complete', newestCommentInit)
})</script><script async data-pjax src="https://npm.elemecdn.com/anzhiyu-theme-static@1.0.1/bubble/bubble.js"></script><script>var visitorMail = "foshana@163.com";
</script><script async data-pjax src="https://unpkg.com/anzhiyu-theme-static@1.0.0/waterfall/waterfall.js"></script><script src="https://lf3-cdn-tos.bytecdntp.com/cdn/expire-1-M/qrcodejs/1.0.0/qrcode.min.js"></script><script src="/js/anzhiyu/right_click_menu.js"></script><link rel="stylesheet" href="https://unpkg.com/anzhiyu-theme-static@1.1.9/icon/ali_iconfont_css.css"><script async src="https://analytics.umami.is/script.js" data-website-id="12b10d95-8761-47e3-9bc9-257f796cc5f0"></script><script src="/custom/custom.js"></script><script src="/custom/welcome/welcome.js"></script><script defer type="text/javascript" src="/custom/dayalert/sweetalert2.all.js"></script><script defer src="/custom/dayalert/lunar.js"></script><script defer src="/custom/dayalert/day.js"></script><script async data-pjax src="/js/imgloaded.js?1"></script><script src="https://unpkg.com/butterfly-extsrc@1.1.3/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = true;
POWERMODE.mobile = false;
document.body.addEventListener('input', POWERMODE);
</script><script id="click-show-text" src="https://unpkg.com/butterfly-extsrc@1.1.3/dist/click-show-text.min.js" data-mobile="true" data-text="I,LOVE,YOU" data-fontsize="15px" data-random="false" async="async"></script><link rel="stylesheet" href="https://unpkg.com/anzhiyu-theme-static@1.0.0/aplayer/APlayer.min.css" media="print" onload="this.media='all'"><script src="https://unpkg.com/anzhiyu-blog-static@1.0.1/js/APlayer.min.js"></script><script src="https://unpkg.com/hexo-anzhiyu-music@1.0.1/assets/js/Meting2.min.js"></script><script src="https://unpkg.com/pjax@0.2.8/pjax.min.js"></script><script>let pjaxSelectors = ["meta[property=\"og:image\"]","meta[property=\"og:title\"]","meta[property=\"og:url\"]","meta[property=\"og:type\"]","meta[property=\"og:site_name\"]","meta[property=\"og:description\"]","head > title","#config-diff","#body-wrap","#rightside-config-hide","#rightside-config-show",".js-pjax"]
var pjax = new Pjax({
  elements: 'a:not([target="_blank"])',
  selectors: pjaxSelectors,
  cacheBust: false,
  analytics: true,
  scrollRestoration: false
})

document.addEventListener('pjax:send', function () {
  // removeEventListener scroll 
  anzhiyu.removeGlobalFnEvent('pjax')
  anzhiyu.removeGlobalFnEvent('themeChange')

  document.getElementById('rightside').classList.remove('rightside-show')
  
  if (window.aplayers) {
    for (let i = 0; i < window.aplayers.length; i++) {
      if (!window.aplayers[i].options.fixed) {
        window.aplayers[i].destroy()
      }
    }
  }

  typeof typed === 'object' && typed.destroy()

  //reset readmode
  const $bodyClassList = document.body.classList
  $bodyClassList.contains('read-mode') && $bodyClassList.remove('read-mode')
})

document.addEventListener('pjax:complete', function () {
  window.refreshFn()

  document.querySelectorAll('script[data-pjax]').forEach(item => {
    const newScript = document.createElement('script')
    const content = item.text || item.textContent || item.innerHTML || ""
    Array.from(item.attributes).forEach(attr => newScript.setAttribute(attr.name, attr.value))
    newScript.appendChild(document.createTextNode(content))
    item.parentNode.replaceChild(newScript, item)
  })

  GLOBAL_CONFIG.islazyload && window.lazyLoadInstance.update()

  typeof panguInit === 'function' && panguInit()

  // google analytics
  typeof gtag === 'function' && gtag('config', 'G-MXDTZ2L2TY', {'page_path': window.location.pathname});

  // baidu analytics
  typeof _hmt === 'object' && _hmt.push(['_trackPageview',window.location.pathname]);

  typeof loadMeting === 'function' && document.getElementsByClassName('aplayer').length && loadMeting()

  // prismjs
  typeof Prism === 'object' && Prism.highlightAll()
})

document.addEventListener('pjax:error', e => {
  if (e.request.status === 404) {
    pjax.loadUrl('/404.html')
  }
})</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script charset="UTF-8" src="https://unpkg.com/anzhiyu-theme-static@1.1.5/accesskey/accesskey.js"></script></div><div id="popup-window"><div class="popup-window-title">通知</div><div class="popup-window-divider"></div><div class="popup-window-content"><div class="popup-tip">你好呀</div><div class="popup-link"><i class="anzhiyufont anzhiyu-icon-arrow-circle-right"></i></div></div></div><!-- hexo injector body_end start --><script data-pjax>function history_calendar_injector_config(){
                var parent_div_git = document.getElementsByClassName('card-widget')[0];
                var item_html = '<div class="card-widget card-history" style="height: 146px;"><div class="card-content"><div class="item-headline"><i class="fas fa-clock fa-spin"></i><span>那年今日</span></div><div id="history-baidu" style="height: 100px;overflow: hidden"><div class="history_swiper-container" id="history-container" style="width: 100%;height: 100%"><div class="swiper-wrapper" id="history_container_wrapper" style="height:20px"></div></div></div></div>';
                console.log('已挂载history_calendar')
                // parent_div_git.innerHTML=item_html+parent_div_git.innerHTML // 无报错，但不影响使用(支持pjax跳转)
                parent_div_git.insertAdjacentHTML("afterbegin",item_html) // 有报错，但不影响使用(支持pjax跳转)
            }if( document.getElementsByClassName('card-widget')[0] && (location.pathname ==='all'|| 'all' ==='all')){

            history_calendar_injector_config()
        } </script><script data-pjax  src="https://cdn.jsdelivr.net/npm/swiper/swiper-bundle.min.js"></script><script data-pjax src="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-card-history/baiduhistory/js/main.js"></script><script data-pjax>
  function butterfly_clock_anzhiyu_injector_config(){
    var parent_div_git = document.getElementsByClassName('sticky_layout')[0];
    var item_html = '<div class="card-widget card-clock"><div class="card-glass"><div class="card-background"><div class="card-content"><div id="hexo_electric_clock"><img class="entered loading" id="card-clock-loading" src= "/imgs/loading/loading.gif" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/custom/clock/loading.gif" style="height: 120px; width: 100%;" data-ll-status="loading"/></div></div></div></div></div>';
    console.log('已挂载butterfly_clock_anzhiyu')
    if(parent_div_git) {
      parent_div_git.insertAdjacentHTML("afterbegin",item_html)
    }
  }
  var elist = 'null'.split(',');
  var cpage = location.pathname;
  var epage = 'all';
  var qweather_key = '8e18b5438c9f4d9cac96586a3589d52e';
  var gaud_map_key = '773a8e229dc264bcededffa74697e731';
  var baidu_ak_key = 'undefined';
  var flag = 0;
  var clock_rectangle = '112.982279,28.19409';
  var clock_default_rectangle_enable = 'false';

  for (var i=0;i<elist.length;i++){
    if (cpage.includes(elist[i])){
      flag++;
    }
  }

  if ((epage ==='all')&&(flag == 0)){
    butterfly_clock_anzhiyu_injector_config();
  }
  else if (epage === cpage){
    butterfly_clock_anzhiyu_injector_config();
  }
  </script><script src="https://widget.qweather.net/simple/static/js/he-simple-common.js?v=2.0"></script><script data-pjax src="/custom/clock/clock.min.js"></script><!-- hexo injector body_end end --></body></html>